{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GuideCH\\Programming\\project\\aib_showcase\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from facebook_scraper import get_posts\n",
    "import pythainlp as pythai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('showcase_data_cleaned(2022).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'ID', 'summary', 'title_image', 'images', 'links', 'reason',\n",
       "       'author', 'fulltext', 'post_url', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "ID             0\n",
       "summary        0\n",
       "title_image    0\n",
       "images         0\n",
       "links          0\n",
       "reason         0\n",
       "author         0\n",
       "fulltext       0\n",
       "post_url       0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {'date': \"\",  \"title\": \"\", \"builder\": \"\", \"builder_info\": \"\", \"thumbnail\": \"\", \"links\": {\"github\": \"\", \"facebook\": \"\", \"blog\": \"\"}, \"title_image\": \"\", \"summary\": \"\", \"reason\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://facebook.com/aibuildersx/posts/405337768301335\n"
     ]
    }
   ],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    print(data['post_url'][i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_summary(x: str) -> list[str]:\n",
    "    newx = x.split('- ')\n",
    "    x = [x for x in newx if x != '']\n",
    "    return newx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_link(link: str) -> list[str]:\n",
    "    newx = link.split('\\n')\n",
    "    newx = [x for x in newx if x != '']\n",
    "    medium = [x for x in newx if 'medium' in x or 'อ่านรายละเอียดเพิ่มเติม:' in x][0].split(': ')[-1]\n",
    "    github = [x for x in newx if 'github' in x][0].split(': ')[-1]\n",
    "    return medium, github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_author(link: str) -> list[str]:\n",
    "    newx = link.split('/')\n",
    "    name = newx[0]\n",
    "    bio = '/'.join(newx[1:])\n",
    "    return name, bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:00<?, ?it/s]C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      " 89%|████████▉ | 40/45 [00:00<00:00, 396.03it/s]C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_30940\\69931062.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "100%|██████████| 45/45 [00:00<00:00, 384.62it/s]\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "for project_index in tqdm(range(data.shape[0])):\n",
    "    root = './images/2022/'\n",
    "\n",
    "    info_dict = {'date': \"\",  \"title\": \"\", \"builder\": \"\", \"builder_info\": \"\", \"thumbnail\": \"\", \"links\": {\"github\": \"\", \"facebook\": \"\", \"blog\": \"\"}, \"summary\": \"\", \"reason\": \"\"}\n",
    "    info_dict['date'] = data.iloc[project_index]['date']\n",
    "    info_dict['title'] = data.iloc[project_index]['title']\n",
    "    info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
    "    # info_dict['thumbnail'] = data.iloc[project_index]['title_image']\n",
    "    project_id = data.iloc[project_index]['ID'].astype(str)\n",
    "    info_dict['thumbnail'] = root + project_id + '/' + '01' + '.jpg' # save to static/images/2022/21/01.jpg\n",
    "    \n",
    "    info_dict['links']['blog'], info_dict['links']['github'] = process_link(data.iloc[project_index]['links'])\n",
    "    info_dict['links']['facebook'] = data.iloc[project_index]['post_url']\n",
    "    info_dict['summary'] = process_summary(data.iloc[project_index]['summary'])\n",
    "    info_dict['summary'] = new_summary = ['- ' + x.replace(\"'\", '') for x in info_dict['summary'] if x != '']\n",
    "    info_dict['reason'] = data.iloc[project_index]['reason'].split('แล้ว):')[-1].replace(\"',\", '').replace(\"'\", '')\n",
    "    # strip everyshit\n",
    "    for key in info_dict.keys():\n",
    "        if type(info_dict[key]) == str:\n",
    "            info_dict[key] = info_dict[key].strip()\n",
    "        elif type(info_dict[key]) == list:\n",
    "            info_dict[key] = [x.strip() for x in info_dict[key]]\n",
    "        elif type(info_dict[key]) == dict:\n",
    "            for key2 in info_dict[key].keys():\n",
    "                info_dict[key][key2] = info_dict[key][key2].strip()\n",
    "    \n",
    "    posts.append(info_dict)\n",
    "\n",
    "    # download image and save to static/images in format \"/images/2022/21/01.jpg\"\n",
    "    # make folder according to ['ID']\n",
    "    if os.path.exists(root) == False:\n",
    "        os.mkdir(root)\n",
    "\n",
    "    if os.path.exists(root + data.iloc[project_index]['ID'].astype(str)) == False:\n",
    "        os.mkdir(root + data.iloc[project_index]['ID'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_md(data_dict):\n",
    "    md_format ='''---\n",
    "date: \"{}\"\n",
    "title: \"{}\"\n",
    "builder: \"{}\"\n",
    "builder_info: \"{}\"\n",
    "thumbnail: \"{}\"\n",
    "links:\n",
    "github: \"{}\"\n",
    "facebook: \"{}\"\n",
    "blog: \"{}\"\n",
    "---\n",
    "\n",
    "![image]({})\n",
    "\n",
    "{}\n",
    "\n",
    "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
    "\n",
    "> \"{}\"'''\n",
    "\n",
    "    return md_format.format(data_dict['date'], data_dict['title'], data_dict['builder'], data_dict['builder_info'], data_dict['thumbnail'][1:], data_dict['links']['github'], data_dict['links']['facebook'], data_dict['links']['blog'], data_dict['thumbnail'][1:], '\\n'.join(data_dict['summary']), info_dict['reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ID</th>\n",
       "      <th>summary</th>\n",
       "      <th>title_image</th>\n",
       "      <th>images</th>\n",
       "      <th>links</th>\n",
       "      <th>reason</th>\n",
       "      <th>author</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>post_url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, ID, summary, title_image, images, links, reason, author, fulltext, post_url, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['title'] == 'MyLittleHR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "date: \"1-7-22\"\n",
      "title: \"BACK (Blind All Can Know) - Action Captioning for Blinds\"\n",
      "builder: \"โชติวัฒน์ ตั้งสถาพร (ไนน์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/21/01.jpg\"\n",
      "links:\n",
      "github: \"https://colab.research.google.com/github/cninet/BACK/blob/main/BACK.ipynb\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/405337768301335\"\n",
      "blog: \"https://medium.com/@cninet.std/back-blind-all-can-know-action-captioning-a10a3fa85695\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/21/01.jpg)\n",
      "\n",
      "- โมเดลอธิบายรูปภาพ (image captioning) เพื่ออธิบายภาพตรงหน้าให้กับผู้พิการทางสายตา,\n",
      "- CLIPCap นำ pretrained CLIP เพื่อสร้าง image embeddings เป็น input ให้กับ pretrained GPT2 สร้างข้อความที่ตรงกับภาพ,\n",
      "- เทรนโมเดลด้วย Flickr30k (รูป-คำบรรยายภาษาอังกฤษ) เป็นเวลา 17 ชั่วโมง (10 epochs),\n",
      "- ตัดสินใจใช้ Flickr30k ทั้งที่จำนวนข้อมูลน้อยกว่า COCO เพราะทำแบบสอบถามแล้วพบว่าข้อมูลคำบรรยายของ Flickr30k มีคุณภาพมากกว่า,\n",
      "- ใช้ PyThaiNLP Translate ในการแปลภาษาคำบรรยายเป็นภาษาไทย เนื่องจากแบบสอบถามพบว่าเป็นธรรมชาติกว่า Google Translate API ในบริบทนี้,\n",
      "- ใช้ Google TTS ในการเปลี่ยนคำบรรยายที่ถูกแปลเป็นเสียงพูด,\n",
      "- นอกจากการเทรนโมเดล CLIPCap ตรง ๆ แล้วยังมีการนำมาประกอบการใช้งานกับ pretrained models อื่น ๆ เช่น PyThaiNLP Translate และ Google TTS อีกทั้งการต่อสู้กับคุณภาพข้อมูลอย่างสมศักดิ์ศรี เช่น ลบรูปซ้ำ, แก้ข้อมูลตาราง, แก้คำบรรยายที่มีมากกว่าหนึ่งประโยคต่อกัน ฯลฯ\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"2-7-22\"\n",
      "title: \"Violence Detection\"\n",
      "builder: \"ชินวัตร นาไชยธง (ม่อน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/22/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/monshinawatra/ViolenceDetection\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/405998371568608\"\n",
      "blog: \"https://medium.com/@monchinawat/%E0%B8%95%E0%B8%A3%E0%B8%A7%E0%B8%88%E0%B8%88%E0%B8%B1%E0%B8%9A%E0%B8%84%E0%B8%A7%E0%B8%B2%E0%B8%A1%E0%B8%A3%E0%B8%B8%E0%B8%99%E0%B9%81%E0%B8%A3%E0%B8%87%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2-video-classification-%E0%B8%89%E0%B8%9A%E0%B8%B1%E0%B8%9A%E0%B8%87%E0%B9%88%E0%B8%B2%E0%B8%A2-d2bbf894149f\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/22/01.jpg)\n",
      "\n",
      "- โมเดลตรวจจับการใช้ความรุนแรงจากกล้องวงจรปิดด้วย action recognition ในแต่ละเฟรม,\n",
      "- เทรนบนชุดข้อมูลที่รวบรวมจาก UCF101 (แยกวิดีโอ เช่น boxing, sumo เป็น violence), Real Life Violence Situations Dataset (1,000 violence, 1,000 non-violence), sparshdrolia/violence, Hockey Fight Videos,\n",
      "- คัดเลือกเฟรมที่จะใช้เทรนด้วย feature engineering แบบเฉพาะที่ทำให้โมเดลทำงานได้ดีกว่าใช้ทุกเฟรม โดยแบ่งวิดีโอเป็นช่วงๆ s ช่วง โดยมากสุด m ช่วง แล้วในแต่ละช่วงเราจะดึง features ออกมาโดย และเราจะข้ามเฟรมทุกๆ k เฟรมในช่วงที่ s นั้น,\n",
      "- เปลี่ยนรูปภาพในแต่ละเฟรมให้เป็น features ด้วย pretrained VGG16; เรียงตามลำดับเวลาในวิดีโอ,\n",
      "- นำ features เหล่านั้นมาเป็น input ให้กับ LSTM โดยใช้ 20 เฟรมก่อนหน้าจนถึงเฟรมปัจจุบัน มาทายว่าเฟรมปัจจุบันมีการใช้ความรุนแรงหรือไม่,\n",
      "- ความแม่นยำ (accuracy) ในระดับเฟรมอยู่ที่ 74.8% ใน test set\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"3-7-22\"\n",
      "title: \"Fake Product Detection on Online Retail\"\n",
      "builder: \"เจษฎา ปราณี (แจ็ค)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/23/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/JackJessada/fake_product_detect\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/406851801483265\"\n",
      "blog: \"https://medium.com/@jessadajackpranee/%E0%B8%82%E0%B8%AD%E0%B8%87%E0%B8%9B%E0%B8%A5%E0%B8%AD%E0%B8%A1%E0%B8%81%E0%B8%B1%E0%B8%9A-e-commerce-c2d1bb142e2e\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/23/01.jpg)\n",
      "\n",
      "- โมเดลประเมินว่าสินค้าที่ขายออนไลน์ในเว็บไซต์เป็นของแท้, ของปลอม หรือของไม่มีแบรนด์โดยใช้ข้อมูลจากหน้า product detail page,\n",
      "- แรงบันดาลใจจากการสำรวจของ intelligencenode ที่ว่าช่วงโรคระบาด COVID-19 มีผู้ใช้พบของปลอมระหว่างเลือกซื้อสินค้าออนไลน์ถึง 38% จากผู้ตอบแบบสอบถามทั้งหมด,\n",
      "- เก็บข้อมูลโดยการใช้ selenium ดึงข้อมูลจากหมวดหมู่เครื่องใช้ไฟฟ้าของ Shopee.co.th จำนวนเกือบ 5,000 รายการ แล้วจำแนกเป็นของแท้ (79%), ของปลอม (9%) และของไม่มีแบรนด์ (12%) **ด้วยมือเองทั้งหมด**,\n",
      "- ทำการ rebalance training set ด้วย SMOTE เป็นของแท้ 55%, ของปลอม 20% และของไม่มีแบรนด์ 25% เพื่อให้โมเดลเรียนรู้ได้ดีขึ้น,\n",
      "- ไม่ลืมที่จะแบ่ง test set ออกมาก่อน เพื่อไม่ให้มีการทดสอบหา metric ด้วยข้อมูลสังเคราะห์ จะทำให้โมเดลดูดีเกินจริง,\n",
      "- ใช้ feature จากหน้า product detail page โดยอ้างอิงสิ่งที่มนุษย์ใช้จำแนกของแท้-ของปลอม เช่น ราคา (ไม่ถูกหรือแพงเกินไป), จำนวนสินค้าที่ถูกขาย (ยอดขายไม่เวอร์จนเกินไป), จำนวนรีวิวสินค้า (รีวิวไม่เยอะหรือน้อยจนผิดสังเกต), จำสินค้าที่ร้านค้าขายทั้งหมด (ยิ่งขายเยอะยิ่งน่าเชื่อถือ), อัตราการตอบกลับของร้านค้า (ยิ่งตอบเร็วยิ่งใส่ใจลูกค้า), จำนวนผู้ติดตามร้านค้า (ไม่ได้มีผู้ติดตามปลอมเยอะจนผิดสัดส่วน), ระยะเวลาที่เปิดร้านค้ามา (ยิ่งยาวนานยิ่งน่าเชื่อถือ), เรตติ้งของสินค้า (ไม่ถูกปลอมขึ้นมา) ฯลฯ,\n",
      "- เลือกโมเดลที่ดีที่สุดด้วย cross-validation จาก KNN, Random Forest, และ XGBoost; เลือกใช้ Random Forest เนื่องจากผลงานดีพอๆกับ XGBoost แต่ใช้งานได้เร็วกว่า,\n",
      "- ลองนำคอมเม้นท์ในหน้า product detail page มาเป็น feature เพิ่มแล้ว แต่ผลไม่ดีขึ้น สันนิษฐานว่าเกิดจากโมเดลไม่สามารถแบ่งคุณภาพคอมเม้นท์ได้ เช่น คอมเม้นท์ปลอม มีคอมเม้นท์ประเภทร้านค้าขอให้พิมพ์ และคอมเม้นท์ที่ไม่เกี่ยวกับเนื้อหาเลย เป็นต้น,\n",
      "- ได้ผลดีถึง F1 score ที่ 0.9x ใน test set ทั้ง micro/macro average และในแต่ละประเภทสินค้าที่ทำนาย,\n",
      "- แต่เมื่อไปทดสอบกับประเภทสินค้าที่ไม่คุ้นเคย, product detail page จากเว็บไซต์อื่นที่ไม่ใช่ Shopee.co.th, หรือสินค้าที่ไม่ครอบคลุมจาก training set ยังพบเห็นความผิดพลาด; ต้องการข้อมูลเพิ่มเพื่อทำให้สมบูรณ์แบบ,\n",
      "- ทำการวิเคราะห์ข้อผิดพลาดอย่างเข้มข้นด้วย SHAP; หนึ่งในข้อสรุปที่น่าสนใจคือต้นไม้บางต้นตัดสินว่า \"ยิ่งยอดขายมาก ยิ่งมีโอกาสเป็นของปลอม\" ทั้งนี้เนื่องจากพฤติกรรมการปั๊มยอดขายของสินค้าปลอมนั่นเอง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"4-7-22\"\n",
      "title: \"Cactus Classification with Fastai\"\n",
      "builder: \"ปัณณธร กรุดทอง (โฟกัส)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/24/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Fosacius/cactus_pred\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/407556248079487\"\n",
      "blog: \"https://medium.com/@neko2nego/cactus-classification-with-fast-ai-393f8a64cadc\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/24/01.jpg)\n",
      "\n",
      "- โมเดลแยกประเภทแคคตัสที่มีหลากหลายสายพันธุ์ ทั้งต้นกระบองเพชรที่มีหนามที่เราคุ้นเคย ไปจนถึงแก้วมังกรก็เป็นแคคตัสประเภทหนึ่ง,\n",
      "- แรงบันดาลใจเกิดจากงานอดิเรกในการปลูกแคคตัส และต้องการดูแลให้ถูกต้องตามสายพันธุ์ โดยเฉพาะมือใหม่ที่อาจจะแยกสายพันธุ์ไม่ออก,\n",
      "- แยกแคคตัสเป็น 5 สกุลได้แก่ Ariocarpus, Astrophytum, Echinopsis, Gymnocalycium, และ Ophuntia,\n",
      "- สร้างชุดข้อมูลจาก DuckDuckGo image search โดยอ้างอิงหนังสือแคคตัส Cactus (ใหม่) ของภวพล ศุภนันทนานนท์รวมทั้งหมด 1,500 รูป แบ่งเป็น validation set สกุลละ 60 รูป,\n",
      "- ทำการปรับจูน pretrained resnet-50 เพื่อจำแนกสกุลแคคตัสได้ความแม่นยำที่ 87%,\n",
      "- มีแผนการเพิ่มสกุลแคคตัสไปถึง 20++,\n",
      "- สุขสันต์วันเกิดโฟกัสเมื่อ 7 กรกฎาคมที่ผ่านมา\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"5-7-22\"\n",
      "title: \"Food Ingredients Label Reader for Food Allergy\"\n",
      "builder: \"พีรณัฐ เมฆวิศิษฏ์ (ปอนด์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/25/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/ponmak/Food-ingredients-label-reader\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/408346911333754\"\n",
      "blog: \"https://medium.com/@peeranut.4498/food-ingredients-label-reader-for-food-allergy-6dea1de06d2\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/25/01.jpg)\n",
      "\n",
      "- โปรแกรมอ่านฉลากสินค้าด้วย pretrained OCR และค้นหาวัตถุดิบที่ผู้ใช้แพ้ด้วย pretrained word vector,\n",
      "- แรงบันดาลใจจากครอบครัวที่สายตาสั้นกันทั้งบ้านทำให้เวลาจะอ่านอะไรที่อยู่บนฉลากนั้นเป็นเรื่องยากพอสมควรโดนเฉพาะส่วนประกอบในอาหาร; หลายสินค้าไม่มีการเน้นชื่อวัตถุดิบที่คนแพ้ง่ายให้เห็นชัดเจน,\n",
      "- เลือกใช้ pretrained OCR ระหว่าง Google Vision, EasyOCR และ Tesseract; เลือกใช้ Google Vision เนื่องจากเหตุผลความเร็วในการทำนาย,\n",
      "- เปลี่ยนคำให้เป็น word vector ด้วย pretrained thai2fit แล้วหาความคล้ายกันด้วย cosine similarity ระหว่างคำในฉลากและชื่อวัตถุดิบ; ตัดคำด้วย dictionary-based newmm (PyThaiNLP default)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"6-7-22\"\n",
      "title: \"Edge-to-Face: Drawing Realistic Faces from Canny Edges\"\n",
      "builder: \"นิธิศรัฎฐ์ พุฒิภาพงศ์ (พลัส)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/26/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/PluzNtp/Edge-to-Face\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/409045037930608\"\n",
      "blog: \"https://medium.com/@nitisarath/edge-to-face-683005cdbbb6\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/26/01.jpg)\n",
      "\n",
      "- โมเดล pix2pix GAN ที่เปลี่ยนรูปร่างหน้าคน (Edges) เป็นรูปภาพหน้าคน,\n",
      "- เทรนด้วยชุดข้อมูลหน้าดารา (ส่วนใหญ่จากสหรัฐอเมริกา) รวม 8,760 รูป,\n",
      "- ใช้ haarcascade จับหน้าจากรูป แล้วเปลี่ยนเป็นภาพร่างด้วย canny edge detection เพื่อใช้เป็น input สำหรับโมเดล (รูปจริงเป็น output),\n",
      "- ใช้สถาปัตยกรรม pix2pix GAN โดยใช้ L1 loss สำหรับ generator (U-Net; สร้างภาพปลอมโดยการเติมสีลงใน pixel) และ BCE loss สำหรับ discriminator (Patch GAN; ทำนายแต่ละ patch ในรูปว่าจริงหรือปลอม),\n",
      "- ในการใช้งานจริงเติมรูปจากภาพร่างที่คล้ายกับ training set ได้ดี (canny edges) แต่ยังมีปัญหากับภาพร่างแบบอื่น เช่น ภาพร่างที่หาจากอินเตอร์เน็ต\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"7-7-22\"\n",
      "title: \"TextDoe: โมเดลจำแนกแวดวงบทความสิ่งพิมพ์\"\n",
      "builder: \"โชติอนันต์ทรัพย์ โสภาเคน (โชกุน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/27/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/ChotanansubSoph/TextDoe\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/409755317859580\"\n",
      "blog: \"https://medium.com/@chotanansub.s/text-classification-%E0%B8%88%E0%B8%B3%E0%B9%81%E0%B8%99%E0%B8%81%E0%B9%81%E0%B8%A7%E0%B8%94%E0%B8%A7%E0%B8%87%E0%B8%9A%E0%B8%97%E0%B8%84%E0%B8%A7%E0%B8%B2%E0%B8%A1%E0%B8%AA%E0%B8%B4%E0%B9%88%E0%B8%87%E0%B8%9E%E0%B8%B4%E0%B8%A1%E0%B8%9E%E0%B9%8C-db0ef5abc676\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/27/01.jpg)\n",
      "\n",
      "- โมเดลจำแนกประเภทเอกสารเพื่อลดระยะเวลาในการคัดแยกเอกสารและสามารถทำงานได้แบบอัตโนมัติ ประเภทได้แก่ Applied Science, Arts, Belief & Thought, Commerce & Finance, History, Imaginative, Natural & Pure Science, Social Science,\n",
      "- เทรนบน TNC ด้วยข้อมูลจากหนังสือ (60%), วารสาร (25), หนังสือพิมพ์ (5-10%), สิ่งพิมพ์อื่น (เช่น แผ่นพับโฆษณา; 5-10%) และงานเขียนเผยแพร่บนอินเตอร์เน็ต (<5%),\n",
      "- แบ่งข้อมูลตามเลข Serial Number ของ TNC โดยใช้ฟังชั่นเฉพาะทำให้จำนวนเอกสารแต่ละแหล่งออกมาสมดุลใน train, validation และ test set,\n",
      "- ใช้ WangchanBERTa เป็นโมเดลพื้นฐาน; ปรับจูนให้ทำการจำแนกประเภทเอกสาร,\n",
      "- WangchanBERTa (F1 0.71) ทำได้ดีกว่า baseline ที่ใช้ bag-of-words (F1 0.64) และ LSTM (F1 0.61),\n",
      "- วิเคราะห์ความผิดพลาดพบว่าบางครั้งประเภทของเอกสารมีความกำกวม เช่น เอกสาร \"ความร่วมมือของประเทศในภูมิภาคเอเชียตะวันออกเฉียงใต้ ในการก่อตั้งองค์การส่วนภูมิภาค 1945–1985\" เป็น History แต่โมเดลทายว่า Social Science\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"8-7-22\"\n",
      "title: \"Auto Lyric Recognizer\"\n",
      "builder: \"กิตติพงศ์ เทพอยู่ (ปืน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/28/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/KittpongT/auto_lyric_recognize\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/410400524461726\"\n",
      "blog: \"https://medium.com/@puenkittipongtapyou/ai-%E0%B8%96%E0%B8%AD%E0%B8%94%E0%B9%80%E0%B8%AA%E0%B8%B5%E0%B8%A2%E0%B8%87%E0%B8%A3%E0%B9%89%E0%B8%AD%E0%B8%87%E0%B8%A0%E0%B8%B2%E0%B8%A9%E0%B8%B2%E0%B9%84%E0%B8%97%E0%B8%A2-speech-to-text-%E0%B8%89%E0%B8%9A%E0%B8%B1%E0%B8%9A%E0%B8%A1%E0%B8%B7%E0%B8%AD%E0%B9%83%E0%B8%AB%E0%B8%A1%E0%B9%88-fcca46eeb3df\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/28/01.jpg)\n",
      "\n",
      "- โมเดลถอดคำร้องเพลงไทยจากไฟล์เสียงหรือลิ้งค์ YouTube โดยตรง ด้วย Wav2Vec2 ที่ถูกปรับจูน,\n",
      "- ใช้ข้อมูล 50 เพลงยอดฮิตบน YouTube ตามยอดคนฟังเป็นความยาว 150 นาที,\n",
      "- แยกเสียงเพลงออกจากเนื้อร้องด้วย Spleeter; ตัดเป็นคลิปละ 2-6 วินาทีเพื่อให้เหมาะกับการเทรนโมเดล,\n",
      "- พบปัญหาเนื้อเพลงที่เป็นข้อความไม่ตรงกับเสียง; แก้ปัญหาด้วยการตัดมือแบ่งกับน้องนนนี่ เพื่อนในโครงการ,\n",
      "- ทำความสะอาดเครื่องหมายพิเศษเข้ามาด้วย เช่น . , ที่เกิดจาการเชื่อมต่อประโยคต่างๆในเนื้อเพลง; เปลี่ยน ๆ เป็นการเพิ่มคำซ้ำในประโยคเช่น สิ่งต่างๆ เป็น สิ่งต่างต่าง; เปลี่ยน สระ แ ที่มักถูกเขียนในรูปของสระ เ เ เเละสระ ำ เป็น ํ า,\n",
      "- แบ่ง train-valid-test ที่ 50:25:25,\n",
      "- ใช้ airesearch/wav2vec2-large-xlsr-53-th ที่ถูกเทรนบน Common Voice 7 เป็นโมเดลพื้นฐาน,\n",
      "- วัดผลด้วย WER (ตัดคำด้วย newmm ของ PyThaiNLP) และ CER; ทำได้ดีกว่า airesearch/wav2vec2-large-xlsr-53-th ประมาณ 3-4 เท่าบน test set\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"9-7-22\"\n",
      "title: \"Image Transfer Day-to-Night and Night-to-Day\"\n",
      "builder: \"ณฐกร คเชนทร (เท็น)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/29/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/TENet1010/cycleGAN_Night2day\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/411124194389359\"\n",
      "blog: \"https://medium.com/@nattakorn2713/image-transfer-night-to-day-and-day-to-night-2086edc6b298\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/29/01.jpg)\n",
      "\n",
      "- เริ่มด้วยปัญหาเวลาเล่น social media ต่างๆแล้วเจอคลิปที่ถ่ายสิ่งลี้ลับ, อะไรที่ดูน่ากลัว หรือพลังงานบางอย่าง เมื่อถูกจับภาพไว้ได้ก็มักจะเป็นภาพที่ไม่ชัดและส่วนใหญ่เป็นตอนกลางคืน บางทีสิ่งเหล่านี้อาจเกินจากการตีความที่ผิดพลาดเนื่องจากละเอียดหายไปกับความมืดจึงอยากที่จะเปลี่ยนภาพพวกนี้ให้เป็นตอนกลางวันสดใส เพื่อดึงรายละเอียดที่หายได้กับความมืดกลับมา,\n",
      "- สาเหตุของความไม่ชัดคาดว่าเกิดจาก ความไวแสง (ISO; ยิ่งเพิ่มยิ่งสว่างแต่อยากทำให้เกิด noise), F-stop (เมื่อค่า F-stop ต่ำรูปจะชัดเพียงที่โฟกัสและสว่าง แต่ถ้าค่า F-stop มากก็จะทำให้ชัดทั้งภาพ แต่ภาพก็จะมืด), รวมถึงคุณภาพของกล้องและเลนส์,\n",
      "- วิธีแก้โดยไม่ใช้ ML เช่น ใช้ Adobe Lightroom ปรับค่า exposure แต่ก็จะทำให้เสียคุณภาพของรูปไป,\n",
      "- ใช้ CycleGAN ในการทำ image-to-image translation; ข้อดีคือไม่จำเป็นต้องใช้คู่รูปกลางวัน-กลางคืนของรูปเดียวกันเพราะ CycleGAN ใช้วิธี optimize ค่า cycle-consistency loss จากรูปภาพเดียวกันที่ถูกแปลงจากกลางวันเป็นกลางคืน หรือกลับกัน,\n",
      "- ใช้ PatchGAN เป็น discriminator และ generator เป็น autoencoder ที่มี residual block 9 ชั้น,\n",
      "- ทดลองรูปภาพจาก Aachen Day-Night dataset, Day-night Dataset จาก Kaggle, Mapillary Vistas Dataset, Day time and Night time road Images, Dataset Night city image; สุดท้ายใช้ภาพกลางวันจาก Mapillary Vistas Dataset และกลางคืนจาก Dataset Night city image อย่างละ 2,500 ภาพเป็น training set และอย่างละ 600 ภาพเป็น test set,\n",
      "- แปลงรูปภาพได้ค่อนข้างน่าพอใจหลังเทรนไป 55 epochs; หลัง error analysis พบภาพที่ผิด เช่น การเติมแสงไฟในรูปที่ไม่ควรเติมเมื่อแปลงรูปจากกลางวันเป็นกลางคืน คาดว่าอาจเกิดจากการที่ใน Dataset มี ภาพที่เป็นแสงไฟจากเมืองรถค่อนข้างมาก, ภาพจริงมีสะพานอยู่ แต่ภาพที่โมเดลสร้างขึ้นได้ลบสะพานให้กลายเป็นท้องฟ้า คาดว่าน่าจะเกิดจากการที่สะพานอยู่ซ้อนทับกับท้องฟ้าเลยอาจทำให้โมเดลคิดว่าสะพานเป็นส่วนหนึ่งของท้องฟ้า,\n",
      "- ใช้ FID score (Fréchet inception distance) ในการวัดคุณภาพ ในการ generate ภาพ FID score วัดได้โดยการนำรูปที่ generate หลายๆรูปกับภาพจริงจำนวนเท่ามาโยนเข้า inception v3 แล้วนำ distribution ของภาพจริงและภาพที่ generate มาเทียบกัน โดย FID ยิ่งน้อยเท่าไรก็นิ่งดีเท่านั้น; night-to-day FID = 75.68 vs day-to-night FID = 57.80 คาดว่าการเปลี่ยนภาพกลางวันเป็นกลางคืนนั้นเป็นการลดรายละเอียดของภาพซึ่งทำได้ง่ายกว่า night to day ที่เป็นการเพิ่มรายละเอียดของภาพ\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"10-7-22\"\n",
      "title: \"Music Recognition\"\n",
      "builder: \"นนทพรรษ วงษ์กัณหา (นน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/30/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Nonnyss/Ms-Wav2Vec2-Finetune\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/411804267654685\"\n",
      "blog: \"https://medium.com/@nonthapan.wong/music-recognition-a6c9acea23e1\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/30/01.jpg)\n",
      "\n",
      "- โมเดลถอดเสียงเนื้อเพลงภาษาไทย แรงบันดาลใจการเป็นคนที่ชอบฟังเพลง 🎶 แต่บางทีนึกชื่อเพลงไม่ออก จำได้แต่เนื้อเพลงบางท่อน หรือแม้กระทั่งเวลาไปคาเฟ่ ☕ ที่เปิดเพลงเพราะๆ ก็มักจะไม่รู้ว่าเพลงนั้นเป็นเพลงอะไร (ขี้อายไม่กล้าถามพนักงาน🥲),\n",
      "- เริ่มจากใช้ Wav2Vec2 ภาษาไทยเป็น baseline; โมเดลอาจทำได้ดีในบทสนทนาทั่วไป (speech-to-text) แต่ผลงานในการถอดเสียงเพลงไม่ดีนัก (sing-to-text) ทั้งจากการร้องสดและคลิปเพลง,\n",
      "- ใช้ข้อมูล 40 เพลงบน YouTube ตามยอดคนฟังเป็นความยาว 2.5 ชั่วโมง,\n",
      "- ทำความสะอาดด้วยการแยกเสียงเครื่องดนตรีจากเนื้อร้อง, ตัดเป็นคลิปเสียงคลิปละ 2-6 วินาทีด้วย Adobe Audition, คัดเนื้อร้องที่เป็นภาษาอังกฤษออก, และทำความสะอาดเครื่องหมายต่างๆ เช่น `จนผ่านวันร้ายๆ` ➜ `จนผ่านวันร้ายร้าย`; พบปัญหา เช่น เสียงร้องกลืนเข้าไปกับ BGM, เสียงคอรัสร้องหลายเนื้อร้องในเวลาเดียวกัน เป็นต้น ทำการคัดเลือกออก**ด้วยมือ**,\n",
      "- พบปัญหาเนื้อเพลงที่เป็นข้อความไม่ตรงกับเสียง; แก้ปัญหาด้วยการตัดมือแบ่งกับปืน เพื่อนในโครงการ,\n",
      "- เสียงมาจากนักร้องชาย 28 คน นักร้องหญิง 12 คน; แบ่ง train-validation-test เป็น 80:10:10,\n",
      "- มีข้อสังเกตว่าโมเดลที่ถูกเทรนบนเสียงนักร้องมืออาชีพจะสามารถถอดความเสียงมือสมัครเล่นที่ร้องเพี้ยนได้หรือเปล่า อาจจะพัฒนาเป็นโมเดลจับคนร้องเพี้ยนต่อไป,\n",
      "- ใช้ airesearch/wav2vec2-large-xlsr-53-th ที่ถูกเทรนบน Common Voice 7 เป็นโมเดลพื้นฐาน,\n",
      "- วัดผลด้วย WER (ตัดคำด้วย newmm ของ PyThaiNLP) และ CER; ทำได้ดีกว่า airesearch/wav2vec2-large-xlsr-53-th ประมาณ 3-4 เท่าบน test set\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"11-7-22\"\n",
      "title: \"vTranslator: Transcribe and Translate VTuber using Wav2Vec2\"\n",
      "builder: \"ธนภณ ทองจำนงค์ (ธันย์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/31/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/thunni-noi/vTranslator-prototype\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/412504900917955\"\n",
      "blog: \"https://medium.com/@thunninoi/vtranslator-vtuber-speech-recognition-with-wav2vec2-cba2e2c4a6df\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/31/01.jpg)\n",
      "\n",
      "- vTranslator คือสคริปต์ที่จะ generate ซับไตเติลของคลิปนั้นๆออกมาเป็นภาษาที่ต้องการ โดยเป็นการรวมกันระหว่างตัว Speech-Recognition Wav2Vec2 และตัว Google Translate เพื่อสร้างไฟล์ซับไตเติล (.srt) ขึ้นมา โดย model Wav2Vec2 ที่นำมาใช้นั้นจะถูก fine-tuned โดยใช้เสียงของ VTuber Hololive เป็นหลัก!,\n",
      "- แรงบันดาลใจจากการชอบดู VTuber แต่ไม่เข้าใจภาษาญี่ปุ่น ส่วนใหญ่ดูผ่านคนแปลตาม YouTube; อยากดูให้เข้าใจแบบถ่ายทอดสด,\n",
      "- ชุดข้อมูลหาจากคลิปสั้นๆของ Hololive ข้อดีคือมี timestamp ชัดเจน-ความยาวเหมาะแก่การเทรนโมเดล; ใช้คลิปจากช่องอื่นบางส่วนโดยการทำ OCR ด้วยมือ, \"\n",
      "- ทำความสะอาดช้อมูล เช่น ตัดการใช้อักษร/สัญลักษณ์เพื่ออธิบายสิ่งที่ตัวละครกำลังทำ-ส่วนใหญ่จะไม่มีเสียงพูด ( (^_^), (O.O), ฯลฯ ), สัญลักษณ์แสดงอารมณ์ ( :(, :D, ฯลฯ ), ลบไฟล์เสียงที่เปิดไม่ได้, เปลี่ยนตัวอักษรเป็น hiragana ทั้งหมดด้วย pykakasi\",\n",
      "- ใช้โมเดลพื้นฐาน ได้แก่ vumichien/wav2vec2-large-xlsr-japanese-hiragana (ปรับจูนบน Common Voice และ Japanese speech corpus of Saruwatari-lab) และ ttop324/wav2vec2-live-japanese (ปรับจูนบน Common Voice, JSUT, CSS10, TEDxJP-10K, JVS และ JSS),\n",
      "- การปรับจูนกับชุดข้อมูล VTuber ทำให้ได้ WER 0.1884\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"12-7-22\"\n",
      "title: \"Text-to-image synthesis with VQGAN-ThCLIP\"\n",
      "builder: \"ภูริช ศิริทิพย์ (มาร์ค)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/32/01.jpg\"\n",
      "links:\n",
      "github: \"https://colab.research.google.com/github/vikimark/VQGAN-ThCLIP/blob/master/Streamlit_VQGANxThaiCLIP.ipynb\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/413224897512622\"\n",
      "blog: \"https://medium.com/@phuritsiritip/%E0%B9%82%E0%B8%84%E0%B8%A3%E0%B8%87%E0%B8%81%E0%B8%B2%E0%B8%A3-ai-builders-%E0%B8%81%E0%B8%B1%E0%B8%9A-ai-%E0%B8%AA%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%87%E0%B8%A0%E0%B8%B2%E0%B8%9E%E0%B8%88%E0%B8%B2%E0%B8%81%E0%B8%82%E0%B9%89%E0%B8%AD%E0%B8%84%E0%B8%A7%E0%B8%B2%E0%B8%A1%E0%B8%AA%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%87%E0%B9%82%E0%B8%94%E0%B8%A2%E0%B9%80%E0%B8%94%E0%B9%87%E0%B8%81%E0%B8%A1%E0%B8%B1%E0%B8%98%E0%B8%A2%E0%B8%A1%E0%B8%9B%E0%B8%A5%E0%B8%B2%E0%B8%A2-%E0%B8%97%E0%B8%B5%E0%B9%88%E0%B9%80%E0%B8%81%E0%B8%B7%E0%B8%AD%E0%B8%9A%E0%B8%88%E0%B8%B0%E0%B8%82%E0%B8%B6%E0%B9%89%E0%B8%99%E0%B8%9B%E0%B8%B5-1-ed5878c7a72c\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/32/01.jpg)\n",
      "\n",
      "- โมเดลสร้างรูปภาพจากคำอธิบายภาษาไทยเพื่อสร้างภาพประกอบนิยาย เรื่องสั้น หรือบทความต่าง ๆ; เลือกใช้ VQGAN และ CLIP โดย VQGAN จะทำหน้าที่เป็นเสมือนผู้วาดรูปและ CLIP จะทำหน้าที่เป็นคนที่คอยกำกับรูปที่ VQGAN วาดว่าตรงกับข้อความที่เราวาดไปแค่ไหน,\n",
      "- CLIP เป็นโมเดลที่เป็นสะพานเชื่อมระหว่างรูปภาพกับข้อความโดยจะทำการ Embed ทั้งสองอย่างนี้ให้อยู่ใน latent space ขนาดเท่ากันจึงสามารถนำทั้ง Text embedding และ Image embedding มาเปรียบเทียบความเหมือนความต่างได้โดยใช้วิธีการทางคณิตศาตร์ต่าง ๆ CLIP จะประกอบไปด้วยโมเดลหลัก 2 ส่วนคือ Text encoder และ Image encoder,\n",
      "- VQGAN เป็นโมเดลประเภท Generative โดยจะประกอบไปด้วย Generator และ Discriminator โมเดลสองตัวนี้จะแข่งกันและพัฒนาตัวเองไปพร้อม ๆ กันจนในที่สุด Discriminator ไม่สามารถเอาชนะ Generator ได้ เราจึงจะนำ Generator ไปสร้างภาพต่อ นอกจากนี้ก่อนที่ทั้งสองโมเดลนี้จะแข่งกัน Generator จะได้เรียนรู้โครงสร้างของภาพที่ตัวเองจะสร้างไว้ก่อน เปรียบเสมือนมีสมุดเปล่าที่เอาไว้จดวิธีการสร้างสิ่งต่าง ๆ ลงไป,\n",
      "- เนื่องจากการจะสร้างรูปจาก VQGAN นั้นต้องมี Random input (กลุ่มตัวเลขแบบสุ่ม) ส่งเข้าไปให้ Generator จึงจะสร้างเป็นรูปต่าง ๆ ได้และแน่นอนว่าเราไม่สามารถรู้ได้ว่าการสุ่มแบบไหนจะให้รูปที่เราต้องการได้ จึงต้องใช้ CLIP คอยกำกับและค่อย ๆ เปลี่ยน Random input เหล่านี้ให้เป็นรูปที่เราต้องการ,\n",
      "- วิธี #1: เริ่มจากการเทรน CLIP ขึ้นมาเองใช้ข้อมูลเริ่มจาก flicker8k (8,000 รูป) ไปจนถึง flicker30k (30,000 รูป) แปลข้อมูล caption จากภาษาอังกฤษไปไทยด้วย PyThaiNLP; ใช้ resnet-50 เป็น image encoder และ WangchanBERTa เป็น text encoder (ThCLIP),\n",
      "- วิธีแรกยังไม่ได้ผลเป็นที่น่าพึงพอใจด้วยปัจจัยขนาดชุดข้อมูลและเวลาในการเทรน จึงทดลองวิธี knowledge distillation สำหรับ CLIP แทน,\n",
      "- วิธี #2: เทรนใหม่โดยการสอนให้ ThCLIP สร้าง text embeddings ให้คล้ายกับ OpenAI CLIP มากที่สุดตาม mean-squared error loss; ใช้ปริมาณข้อมูลน้อยกว่าและได้ผลดีกว่ามาก,\n",
      "- เทรนตามวิธี #2 ด้วยข้อมูล 2 ล้านรูป สุ่มจาก GCC, MSCOCO เหมือนของ SwedishCLIP,\n",
      "- จากการ \"ทดลอง ทดลอง ทดลอง\" พบว่า transform ภาพโดยสุ่มเพิ่มระดับ sharpness ให้กับภาพทำให้กราฟ Loss converge เร็วขึ้น, iteration ที่เหมาะที่สุดอยู่ระหว่าง 200–300 รอบ, รวมถึง:,\n",
      "- ใช้ negative prompt เพื่อพัฒนาคุณภาพรูปภาพได้ เช่น เมื่อสร้างภาพ \"เครื่องบิน\" ให้ \"ภาพเบลอ\" เป็น negative prompt (ใส่เข้าไปใน loss function) จะทำให้ได้ภาพเครื่องบินที่ชัดขึ้น,\n",
      "- ใช้ aesthetic-predictor จาก pretrained model ที่ประเมิน \"ความสวย\" ของรูป และให้ความสวยเป็นส่วนหนึ่งของ loss function; ทำให้รูปที่ออกมาสวยขึ้น,\n",
      "- ทดสอบประสิทธิภาพโมเดลด้วยแบบสอบถามจาก 27 คน พบว่า VGQAN-ThCLIP (โมเดลของเรา) ทำได้ดีกว่า VQGAN-CLIP (pretrained จาก OpenAI) เมื่อรูปภาพถูกสร้างจากข้อความสั้นทั้งด้านความสอดคล้องและความหลากหลาย แต่ยิ่งข้อความยาวทำได้ดีกว่าในด้านความสอดคล้องแต่ด้อยกว่าในด้านความหลากหลาย,\n",
      "- โมเดลสามารถทำ prompting ได้เหมือน text-to-image ชั้นนำทั่วไป เช่น \"คฤหาสน์\", \"คฤหาสน์ แฟนตาซี\", \"คฤหาสน์ แฮรี่พอตเตอร์\" ฯลฯ\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"13-7-22\"\n",
      "title: \"Game Recommendation by using Neural Network Embeddings\"\n",
      "builder: \"มาวิน ศรีชาติ (วิน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/33/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/kyou7797/Game-Recommendation\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/413880357447076\"\n",
      "blog: \"https://medium.com/@meow7747/%E0%B9%80%E0%B8%A1%E0%B8%B7%E0%B9%88%E0%B8%AD%E0%B9%80%E0%B8%81%E0%B8%A1%E0%B8%A1%E0%B8%B5%E0%B8%A1%E0%B8%B2%E0%B8%81%E0%B8%A1%E0%B8%B2%E0%B8%A2-%E0%B9%81%E0%B8%95%E0%B9%88%E0%B9%80%E0%B8%A3%E0%B8%B2%E0%B9%84%E0%B8%A1%E0%B9%88%E0%B8%A1%E0%B8%B5%E0%B9%80%E0%B8%A7%E0%B8%A5%E0%B8%B2%E0%B9%80%E0%B8%A5%E0%B9%88%E0%B8%99%E0%B9%80%E0%B8%81%E0%B8%A1-t-t-game-recommendation-a1598c50553f\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/33/01.jpg)\n",
      "\n",
      "- โมเดลแนะนำเกมด้วย neural collaborative filtering,\n",
      "- ใช้ชุดข้อมูลเกมใน Steam จาก 70,912 ผู้ใช้และ 10,947 เกมส์; ข้อมูลที่บ่งบอกความชอบคือเวลาที่ใช้ในการเล่น,\n",
      "- ทำการ normalize เวลาเล่นด้วย min-max scaling เนื่องจากบางเกมมีคอนเท้นท์ให้เล่นน้อย-เยอะ จึงใช้เวลาน้อย-เยอะกว่าเกมอื่นๆ,\n",
      "- ทำโมเดลด้วยเกมส์ที่มีคนเล่นอย่างน้อย 15 คนและผู้เล่นที่เล่นมาแล้วอย่างน้อย 10 เกมส์,\n",
      "- ปัญหาที่ผมเมื่อประเมินผลคือชุดข้อมูลไม่มี timestamp ทำให้ไม่สามารถประเมินด้วยการทำนายเกมส์สุดท้ายที่เล่นของแต่ละผู้ใช้เหมือน recommendation ทั่วไปได้; เลือกใช้วิธีสุ่มเกมส์มาหนึ่งเกมส์จากผู้ใช้ทุกคน แล้วทาย top-k accuracy (แนะนำ k เกมสำหรับผู้เล่นแต่ละคนใน validation set แล้วดูว่าเกมส์ที่สุ่มมาอยู่ใน k เกมส์นั้นหรือไม่),\n",
      "- โมเดลทำได้ดีกว่า rule-based baseline ที่ทายว่าทุกคนจะเล่นเกมค่าเฉลี่ยเวลาเล่น-เวลาเล่นรวมมากที่สุด k ลำดับ แต่แพ้ให้กับการทายว่าทุกคนจะเล่นเกมที่มีคนเล่นมากที่สุด k ลำดับ; จะเห็นได้ว่าอุตสากรรมเกมส์ค่อนข้างเป็น winners take all มีเพียงไม่กี่เกมเท่านั้นที่ผู้เล่นแทบทุกคนจะเล่น,\n",
      "- ทำ error analysis ด้วยการลองสมมุติว่าเกม top 1-10, 11-20, 21-30, ... ไม่มีอยู่จริง พบว่าโมเดลทำได้ใกล้เคียง rule-based baseline เกมที่คนเล่นมากที่สุดขึ้นเรื่อยๆ; คาดว่าโมเดลน่าจะมีประโยชน์ในการแนะนำเกมที่ไม่ค่อยเป็นที่นิยมมากนัก\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"14-7-22\"\n",
      "title: \"Chaos EDM: Generating EDM Song with VAE (Variational Autoencoder) Spectrogram\"\n",
      "builder: \"ณยศ สุวัฒโน (ไมค์กี้)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/34/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Mikey8943/EDM-spectrogram-vae\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/414621047373007\"\n",
      "blog: \"https://medium.com/@nayos.su/generating-edm-song-with-vae-variational-autoencoder-spectrogram-eb6dcd5fc4b8\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/34/01.jpg)\n",
      "\n",
      "- โมเดลแต่งเพลง EDM ด้วย Variational Autoencoder (VAE),\n",
      "- แรงบันดาลใจการความชื่นชอบเพลง EDM และโครงการที่ใช้ deep learning เข้ามาช่วยแต่งเพลงอย่าง Magenta Tensorflow,\n",
      "- สร้างชุดข้อมูลจาก EDM ประเภท (genre) Hardcore (ดูประเภทของ EDM ทั้งหมดที่ https://music.ishkur.com/) เนื่องจากได้รับความนิยมสูง โดยใช้คลิปจาก YouTube,\n",
      "- เลือกเพลงที่มีเสียงคนร้องเพลงไม่เกินร้อยละ 60 ของความยาวเพลง, หากมี voice sample แต่ยังมีช่วงที่มี beat หรือ melody เล่นอยู่ด้วยก็พอปล่อยผ่านได้, ทั้งเพลงควรมีความคงที่ของ BPM(Beat per minute) และ Time Signature หรือไม่ได้มีการเปลี่ยนแปลงที่ไม่บ่อยจนเกินไป; ได้เพลงที่ผ่านการทำความสะอาด 1,090 เพลงรวมเวลา 71.8 ชั่วโมง,\n",
      "- ใช้สถาปัตยกรรม Variational Autoencoder (VAE) เพื่อเรียนรู้การสร้าง spectogram ของเพลง EDM,\n",
      "- ประเมินคุณภาพด้วย mean opinion score (MOS) จากแบบสอบถาม คน ด้านความชัดเจนของ beat โดยรวม (2.67/5), ความชัดเจนของ melody โดยรวม (2.69/5) และความพึงพอใจโดยรวม (2.77/5),\n",
      "- มองแนวทางพัฒนาด้วยการเทรนให้นานขึ้น-ข้อมูลมากขึ้น, ใช้ช่วง climax ที่เมโลดี้ชัดเจนเทรน และลองสถาปัตยกรรมใหม่ๆ,\n",
      "- อัลบั้ม The Final of Chaos? (น่าจะ) เป็นอัลบั้ม EDM ที่สร้างโดยปัญญาประดิษฐ์แรกของไทย ลองฟังกันได้ที่: https://soundcloud.app.goo.gl/17SThr5PisKCFaZC6\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"15-7-22\"\n",
      "title: \"WanchanBERTa Thai Grammarly\"\n",
      "builder: \"อิทธิพัฒน์ ปานขำ (มาร์จิ้น)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/35/01.jpg\"\n",
      "links:\n",
      "github: \"https://colab.research.google.com/github/bookpanda/WanchanBERTa-Thai-Grammarly/blob/main/demo.ipynb\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/415235220644923\"\n",
      "blog: \"https://medium.com/@marginpankam/wanchanberta-thai-grammarly-5010671797c7\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/35/01.jpg)\n",
      "\n",
      "- โมเดลแก้การสะกดคำภาษาไทยด้วยเทคนิค tagging and masking โดยอาศัย WangchanBERTa เป็นโมเดลพื้นฐาน,\n",
      "- ปรับจูบนชุดข้อมูล VISTEC-TP-TH-2021 (https://github.com/mrpeerat/OSKut/blob/main/VISTEC-TP-TH-2021) ประกอบด้วยการสะกดคำผิด เช่น ตัวอักษรซ้ำ; มากกกกกก (มาก), รักๆๆๆๆ (รัก ๆ), ไม้ยมกโดยไม่เว้นช่องว่า; ขอบคุณๆ (ขอบคุณ ๆ), คำย่อโดยไม่มีจุด; มิย (มิ.ย.), วรรณยุกต์หาย; แป๊ป (แปป), พิมพ์ตก; อุหนุน (อุดหนุน), จงใจพิมพ์ผิด; นะ (น้า), ณ๊อง (น้อง), พิมพ์ไม่ครบ; อลัง (อลังการ), แบต (แบตเตอรี) เป็นต้น รวม 42,893 ประโยคที่มีการสะกดผิด,\n",
      "- ทำความสะอาดข้อมูลโดย เปลี่ยนรูปแบบประโยคจาก \"สวัสดี|<msp value=”ครับ”>ค้าบ</msp>|พี่|<ne>จอม</ne>\" เป็น \"สวัสดี^ครับ$พี่จอม\", เพิ่ม token สำหรับคำที่สะกดถูกเพื่อให้สามารถเติมคำได้ใน token เดียว, หาก token ที่สะกดผิดมีมากกว่าที่สะกดถูก ให้เติม _ ไปให้ครบเท่ากัน,\n",
      "- ทดลองใช้ hunspell, seq2seq และ tagging and masking,\n",
      "- tagging and masking ทำได้ดีที่สุด; โมเดลทำงานด้วยการชี้เป้า token ที่สะกดผิด (tagging; token classification) แล้วแทนที่ด้วย mask token จากนั้นให้โมเดลเดาว่า mask นั้นควรจะเป็นอะไร (masking),\n",
      "- ได้ accuracy 28.1% / F1 score 0.256 เทียบกับ hunspell และ seq2seq ที่แทบทายไม่ถูกเลย; ถ้าดูจาก BLEU รายประโยค จาก 1,000 ประโยคใน test set โมเดล tagging and masking แก้ถูก 386 ประโยค\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"16-7-22\"\n",
      "title: \"Garbage Detection with Tensorflow Lite\"\n",
      "builder: \"กันต์พัจน์ วิเศษสุข (กัน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/36/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/24GUNV/aibuilders/tree/main/object_detection/images\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/415865783915200\"\n",
      "blog: \"https://medium.com/@24progun/object-detection-using-tensorflow-lite-80da8d75c03b\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/36/01.jpg)\n",
      "\n",
      "- โมเดลคัดแยกประเภทขยะจากรูปภาพแบบ real-time ด้วย Tensorflow Lite; แยกลัง, แก้ว, โลหะ, กระดาษ และพลาสติก,\n",
      "- เลือกใช้ Tensorflow Lite เนื่องจากต้องการ deploy ลง OrangePi; ต้องการความแม่นยำประมาณ 70-80% เพื่อให้ใช้งานได้จริง,\n",
      "- ใช้ข้อมูลจาก asdasdasasdas/garbage-classification, mostafaabla/garbage-classification แล้วนำมา annotate เองเพื่อทำ object detection ได้เป็น training set (1,554 รูป), validation set (170 รูป) และ test set (170 รูป),\n",
      "- ชุดข้อมูลที่ annotate เองเปิดให้ใช้เป็นสาธารณะที่ https://github.com/24GUNV/aibuilders/tree/main/object_detection/images ; แบ่งเป็นลัง (325 รูป), แก้ว (406 รูป), โลหะ (433 รูป), กระดาษ (199 รูป) และพลาสติก (191 รูป),\n",
      "- เลือกใช้สถาปัตยกรรม EfficientDet-Lite0 เพื่อ latency ที่ดีที่สุด; ได้ AP 76.6% บน test set,\n",
      "- สามารถทดลองใช้แบบ real-time ได้บน streamlit cloud; ใช้ OpenRelay เพื่อเชื่อม streamlit กับ webcam ของผู้ใช้\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"17-7-22\"\n",
      "title: \"Sick Pig Classifier\"\n",
      "builder: \"ภวัต ลีชาแสน (บีม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/37/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Igonazio/Sick-Pig-Classifier\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/416533550515090\"\n",
      "blog: \"https://medium.com/@beamsisb/sick-pig-classifier-394db89c3c5d\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/37/01.jpg)\n",
      "\n",
      "- โมเดลแยกแยะรูปหมูป่วยด้วย ResNet-18; แรงบันดาลใจจากข่าวโรคอหิวาต์แอฟริกาในสุกร (African swine fever : ASF) ระบาดช่วงต้นปี 2022,\n",
      "- ต้องการโมเดลที่ขนาดเล็กสามารถใช้งานได้ง่าย และมีความแม่นยำเพียงพอในการทุ่นแรงมนุษย์ โดยอาจไม่แม่นยำเท่ามนุษย์เนื่องจากการวินิฉัยโรคใช้มากกว่าการมองเห็น,\n",
      "- สร้างชุดข้อมูลจากการ scrape รูปจากอินเตอร์เน็ต; พบปัญหารูปหมูป่วยหาได้ยาก และรูปหมูไม่ป่วยบางครั้งมีรูปที่ไม่เกี่ยวข้อง เช่น การ์ตูน Peppa Pig ติดมาด้วย; ได้รูปหมูป่วยทั้งหมด 141 รูป หมูไม่ป่วย 370 รูป,\n",
      "- ResNet-18 ได้ผลดีที่สุดบน test set จำนวน 154 รูป ได้ micro-averaged F1 ที่ 0.84; เทียบกับ baseline การทายว่าทุกตัวไม่ป่วยที่ 0.82 (แน่นอนว่าในกรณีนี้ recall ของหมูป่วยเป็น 0) และ CNN ที่ 0.63,\n",
      "- โมเดลที่ดีที่สุดมี recall (จำนวนหมูป่วยที่ทายถูก / จำนวนหมูป่วยทั้งหมด) สูงถึง 0.88 ซึ่งน่าจะเพียงพอสำหรับการช่วยคนเฝ้าระวังในฟาร์ม,\n",
      "- จำเป็นต้องทดลองกับภาพจริงในฟาร์ม เพื่อพัฒนาสู่ระบบใช้งานจริง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"18-7-22\"\n",
      "title: \"NLP for genre predictions on FFnet: an antithesis to utilitarianism\"\n",
      "builder: \"zeiosis@\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/38/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/zeiosis/ffnet-summary-prediction\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/417209980447447\"\n",
      "blog: \"https://medium.com/@cryingptosis/nlp-for-genre-predictions-on-ffnet-an-antithesis-to-utilitarianism-4380524ca1fc\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/38/01.jpg)\n",
      "\n",
      "- โมเดลจำแนก genre ของ fan fiction จากบทคัดย่อด้วย BERT; แรงบันดาลใจคืออยากสร้างระบบแท้กอัตโนมัติให้ AO3 (ao3.org) เพราะแท้กปัจจุบันสร้างโดยผู้ใช้และคุณภาพไม่ค่อยดี,\n",
      "- เลือก scrape ข้อมูลจาก FFNet (fanfiction.net) เพื่อเป็นชุดข้อมูล เนื่องจากแท้กใน FFNet นั้นคุณภาพเสมอต้นเสมอปลายกว่าและอนุญาตให้ใส่เพียง 2 แท้กต่อเรื่อง,\n",
      "- เนื่องจากหนึ่ง fan fiction โดยทั่วไปแล้วมีมากกว่าหนึ่งแท้กจึงเลือกทำการวัดผลด้วย accuracy metric ที่ิคิดขึ้นเองคือ (% เรื่องที่มี 2 แท้กและทายถูกทั้ง 2 แท้ก) + 1/2 * (% เรื่องที่มี 1 แท้กและทายถูก) + 1/2 * (% เรื่องที่มี 2 แท้กแต่ทายถูกแค่ 1 แท้ก),\n",
      "- เขียนสคริปท์สำหรับ scrape FFNet ขึ้นมาเองเนื่องจากไม่มี API อย่างเป็นทางการโดยเลือกเฉพาะเรื่องที่เป็นภาษาอังกฤษ, K->T-rated, เรื่องที่จบแล้ว และมาจากต้นฉบับที่มีงาน fan fiction อย่างน้อย 50k เรื่อง,\n",
      "- พบว่ามีเพียง 8 genre หลักที่มีคนใช้เป็นแท้กคือ Romance, Humor, Drama, Hurt_Comfort, Adventure, Family, Angst, Friendship; แท้กมีความไม่สมดุลโดยเฉพาะ Romance ที่มีเยอะกว่าแท้กอื่นมาก,\n",
      "- เทรนโมเดลเปรียบเทียบกับ pretrained หลาย iteration เช่น bart-large-mnli, distilbert-base-uncased-mnli และ distilbart-mnli-12-1; โมเดลที่ดีที่สุดได้ค่า accuracy ตามวิธีคิดด้านบนที่ 0.437 เทียบกับ baseline ที่ 0.269\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"19-7-22\"\n",
      "title: \"AI แยกแยะแมงดาจาน กับ แมงดาถ้วย\"\n",
      "builder: \"ภัคพล อาจบุราย (หลุยส์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/39/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/alicelouis47/maengda-classification-detection\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/417931133708665\"\n",
      "blog: \"https://medium.com/@phakkhaphonartburai/ai-%E0%B9%81%E0%B8%A2%E0%B8%81%E0%B9%81%E0%B8%A2%E0%B8%B0%E0%B9%81%E0%B8%A1%E0%B8%87%E0%B8%94%E0%B8%B2%E0%B8%88%E0%B8%B2%E0%B8%99-%E0%B8%81%E0%B8%B1%E0%B8%9A-%E0%B9%81%E0%B8%A1%E0%B8%87%E0%B8%94%E0%B8%B2%E0%B8%9E%E0%B8%B4%E0%B8%A9-784bf470c592\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/39/01.jpg)\n",
      "\n",
      "- ในปัจจุบันการรับประทานยำไข่แมงดาได้รับความนิยมมากขึ้น จึงทำให้เกิดปัญหาที่ว่าร้านนำแมงดาที่มีพิษ(แมงดาถ้วย หรือแมงดาเหรา)นำมาปรุงอาหาร และขาย ซึ่งเกิดจากการเข้าใจผิด อาจทำให้ส่งผลต่อชีวิตได้ ผมจึงได้มีความสนใจที่จะสร้าง Application ในการแยกแยะประเภทของแมงดาจาน(กินได้) กับ แมงดาถ้วย(มีพิษ กินไม่ได้) เพื่อช่วยการตัดสินใจก่อนทำอาหาร เพื่อความปลอดภัยในการรับประทาน,\n",
      "- เก็บชุดข้อมูลจาก DuckDuckGo Image Search API; เริ่มแรก scrape ได้กว่า 1,000 รูปแต่คุณภาพไม่ดีจึงคัดเลือกด้วยมือและหาเพิ่มจนได้ชุดข้อมูลสุดท้ายที่แมงดาถ้วย 224 รูปและแมงดาจาน 226 รูป แบ่ง train-test split ที่ 85:15,\n",
      "- สร้าง annotation สำหรับ object detection ด้วยมือผ่านโปรแกรม LabelImg,\n",
      "- ปรับจูนโมเดลจากสถาปัตยกรรม VGG16, VGG19, AlexNet, ResNeXt50, DenseNet201 ครั้งแรกพบว่าผลบน test set ค่อนข้างแย่,\n",
      "- พบว่าโมเดลมีความสับสนระหว่างด้านหน้าและด้านหลังของแมงดา จึงทำโมเดลแยกสำหรับหน้า-หลัง; ได้ความแม่นยำสูงในการทายด้านหน้า-หลัง (F1 ~0.9),\n",
      "- หลังจากแยกแยะด้านหน้า-หลังแล้ว ใช้อีกโมเดลแยกประเภทซ้ำ (multi-model approach) ได้ผลดีขึ้น ด้านหน้า (F1 ~0.83) และ ด้านหลัง (F1 ~0.70); โมเดลที่ทำได้ดีที่สุดได้ผลในการจำแนกชนิดแมงดาโดยรวมสูงถึง F1 0.92,\n",
      "- โมเดลสุดท้ายคือ 1) object detection ทำนายว่าแมงดาอยู่ไหน 2) โมเดลทำนายว่าด้านหน้า-ด้านหลัง 3) ทำนายชนิดแมงดา,\n",
      "- ทดสอบเทียบกับมนุษย์ด้วยแบบสอบถามและรูป 16 รูป พบว่าโมเดลทำได้ดีกว่า (F1 0.89 vs 0.74); จำนวนตัวอย่างเล็กมาก ตีความอย่างระมัดระวัง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"20-7-22\"\n",
      "title: \"Is that a Supra?!\"\n",
      "builder: \"จิตรบุณย์ ทรัพย์สินทวีลาภ (กั๊ต)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/40/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/BikiniGordon/Is-that-a-Supra\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/418635413638237\"\n",
      "blog: \"https://medium.com/@gatchanminecraft/is-that-a-supra-thai-version-405cb2231f2b\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/40/01.jpg)\n",
      "\n",
      "- โมเดลแยกรุ่นรถโตโยต้าจากรูปภาพรวม 36 รุ่นที่เป็นที่นิยมในประเทศไทย; แรงบันดาลใจจากคุณพ่อผู้เป็นอดีตวิศวกรโตโยต้า นั่งรถไปด้วยกันแล้วถามชื่อรุ่น บางครั้งคุณพ่อตอบไม่ได้เนื่องจากเป็นรถรุ่นใหม่หลังจากที่คุณพ่อออกจากบริษัทแล้วจึงมึความคิดว่า “ถ้าเรามีระบบที่เราสามารถโยนรูปไป แล้วระบบตอบกลับมาเป็นชื่อรุ่นเลยก็คงจะดี”,\n",
      "- เริ่มจากการใช้ชุดข้อมูลที่จัดทำโดย Occulta Insights บน Kaggle ประกอบด้วยรถ 38 รุ่น แต่มีรุ่นที่เป็นที่นิยมในประเทศไทยน้อย เช่น Vios มีเพียง 141 รูป และไม่มีการแยกรุ่นย่อย เช่น yaris ativ หรือ corolla altis,\n",
      "- ทำความสะอาดข้อมูล ประเภทรูปที่ไม่ได้ใช้คือ รูปภายในรถ, รูปเครื่องยนต์รถ, รูปที่เจาะจงเฉพาะบางส่วนมากเกินไป และรูปรถคนละรุ่น; มีรูปที่คัดออกทั้งหมด 2,203 จากประมาณ 16,000 รูป หรือประมาณ 13.5% ของจำนวนรูปภาพทั้งหมด,\n",
      "- แบ่งข้อมูลเป็น train-validation-test ที่ 70-15-15; เริ่มเทรนด้วยการปรับจูน resnet34 (freeze 1 epoch; unfreeze 5 epochs) ได้ balanced accuracy 57%; พบว่ารุ่นที่มีรูปน้อย เช่น estima, revo และ rush ทำให้ได้ผลแย่,\n",
      "- แก้ปัญหาด้วยความรู้เกี่ยวกับรถโตโยต้า ได้แก่ 1) ยุบ revo รวมกับ hilux เนื่องจากเป็นรุ่นเดียวกัน 2) ใช้ DuckDuckGo Image Search API หารูปมาเพิ่มสำหรับรุ่นที่มีรูปน้อย 3) ตัด previa ออกเนื่องจากเป็นรุ่นเดียวกับ estima ต่างกันเพียงแค่โซนยุโรปกับเอเชีย 4) ตัด avalon ออก เนื่องจากหน้าตาคล้าย camry และมีขายเพียงแค่ในสหรัฐอเมริกา 5) เพิ่มรูปด้านหลังของ avanza เข้าไปเนื่องจากเดิมมีรูปน้อย 6) เนื่องจาก celica, crown, corona รุ่นเก่าจะมีหน้าตาคล้ายกันมาก จึงเลือกเฉพาะ celica 6-7th generation, crown 12-15th generation ที่ยังมีวิ่งให้เห็นตามท้องถนนเท่านั้น 7) หารูป hilux เพิ่ม 8 ) ตัด vitz ออกเนื่องจากเป็นเพียง yaris ดัดแปลงเล็กน้อย มีขายเฉพาะในญี่ปุ่น 9) เพิ่ม wish ที่มีความนิยมสูงในไทย 10) ตัด vios 3rd generation ออกเนื่องจากโครงเหมือน yaris ativ 10) ตัด verso ออกเนื่องจากไม่มีขายในไทย 11) เพิ่ม c-hr และ sienta ที่เป็นที่นิยมในไทย,\n",
      "- จากการแก้ปัญหาแบบ data centric ทั้งหมดด้านบนทำให้ได้ balanced accuracy เพิ่มเป็น 89% จาก 36 รุ่น\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"21-7-22\"\n",
      "title: \"Microplastic detection and collect statistical tebular data.\"\n",
      "builder: \"ภานุวัฒน์ วงศ์พัฒนวุฒิ (ก้อง)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/41/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/kongonggong\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/419222536912858\"\n",
      "blog: \"https://medium.com/@kongwongpattanawut_61910/microplastic-detection-and-collect-statistical-tebular-data-8d09339e79d\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/41/01.jpg)\n",
      "\n",
      "- โมเดล object detection คัดแยก microplastic ในน้ำ แยกเป็น fragment, pellet, film, foam และ fiber,\n",
      "- เก็บตัวอย่างมาจากแหล่งน้ำต่างๆในจังหวัดมุกดาหาร 6 แหล่ง และนำมาถ่ายในไมโครสโคป ยี่ห้อ Olympus CX23 กำลังขยายเลนส์ใกล้ตา 10x ใกล้วัตถุ 4x; เป็น training set 174 ภาพและ validation set 75 ภาพ,\n",
      "- เพิ่มรูปและแก้ไข class imbalance (pellet และ fiber เยอะกว่าประเภทอื่นมาก) ด้วยการพลิกรูปบน-ล่าง,\n",
      "- ใช้ YOLO v5l (latency น้อยกว่า) และ v5x (ประสิทธิภาพสูงกว่า); ได้ mAP[0.05:0.95] ประมาณ 0.54\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"22-7-22\"\n",
      "title: \"Debunker: ML ตรวจจับข่าวลวง\"\n",
      "builder: \"นิธิวัฒน์ สิริรัตนชัยกุล (ตง)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/42/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/nitsirs/debunker\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/419846963517082\"\n",
      "blog: \"https://medium.com/@nitsirs/detecting-thai-fake-news-with-machine-learning-5c1bb3430bf3\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/42/01.jpg)\n",
      "\n",
      "- โมเดลแยกแยะข่าวปลอมประเภทสาธารณสุข,\n",
      "- ใช้ข้อมูลข่าวจริง (2,081 ข่าว) และข่าวเท็จ (2,570 ข่าว) จากชุดข้อมูล LimeSoda (ไม่ใช้ข่าวที่ยังไม่ได้รับการยืนยัน); พยายามหาข้อมูลจากแหล่งอื่นด้วย OCR แล้วแต่ไมไ่ด้ผลดีเท่าที่ควร,\n",
      "- ทดลองกับ WangchanBERTa และ Linear/LSTM head โดยมีและไม่มี backtranslation ได้ผลดีประมาณ F1 0.89-0.91,\n",
      "- พบว่าโมเดลที่ทำได้ดีที่สุดในบริบทการแยะแยะประโยคสั้นๆเช่นกรณีนี้คือ tf-idf + SVM ที่ F1 0.92,\n",
      "- ใช้ LIME เพื่อทำ error analysis ว่าโมเดลใช้อะไรตัดสินว่าเป็นข่าวปลอม ข้อสรุปคือสำหรับโมเดลที่ใช้ keyword ในการแยะแยะเช่น tfidf + SVM นั้นการมี keyword ที่ปรากฎบ่อยในข่าวปลอมอาจจะส่งผลให้โมเดลผิดพลาด เช่น รักษามะเร็ง ลูกหลานของเรา ฯลฯ\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"23-7-22\"\n",
      "title: \"Brain Tumor Segmentation using SegResNet\"\n",
      "builder: \"ณัฐวดี ลีภัทรกิจ (กิ่งแก้ว)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/43/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Kkingssss/Brain-Tumor-Segmentation/tree/main\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/420395566795555\"\n",
      "blog: \"https://medium.com/@nattawadee.lee/brain-tumor-segmentation-using-swin-unet-transformers-d003cbe7ba0f\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/43/01.jpg)\n",
      "\n",
      "- โมเดล image segmentation สำหรับเนื้องอกในสมองจากภาพ MRI เพื่อเป็นการช่วยเหลือการทำงานของบุลคลากรทางการแพทย์ทั้งในด้านของเวลาและภาระหน้าที่; การที่จะได้เนื้องอกและปริมาตรของเนื้องอกสมองที่แม่นยำ จะเป็นต้องใช้ผู้เชี่ยวชาญในการระบายสี ภาพสแกนสมอง ซึ่งบางครั้งหากต้องการความแม่นยำสูงอาจต้องใช้มากกว่า 15 นาทีต่อภาพ,\n",
      "- เทรนบนข้อมูล Brain Tumor Segmentation (BraTS) challenge 2021 และใช้ fold 1 สำหรับ validation; ข้อมูลเป็นรูปภาพ 3D ของสมอง (1251 Training / 219 Validation),\n",
      "- ใช้สถาปัตยกรรม SegResNet ที่เป็น encoder-decoder CNN แบบไม่สมมาตร encoder จะเป็นส่วนที่มี ขนาดใหญ่กว่าเพื่อใช้ในการ สกัดฟีเจอร์ของภาพ และ decoder ขนาดเล็กกว่า เพื่อใช้ในการสร้างภาพกลับและตัดชิ้นส่วน,\n",
      "- เปรียบเทียบกับ Swin U-Net Transformers; วัดผลด้วย dice coefficient (พื้นที่ที่ทับซ้อนกันระหว่างจุดที่เป็นเนื้องอกจริงและถูกที่ทำนายว่าเป็นเนื้องอก / พื้นที่ที่เป็นเนื้องอกทั้งหมดทั้งที่เป็นจริงและที่โมเดลทำนาย),\n",
      "- SegResNet ได้ผลดีกว่าที่ 0.8719 แต่มีข้อจำกัดทางทรัพยากรทำให้เทรน Swin U-Net Transformers ได้เพียง 70 epochs (คาดว่าอาจต้องใช้ถึง 600 epochs) ได้ average dice coefficient ที่ 0.7592 (ผู้ชนะการแข่งขันจาก BraTS 2021 ได้ 0.9294)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"24-7-22\"\n",
      "title: \"Classical Music Generator\"\n",
      "builder: \"มณิสรา แซ่จัน (ฟิล์ม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/44/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/ManissaraZ0/AI-Builders-Deploy\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/421598560008589\"\n",
      "blog: \"https://medium.com/@manissara2548/classical-music-generator-d9fc911abc9c\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/44/01.jpg)\n",
      "\n",
      "- โมเดลแต่งเพลงคลาสสิคด้วย autoregressive LSTM,\n",
      "- แรงบันดาลใจคืออยากมีเพลงที่ทำขึ้นมาไม่ซ้ำใครและเป็นของเราเอง แต่เราไม่จำเป็นต้องเล่นดนตรีด้วยตัวเอง,\n",
      "- เลือกดนตรีคลาสสิคเนื่องจากมีไฟล์ MIDI ที่แสดงข้อมูลทางดนตรี (duration, pitch, step) ไว้เพียงพอแก่การเทรน,\n",
      "- ใช้ข้อมูลทั้งหมดจาก http://www.piano-midi.de/,\n",
      "- ใช้ LSTM 1 layer เพื่อทำนาย pitch (โน้ตมี 128 ชนิด), duration (ระยะเวลาที่กดโน้ต) และ step (ระยะห่างจากโน้ตตัวหน้า)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"25-7-22\"\n",
      "title: \"Lamiaceae Classification แยกพืชวงศ์กะเพรา 3 ชนิด\"\n",
      "builder: \"วชิรวิทย์ ไชยมาตย์ (เจ้านาย)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/45/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/KaiZer003/LamiaceaeClassify\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/424327439735701\"\n",
      "blog: \"https://medium.com/@wachirawit003/image-classification-%E0%B9%80%E0%B9%80%E0%B8%A2%E0%B8%81%E0%B8%9E%E0%B8%B7%E0%B8%8A%E0%B8%A7%E0%B8%87%E0%B8%A8%E0%B9%8C%E0%B8%81%E0%B8%B0%E0%B9%80%E0%B8%9E%E0%B8%A3%E0%B8%B2-3-%E0%B8%8A%E0%B8%99%E0%B8%B4%E0%B8%94-480b9b823d85\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/45/01.jpg)\n",
      "\n",
      "-  พืชวงศ์กระเพราหรือ Lamiaceae มีลักษณะคล้ายคลึงกันมากจนบางครั้งมนุษย์แยกไม่ออก นำมาซึ่งแรงบันดาลใจในการทำโมเดลแยกกะเพรา โหระพา และแมงลักจากรูป,\n",
      "- วัดผลเทียบกับมนุษย์ 20 คน (ครู 4 นักเรียน 16) ด้วย mini-validation set 30 รูป (พืชชนิดละ 10 รูป) มี accuracy เฉลี่ยที่ 52.16%; ทำได้ดีที่สุด 76.66% (นักเรียน) และ73.33% (นักเรียน),\n",
      "- รวบรวมข้อมูลด้วยการถ่ายภาพเอง ระหว่างทางพบชุดข้อมูลกะเพรา-โหระพาจาก TAUTOLOGY-EDUCATION Tautology Thailand; แบ่ง test set 20% (177 รูป),\n",
      "- เลือกทำ data augmentation เช่น zoom, lighting, affine transformation ด้วย fastai,\n",
      "- ทดสอบกับสถาปัตยกรรม GoogLeNet, ResNet-152 และ VGG-19 พบว่า GoogLeNet ได้ผลดีที่สุดที่ accuracy 95%; resnet152 และ vgg19 ยังมีความสับสนระหว่างโหระพาและแมงลักอยู่เล็กน้อย,\n",
      "- เทียบกับมนุษย์บน mini-validation set โมเดลทำได้ 86.66% เทียบกับมนุษย์ที่เก่งที่สุดที่ 76.66%,\n",
      "- ข้อจำกัดของโมเดล ด้วยปริมาณข้อมูลเเละวิธีการเก็บ ทำให้เกิดข้อจำกัดหลายส่วน คือ 1.เก่งกับใบมากกว่าต้น 2.ความเเม่นยำต่ำเมื่อนำไปใช้กับภาพที่มีสภาพเเวดล้อมเป็นพื้นหลัง 3.ข้อมูลที่ใช้เทรนได้มาจากผักตามตลาดทำให้โมเดลไม่เก่งกับภาพพืชที่ได้รับความเสียหายจากสภาพเเวดล้อม 4.ต้องโฟกัสภาพเพื่อให้เห็นรายละเอียดของใบชัดเจนก่อน เพื่อให้โมเดลมีประสิทธิภาพสูงสุด,\n",
      "- ลองใช้ชุดข้อมูลได้ที่ https://drive.google.com/drive/folders/1hmc1Io_lg4_Q3fMqsmSPD9XpsBZ93FmJ?usp=sharing\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"26-7-22\"\n",
      "title: \"สร้างสรรบทเพลง Undertale ผ่าน LSTM และ Teacher Forcing RNN\"\n",
      "builder: \"นพวิทย์ ตันติศิริวัฒน์ (ภีม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/46/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Noppawit-Tantisiriwat/AIB2022-Undertale-Music-Generation\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/424934103008368\"\n",
      "blog: \"https://medium.com/@noppawitpeam/%E0%B8%AA%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%87%E0%B8%AA%E0%B8%A3%E0%B8%A3%E0%B8%9A%E0%B8%97%E0%B9%80%E0%B8%9E%E0%B8%A5%E0%B8%87-undertale-%E0%B8%9C%E0%B9%88%E0%B8%B2%E0%B8%99-lstm-%E0%B9%81%E0%B8%A5%E0%B8%B0-teacher-forcing-6053a939bc62\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/46/01.jpg)\n",
      "\n",
      "- โมเดลแต่งเพลงประกอบเกม Undertale ด้วย RNN ที่ถูกเทรนด้วยเทคนิค Teacher Forcing,\n",
      "- ในวัยเด็กผมเคยมีประสบการณ์เล่มเกมที่มีชื่อว่า Undertale มันเป็นเกมที่มีเนื้อเรื่องแปลกใหม่ ระบบการเล่นที่สนุก และที่สำคัญที่สุด มันมีเพลงประกอบตัวเกมที่ไพเราะเกินบรรยาย เพลงประกอบเกมนี้ได้กวาดรางวัลมาแล้วมากมาย ขายเป็นแผ่นเสียงได้เป็นกอบเป็นกำและได้ถูกจัดแสดงบนเวทีระดับโลกมาแล้ว ตัวผมจึงอยากลองค้นหาความมหัศจรรย์ของบทเพลงเหล่านี้ ทว่าผมขาดความรู้และพรสวรรค์ทางด้านดนตรีจึงไม่สามารถเข้าใจความสัมพันธ์ของบทเพลงเหล่านี้ได้ ผมจึงลองศึกษาศาสตร์AI ในการวิเคราะห์ความสัมพันธ์เหล่านี้ดู,\n",
      "- ใช้ dataset ที่เป็น MIDI ของเพลงเกม Undertale จาก Kaggle,\n",
      "- พบปัญหาว่า 1) มีเครื่องดนตรีเล่นพร้อมกันหลาย track ใน 1 file midi ทำให้ยากต่อการเลือก track ที่มีความสำคัญมากที่สุด 2) resolution (โน้ตถูกแบ่งเป็นกี่ส่วน) ที่กระจายตัวหลากหลาย ค่า resolution ที่มากทำให้สามารถอ่านข้อมูลได้ช้า และสิ้นเปลืองพื้นที่หน่วยความจำ,\n",
      "- แก้ปัญหาโดยการปรับ resolution ให้เป็น 96 ทั้งหมด (เพิ่ม tempo เป็นการทดแทน) และแปลงไฟล์midi ให้เหลือเพียง 1 track และมีเพียง 1 เสียงเครื่องดนตรีด้วย pianoroll (แล้วค่อยเปลี่ยนกลับเป็น MIDI อีกรอบ),\n",
      "- ใช้สถาปัตยกรรม LSTM (1-3 ชั้น), BiLSTM (3 ชั้น) และทดลองเทคนิค warm-start (เทรนต่อจากโมเดลคล้ายคลึงกัน) และ teacher forcing,\n",
      "- teacher forcing เป็นเทคนิคที่ใช้ ground truth เป็น input ให้กับ RNN (ในที่นี้คือ LSTM) ในหน่วยถัดไปแทนที่จะเป็น output จากหน่วยก่อนหน้า,\n",
      "- วัดผลด้วยแบบสอบถามและคำนวณ mean opinion score; พบว่า WarmStart + BiThreeFold (BiLSTM 3 ชั้นและ warm start; 3.68), WarmStart (warmstart + teacher forcing; 3.59), BiThreeFold (BiLSTM 3 ชั้น; 3.34) และ Toby (LSTM 1 ชั้น; 3.30) ทำคะแนนได้ดีกว่าเพลงจริง (2.80) เสียอีก(!!) ทั้งนี้การประเมินผลอาจจะมี bias เนื่องจากความหลากหลายและประสบการณ์ของผู้ทำแบบสอบถาม,\n",
      "- โมเดลไม่สามารถเรียนรู้จังหวะ, ความยาวของโน๊ต และไม่สามารถแต่งเพลงที่มีความหลากหลายของจังหวะได้ อาจจะส่งผลต่อความรู้สึกต่อคุณภาพของเพลงของผู้ตอบแบบสอบถาม เนื่องจากว่าความไพเราะของเพลงมีเรื่องจังหวะและทำนองเข้ามาเกี่ยวข้องด้วย,\n",
      "- โมเดลอาจจะ overfit บทเพลงและยังไม่สามารถแต่งเพลงให้หลากหลายตามอารมณ์ได้; อาจต้องแยกเทรนตามอารมณ์ของเพลง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"27-7-22\"\n",
      "title: \"Plant Disease Classification\"\n",
      "builder: \"รัชชานนท์ มุขแก้ว (นนท์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/47/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/RatchanonMo/plant-diseases-classification\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/425577722944006\"\n",
      "blog: \"https://medium.com/@49874/plant-diseases-classification-68b103f624d7\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/47/01.jpg)\n",
      "\n",
      "-  โมเดลจำแนกรูปภาพโรคใบพืช 6 ชนิด ได้แก่ เน่าดำ น้ำค้าง ใบจุดดำ ราแป้ง ราดำ ราสนิม,\n",
      "- ใช้ DuckDuckGo Image Search และ Google Image Search ในการรวบรวมชุดข้อมูล; ทำความสะอาด**ด้วยมือ** ทำให้ได้ชุดข้อมูลโรคละ 100-200 รูป และใบพืชไม่เป็นโรคอีก 193 รูป; แบ่ง train-test split ที่ 80/20,\n",
      "- เทรนด้วยสถาปัตยกรรม VGG-16 และเลือก checkpoint ที่ดีที่สุดด้วย validation set ที่สุ่มออกมาจาก training set 17%,\n",
      "- ได้ผลเป็นที่น่าพอใจที่ F1 และ accuracy 0.9 เทียบกับบุคคลทั่วไป (ที่ไม่ได้มีความรู้เรื่องโรคพืช) 30 คนทำแบบสอบถามจะตอบถูกประมาณ 4/10 รูป,\n",
      "- จำเป็นต้องทดสอบกับรูปจากสนามจริงเพื่อปรับปรุงให้พร้อมกับการใช้งานจริงต่อไป\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"28-7-22\"\n",
      "title: \"TLDR; Terms and Conditions Summarizer\"\n",
      "builder: \"ศุภโชค บุตรดีขันธ์ (บูม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/48/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Mikune00/ai-text-sum\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/427644922737286\"\n",
      "blog: \"https://medium.com/@kaitosolo18/terms-and-condition-summarization-d7f0680f752b\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/48/01.jpg)\n",
      "\n",
      "- ผลจากการสำรวจประชากร Gen Z 100 คนชาวไทยพบว่าเพียง 92% เห็นว่าข้อกำหนดและเงื่อนไขมีความสำคัญ แต่มีเพียง 1% ที่อ่านเต็มๆทุกครั้ง เนื่องจากมันยาวมาก ข้อมูลเยอะเกินไป ไม่น่าอ่านด้วย เสียเวลา และอื่น ๆ อีกมากมาย, \"\n",
      "- เก็บข้อมูลจากเว็บไซต์ Terms of Service; Didnt Read ที่ประกอบด้วยข้อกำหนดและเงื่อนไขตัวเต็มและคำย่อที่เว็บไซต์ย่อมาให้แล้ว\",\n",
      "- ทำความสะอาดข้อมูลด้วยการลบอักษรพิเศษ ช่องว่างส่วนเกิน และข้อความที่ไม่มีคู่คำย่อ,\n",
      "- ข้อความตัวเต็มส่วนใหญ่มีความยาวราว 100-200 คำและมากที่สุดถึง 1600 คำ ส่วนคำย่อมีความยาวเฉลี่ย 10 คำ,\n",
      "- เทรนด้วยสถาปัตยกรรม T5; แบ่งชุดข้อมูลเป็น train-validation-test ที่ 70-20-10,\n",
      "- ได้ผล ROUGE-1 F1 0.66, ROUGE-2 F1 0.52 และ ROUGE-L F1 0.61; เปรียบเทียบกับ baseline คือการทำ sentence retrieval ด้วย T5 ได้ดีกว่าประมาณ 3-5 เท่า,\n",
      "- Open Source บน HuggingFace Hub\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"29-7-22\"\n",
      "title: \"RL in Traffic Management\"\n",
      "builder: \"ณดล พิพัฒนติกานันท์ (ไตตั้น)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/49/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/nadoltitan/RL_in_Traffic_Management\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/429097575925354\"\n",
      "blog: \"https://medium.com/@nadoltitan1/%E0%B8%A5%E0%B8%94%E0%B8%9B%E0%B8%B1%E0%B8%8D%E0%B8%AB%E0%B8%B2%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%88%E0%B8%A3%E0%B8%B2%E0%B8%88%E0%B8%A3%E0%B8%95%E0%B8%B4%E0%B8%94%E0%B8%82%E0%B8%B1%E0%B8%94%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2-reinforcement-learning-d3b9c6014863\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/49/01.jpg)\n",
      "\n",
      "- โมเดล reinforcement learning (advantage actor-critic; A2C) ทำหรับจัดการไฟจาราจรบนแบบจำลอง Simulation of Urban Mobility (SUMO) ที่สร้างขึ้นมาจากแผนที่จริงผ่าน OpenStreetMap,\n",
      "- สร้างแบบจำลองแยกจราจรจากแผนที่ OpenStreetMap บน SUMO ด้วยOSMWebWizard; สร้างไฟล์ .net.xml สำหรับเส้นทางเดินรถ และ .rou.xml สำหรับระบุรถที่เข้ามาในเลน กำหนดให้รถเข้ามาในเลนของแบบจำลองโดยการสุ่ม,\n",
      "- วัดผลโดยการคำนวณความหนาแน่นของรถต่อเลนโดยเฉลี่ย (average lane density),\n",
      "- ทดลองสี่แยกแบบง่ายกับสถาปัตยกรรม A2C, Deep Q-learning (DQN), Proximal Policy Optimization (PPO); พบว่า A2C ทำได้ดีที่สุด,\n",
      "- ปัญหาสำคัญของโครงงานนี้ที่ยังต้องหาทางแก้ไข และปรับปรุงต่อไปก็คือ map จากเส้นทางจริงที่ถูก import มาจาก OSM มีความผิดพลาดของเส้นถนนอยู่มากมาย เช่น สัญญาณไฟจราจรที่มีมากกว่าหนึ่งอันในหนึ่งแยก เส้นทางถนนที่เกิดการทับซ้อนกันของ map ทำให้รถวิ่งขวางเส้นทางกันเอง(ซึ่งไม่ควรเกิดขึ้นกับสถานที่จริง) ปัญหาถนนที่เป็นทางตันทำให้รถบางส่วนวิ่งวนและเกิดการติดขัดไปสู่ทั้งระบบ และทำให้เป็นปัญหาในการ import มาให้ RL เรียนรู้ จากปัญหาดังกล่าวทำให้เราตัดสินใจว่า โครงงานนี้จะใช้ map ที่มีอยู่จาก Library SUMO-RL ที่มีความซับซ้อนมากขึ้นและใกล้เคียงกับ map ในสถานที่จริงมากที่สุด แทนการใช้ map ที่มีในสถานที่จริง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"30-7-22\"\n",
      "title: \"Learn Chinese Faster by Using Handwritten Chinese Character Recognition (HCCR)\"\n",
      "builder: \"ภควุฒิ ธรรมาวุฒิกุล (Army)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/50/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/GithubArmy/Handwritten-Chinese-Character-Recognition\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/429664732535305\"\n",
      "blog: \"https://medium.com/@army.prakawut/learn-chinese-faster-by-using-handwritten-chinese-character-recognition-hccr-67b23c63fb9\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/50/01.jpg)\n",
      "\n",
      "- โมเดลทำนายตัวอักษรภาษาจีนจากลายมือ 1,059 ตัวใน HSK4 และ 7,330 ตัวที่ใช้บ่อยด้วย resnet34; ใช้ได้ทั้งทาง webapp และบน Raspberry Pi,\n",
      "- ชุดข้อมูลจาก Institute of Automation of Chinese Academy of Sciences; แปลงเป็น png ในชุดข้อมูล pascalbliem/handwritten-chinese-character-hanzi-datasets บน Kaggle,\n",
      "- ข้อมูลแบ่งเป็น train ประมาณ 600 รูปต่อตัวอักษรและ test ประมาณ 140 รูปต่อตัวอักษร,\n",
      "- เทรนโมเดล ResNet18, ResNet34 และ MobileNetV2 ด้วย GPU บนโน้ตบุ๊คของตัวเอง,\n",
      "- ได้ accuracy 97.3% บนชุดข้อมูล HSK4 (1,059 ตัวอักษร) และ 94.4% บนชุดข้อมูล 7,330 ตัวอักษร,\n",
      "- ศึกษาคุณภาพของโมเดลด้วยการให้คน 15 คนลองใช้ webapp บน Huggingface ค้นพบว่าการเขียนผิด เช่น องศาของเส้น มีผลต่อความมั่นใจของโมเดล; โมเดลที่เทรนบนชุดข้อมูล 7,330 ตัวอักษรมีตัวอักษรที่ไม่ใช่อักษรจีน เช่น\\u3000≠ ถูกสับสนกับ\\u3000半,\n",
      "- พบว่าโมเดลทำนาย 一 (เลขหนึ่ง) ได้ยากมาก (ถูกเพียงหนึ่งในสิบครั้งโดยเฉลี่ย); เหตุผลคือภาพที่ถูกเทรนเป็นสี่เหลี่ยมผืนผ้า และเมื่อถูกบีบให้เป็นสี่เหลี่ยมจตุรัสระหว่างเทรนจึงทำให้ได้ผลที่ไม่ดี; แก้ไขด้วยการปรับขนาดให้ถูกต้อง,\n",
      "- โมเดลสามารถใช้ได้ทั้งผ่าน webapp, Raspberry Pi 3b+ และ Raspberry Pi Zero 2w\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"31-7-22\"\n",
      "title: \"Crossec : ระบบส่งเสริมการทำปฏิบัติการเนื้อเยื่อพืชด้วยปัญญาประดิษฐ์\"\n",
      "builder: \"วิทวัส กิติภัทร์ถาวร (เอิร์ธ)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/51/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/earthwittawat2548/Crossec\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/432856865549425\"\n",
      "blog: \"https://medium.com/@wittawatkitipatthavorn/crossec-%E0%B8%A3%E0%B8%B0%E0%B8%9A%E0%B8%9A%E0%B8%AA%E0%B9%88%E0%B8%87%E0%B9%80%E0%B8%AA%E0%B8%A3%E0%B8%B4%E0%B8%A1%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%97%E0%B8%B3%E0%B8%9B%E0%B8%8F%E0%B8%B4%E0%B8%9A%E0%B8%B1%E0%B8%95%E0%B8%B4%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B9%80%E0%B8%99%E0%B8%B7%E0%B9%89%E0%B8%AD%E0%B9%80%E0%B8%A2%E0%B8%B7%E0%B9%88%E0%B8%AD%E0%B8%9E%E0%B8%B7%E0%B8%8A%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2%E0%B8%9B%E0%B8%B1%E0%B8%8D%E0%B8%8D%E0%B8%B2%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B8%94%E0%B8%B4%E0%B8%A9%E0%B8%90%E0%B9%8C-77613e88fb0a\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/51/01.jpg)\n",
      "\n",
      "- โมเดลจำแนกภาพตัดขวางเนื้อเยื่อพืช 8 ประเภท (ลำต้น ราก ใบ ประเภทต่างๆ) ด้วย ResNet34,\n",
      "- แรงบันดาลใจจากการสัมภาษณ์ครูสอนเรื่องการทำปฏิบัติการภาพตัดขวางเนื้อเยื่อพืช ครู 1 คนต้องมีหน้าที่ตรวจชิ้นเนื้อที่นักเรียนประมาณ 40 คนทำการตัดขวาง (cross section) ทำให้ต้องใช้เวลานานหรือจำเป็นต้องจำกัดชนิดของพืชที่เลือกมาทำปฏิบัติการลง,\n",
      "- ทำ cross section เพื่อเก็บภาพจากห้องปฏิบัติการด้วยความช่วยเหลือของทีมงาน (ของ builder เอง) จากพืชหลากหลายชนิด เช่น ข้าวโพด หญ้าขน ถั่วเขียว หมอน้อย ผัดเป็ดไทย หญ้าหมู เป็นต้น รวมทั้งสิ้น 1,250 ภาพ,\n",
      "- ชุดข้อมูลที่ใช้งานถูก open source ไว้ที่: https://www.kaggle.com/datasets/earthwttw/plant-tissue-cross-section-dataset/,\n",
      "- วัดผลด้วย 10-fold cross validation เนื่องจากข้อมูลที่ใช้เทรนมีปริมาณน้อย,\n",
      "- ใช้สถาปัตยกรรม ResNet34 ในการปรับจูนกับภาพเนื้อเยื่อพืช เทรนโมเดล 5 ครั้ง ได้ accuracy เฉลี่ยที่ 96.96% เทียบกับนักเรียนมัธยม 6 ภาควิทย์คณิต 37 คนที่ตอบถูกเฉลี่ยเพียง 31% แสดงให้เห็นว่าโมเดลสามารถใช้เพื่อช่วยส่งเสริมการสอนทำปฏิบัติการสำหรับนักเรียนที่ยังไม่มีความชำนาญได้เป็นอย่างดี\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"1-8-22\"\n",
      "title: \"American Sign Language\"\n",
      "builder: \"กรกมล แสงสว่าง (เบลล์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/52/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Berubell9/American-sign-language\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/434912155343896\"\n",
      "blog: \"https://medium.com/@15192/american-sign-language-asl-b9f1c1a6dc01\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/52/01.jpg)\n",
      "\n",
      "- แรงบันดาลใจจากการดูวิดีโอที่มีชื่อว่า “ครู…โลกเงียบ” ของ 7Eleven ที่แสดงให้เห็นถึงครูที่เข้าใจหัวอกของเด็กสาวที่ชื่อว่า “บัว” ซึ่งเธอเป็นผู้พิการที่มีความบกพร่องทางการได้ยิน แต่กลับกันแม่ของเธอกลับไม่เข้าใจถึงโลกที่เธออยู่ และเพิกเฉยต่อสิ่งที่เธอเป็น ทำให้เด็กสาวมีความพยายามที่อยากจะพูดให้ได้ เพื่อที่จะให้แม่ของเธอเข้าใจในสิ่งที่เธอนั้นต้องการ (https://www.youtube.com/watch?v=8n6ocbjrZw8),\n",
      "- พบข้อจำกัดคือไม่มีชุดข้อมูลภาษามือไทยจึงเริ่มทำโครงงานด้วยชุดข้อมูลตัวอักษรภาษามืออเมริกัน American sign language (ASL) ได้แก่ A , B, C, D, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, Nothing, Space และ Del,\n",
      "- ชุดข้อมูลรวบรวมจาก open source บน Kaggle จำนวน 7 แหล่ง; ทำความสะอาดข้อมูลจาก 352,647 รูป คัดอย่างละเอียดเหลือ 14,498 รูป (หนึงประเภทตัวอักษรมีข้อมูลประมาณ 500 รูป),\n",
      "- ปรับจูนสถาปัตยกรรม ResNet50 จำนวน 30 epoch ได้ accuracy บน test set (แบ่ง 90/10) ที่ 71%,\n",
      "- พบตัวอักษรที่ใช้สัญลักษณ์มือคล้ายกันทำให้โมเดลอาจจะจำผิดพลาด เช่น A กับ E, S กับ T, G กับ Z เป็นต้น\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"2-8-22\"\n",
      "title: \"A Lip Reader\"\n",
      "builder: \"พุทธคุณ บุญชัย (ข้าวตู)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/53/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Kaotu999/A_Lip_Reader\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/435685011933277\"\n",
      "blog: \"https://medium.com/@boonchaiphutthakhun/a-lip-reader-c69be0d8363c\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/53/01.jpg)\n",
      "\n",
      "- โมเดลอ่านปากจากวิดีโอด้วย CNN-LSTM,\n",
      "- สร้างชุดข้อมูลขึ้นมาเองโดยใช้รูปหน้าคนที่กำลังพูด phoneme จากวิดีโอคนพูดบทหนัง Bee Movie เป็นเวลา 1 ชั่วโมงกว่า (https://www.youtube.com/watch?v=AJCfgXhA5fc),\n",
      "- จับคู่รูปหน้า(และปาก)กับ phoneme ได้ประมาณ 100,000 คู่; phoneme มี 40 ประเภท,\n",
      "- ทดลองสถาปัตยกรรม CNN ทายทีละรูปและ CNN-LSTM เพื่อทาย phoneme จาก sequence ของรูปก่อนหน้า; ได้ accuracy บน validation set ที่ 42.9% (CNN) และ 32% (CNN-LSTM),\n",
      "- เปลี่ยน phoneme เป็นคำด้วย The CMU Pronouncing Dictionary,\n",
      "- เหตุผลความผิดพลาดหลักๆเนื่องจาก phoneme มีประเภทเยอะ, บาง phoneme รูปปากใกล้เคียงกันมาก เช่น f และ v, และบาง phoneme มีจำนวนรูปที่ใช้เทรนน้อย (เสียงที่ไม่ค่อยมีคนใช้ เช่น zh)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"3-8-22\"\n",
      "title: \"Obstacle Detection for Blind people ช่วยเหลือผู้พิการทางสายตาด้วย Deep Learning\"\n",
      "builder: \"เทพบดินทร์ ใจอินสม (ฟู่)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/54/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/thepbordin/Obstacle-Detection-for-Blind-people\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/436406668527778\"\n",
      "blog: \"https://medium.com/@thepbordinjaiinsom/obstacle-detection-for-blind-people-d33e3c4e11dd\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/54/01.jpg)\n",
      "\n",
      "- โมเดลตรวจจับสิ่งกีดขวางเพื่อช่วยนำทางผู้พิการทางสายตาด้วย YOLO v5,\n",
      "- แรงบันดาลใจจากการเป็นจิตอาสาอ่านหนังสือให้ผู้พิการทางสายตาบน Read for The Blind สนใจการพัฒนา Accessibility ต่างๆให้กับผู้พิการ,\n",
      "- ไอเดียแรกเริ่มจากการทำโมเดลตรวจจับ ประตู vs ทางเดิน (object detection) ด้วยชุดข้อมูล Unimelb Corridor Synthetic Dataset และ MiguelARD/DoorDetect-Dataset ด้วยการปรับจูนสถาปัตยกรรม Detectron2 และ Faster R-CNN R50-FPN ได้ผลไม่เป็นที่น่าพอใจ สันนิษฐานว่าเป็นเพราะคำนิยาม \"ทางเดิน\" นั้นกว้างจนเกินไป,\n",
      "- ปรับไอเดียเป็น object detection สำหรับสิ่งกีดขวาง 10 ชนิด เช่น ประตู ประตูที่เปิด ประตูตู้เย็น โต๊ะ โซฟา ฯลฯ โดยใช้ชุดข้อมูล Indoor Training Set (ITS) [RESIDE-Standard] บน Kaggle และ annotate ข้อมูลเองด้วย openvinotoolkit/CVAT; แบ่งเป็น test set ประมาณ 100 รูป,\n",
      "- ทดลองเทรน Detectron2 และ Faster R-CNN R50-FPN หลายครั้ง พร้อมทำ error analysis ว่าสิ่งกีดขวางประเภทไหนโมเดลยังจับได้ไม่ดี ได้ทำการ annotate ข้อมูลเพิ่ม,\n",
      "- สุดท้ายเปลี่ยนมาใช้สถาปัตยกรรม YOLO v5 ที่ได้ผลดีที่สุดบน test set; ยังมีสิ่งกีดขวางบางประเภท เช่น เสา ที่มีข้อมูลน้อยจนโมเดลไม่สามารถเรียนรู้ได้ดีเท่าที่ควร,\n",
      "- เปิดชุดข้อมูลเป็นสาธารณะ เข้าไปใช้งานได้ที่ https://www.kaggle.com/datasets/thepbordin/indoor-object-detection,\n",
      "- เปิด template สำหรับการ deploy YOLO v5 บน streamlit เป็น open source; เข้าไปใช้ไดที่ https://github.com/thepbordin/YOLOv5-Streamlit-Deployment\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"4-8-22\"\n",
      "title: \"Detect and collect COVID-19 data more faster by using ATK-OCR Classification (AOC) model\"\n",
      "builder: \"ธนอนันท์ เฉลิมพันธ์ (เอ็ม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/55/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Tanaanan/AOC_ATK_OCR_Classification\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/437047961796982\"\n",
      "blog: \"www.shorturl.at/apGX5\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/55/01.jpg)\n",
      "\n",
      "- Model คัดกรอง และ บันทึกผลตรวจเชื้อ COVID-19 ผ่านที่ตรวจ ATK (Antigen Test Kit) คู่กับ บัตรประชาชน (Identification Card; ตัวอย่างภาพบัตรประชาชน อ้างอิงมาจาก AIForThai) ด้วย Efficientdet_d2 (Object detection) ควบคู่กับ PyThaiNLP (Natural Language Processing),\n",
      "- Dataset ที่ตรวจ ATK ได้จากการทำ Image Scraping ผ่านทาง Web Stock image กับ DuckDuckgo แล้วทำการคัดแยกข้อมูลด้วยมืออีกรอบ (1,500 รูป) ; ส่วนของบัตรประชาชน ใช้ Rules-based programming. (Selection + Edit distance) คู่กับ OCR (Optical Character Recognition) ในการตรวจจับ ชื่อ-นามสกุล และ เลขบัตรประชาชน เนื่องจากไม่สามารถหา Dataset ได้ T T,\n",
      "- ข้อมูลแบ่งเป็น Train set : 1,000 รูป , Validation / Test set : อย่างละ 250 รูป,\n",
      "- เทรนโมเดล Efficientdet_d2 (Object detection) ด้วย Google Colab Pro,\n",
      "- ได้ accuracy และ F1Score ที่ประมาณ 99.51 % บนชุดข้อมูล Validation set และ 94.00 % บนชุดข้อมูล Test set,\n",
      "- ศึกษาคุณภาพโมเดลด้วยให้คนจำนวน 15 คน ทดลองบันทึกผลตรวจ ATK ควบคู่กับ ชื่อ-นามสกุล, เลขบัตรประชาชนด้วยตัวเอง และ ทดลองใช้บน Webapp พบว่ามีประสิทธิภาพที่มากกว่า และ ใช้ระยะเวลาที่น้อยกว่าในการบันทึก และ แยกแยะข้อมูลด้วยตัวเอง,\n",
      "- พบว่าโมเดลยังมีข้อบกพร่องในกรณีที่เป็นตัวอักษร “i” (อักษรไอตัวเล็ก) กับ “l” (อักษรแอลตัวเล็ก) ที่ชื่อ-นามสกุล ของบัตรประชาชน โมเดลยังมีโอกาสตรวจจับผิดพลาดได้อยู่ (เกิดขึ้นสามในสิบครั้งโดยเฉลี่ย) ; แก้ไขได้ด้วยการทำ prediction model อักษร (i, l) [พัฒนาต่อในอนาคต],\n",
      "- ในกรณีที่ที่ตรวจ ATK สีมีความจางมาก หรือ มีแสงรบกวนเข้ามาในรูปภาพ อาจทำให้โมเดลตรวจจับผิดพลาดได้ ; แก้ไขได้โดยการถ่ายภาพใหม่ หรือ เปลี่ยนที่ตรวจ ATK ใหม่ และ หา Dataset เพิ่ม [พัฒนาต่อในอนาคต],\n",
      "- โดยในอนาคตจะพัฒนาให้ใช้ได้ในระบบ Line หรือ Application เพื่อให้โมเดลสามารถใช้งานได้จริงในการคัดกรอง และ บันทึกผลตรวจเชื้อ COVID-19 ในสถานศึกษา หรือ ในหน่วยงานต่างๆในอนาคต, ** ตอนนี้เปิดให้ทดลองใช้บน Webapp [กรณีพบเจอปัญหา หรือ อยากให้คำแนะนำสามารถ report มาใน Webapp ได้เลยย…. O w O\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"5-8-22\"\n",
      "title: \"โมเดล CNN สำหรับการจำแนกสัญญาณสมองในระบบ SSVEP-BCI สำหรับไมเกรน (A CNN for Classification Task in SSVEP-BCI for Migraine)\"\n",
      "builder: \"ฆนัท บุญจง (เค)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/56/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/KhanutBJ/Migraine_CNN\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/438384788329966\"\n",
      "blog: \"https://medium.com/@vwgprvvtsf/showcase-120bc69fb720\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/56/01.jpg)\n",
      "\n",
      "- แรงบันดาลใจจากความสนใจในการทำวิจัยทางการแพทย์และชีววิทยา; ไมเกรนเป็นโรคที่ส่งผลกระทบต่อประชากรถึง 10% โดยไม่เลือกเพศและอายุ,\n",
      "- โมเดลจำแนกคลื่นสมอง EEG (electroencephalogram) ของผู้ป่วยไมเกรนที่เกิดจาก SSEVP (steady state visually evoked potentials) หรือการให้ผู้ป่วยดูภาพ/เสียงและบันทึกคลื่นสมองผ่าน BCI (brain-computer interface),\n",
      "- ใช้ชุดข้อมูลคนเป็มไมเกรน 17 คนและไม่เป็นไมเกรน 18 คนจากงานวิจัย Zar et al (2020; https://kilthub.cmu.edu/articles/dataset/Ultra_high-density_EEG_recording_of_interictal_migraine_and_controls_sensory_and_rest/12636731),\n",
      "- ใช้ 60 Hz notch filter เพื่อลด noise ในข้อมูลสัญญาณ; ใช้ sampling rate ที่ 512 Hz และทดลองแยกแยะสัญญาณด้วย window 30 และ 4 วินาที; แบ่ง train-valid-test ที่ 64:16:20,\n",
      "- ใช้สถาปัตยกรรม EEGNet ในการเทรน; โมเดลประกอบด้วย 2D convolution, depthwise 2D convolution และ separable 2D convolution layers; https://arxiv.org/abs/1611.08024,\n",
      "- สำหรับ window 30 วินาที ได้ accuracy ดีกว่า SVM (51.4%) และ XGBoost (54.8%) ที่ 74% และ 87.5% สำหรับ window 4 วินาที\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"6-8-22\"\n",
      "title: \"PsychNLP: A BERT-based NLP model as a screening tool to help classify the risks of depression and suicide\"\n",
      "builder: \"พลกฤต สาตสิน (เจ)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/57/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/urseamajoris/PsychNLP\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/441008288067616\"\n",
      "blog: \"https://medium.com/@urseamlaccs/psychnlp-part-1-d8180740c0ec\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/57/01.jpg)\n",
      "\n",
      "- โมเดลแยกแยะข้อความ depression, suicidal และ neither จากข้อความในกระทู้ออนไลน์; อยู่ในขั้นตอนการศึกษา ไม่สามารถนำไปวินิฉัยโรคได้จริง โปรดใช้วิจารณญาณในการรับชม,\n",
      "- แรงบันดาลใจจากจับใจและสายใจ บอทคัดกรองภาวะซึมเศร้าของโรงพยาบาลศิริราช,\n",
      "- เก็บข้อมูลจากกระทู้ Reddit ที่มีข้อความยาวกว่า 32 ตัวอักษรต่อประโยคด้วย Python Reddit API Wrapper (PRAW) และ PushshiftAPI รวมประมาณ 400,000 ประโยค; ทำความสะอาดด้วยการลบ emoticon, ปรับเป็น lowercase, ลบสัญลักษณ์ต่างๆ ฯลฯ,\n",
      "- แยก label ตาม subreddit คือ depression จาก r/depression, suicidal จาก r/SuicideWatch และ neither จาก r/offmychest (คนมาโพสระบายเฉยๆไม่ได้ระบุว่าต้องมีอาการ); มีจำนวนแต่ละ label เท่าๆกัน,\n",
      "- ปรับจูนสถาปัตยกรรม all-distilroberta-v1 ที่เป็น sentence embeddings (768 dimensions) แล้วเพิ่ม classification head เพื่อจำแนกประเภทข้อความ,\n",
      "- ได้ผลใกล้เคียงกับ baseline ที่เป็น tf-idf + LinearSVC ที่ F1 0.548 (vs 0.584) และ accuracy 62.7% (vs 58.8%),\n",
      "- จากการวิเคราะห์พบว่าสาเหตุใหญ่มาจากข้อความใน r/depression และ r/SuicideWatch มีความคล้ายคลึงกันแม้ตัดสินด้วยมนุษย์,\n",
      "- สามารถปรับไปใช้กับ Discord Bot ได้ด้วย\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"7-8-22\"\n",
      "title: \"My Little HR: โมเดลประเมินเงินเดือนอาชีพสาย IT ในประเทศไทย\"\n",
      "builder: \"กันตพงศ์ วงศ์พานิชย์ (เติร์ด)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/58/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/JustAnotherTunaInTheSea/LittleHR-Thai-IT-Salary-Estimator\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/442411951260583\"\n",
      "blog: \"https://medium.com/@kantapong.vong/%E0%B8%A1%E0%B8%AB%E0%B8%B2%E0%B8%81%E0%B8%B2%E0%B8%9E%E0%B8%A2%E0%B9%8C%E0%B9%82%E0%B8%A1%E0%B9%80%E0%B8%94%E0%B8%A5%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B9%80%E0%B8%A1%E0%B8%B4%E0%B8%99%E0%B9%80%E0%B8%87%E0%B8%B4%E0%B8%99%E0%B9%80%E0%B8%94%E0%B8%B7%E0%B8%AD%E0%B8%99%E0%B8%AD%E0%B8%B2%E0%B8%8A%E0%B8%B5%E0%B8%9E%E0%B8%AA%E0%B8%B2%E0%B8%A2-it-%E0%B9%83%E0%B8%99%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B9%80%E0%B8%97%E0%B8%A8%E0%B9%84%E0%B8%97%E0%B8%A2-c2743d96d164\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/58/01.jpg)\n",
      "\n",
      "- โมเดลประเมินเงินเดือนอาชีพสาย IT ในประเทศไทยจากข้อมูลคนทำงาน,\n",
      "- แรงบันดาลใจจากโปรแกรมเมอร์หรือคนทำงานสาย IT ที่จบใหม่แล้วถูกกดเงินเดือนค่อนข้างมาก หรือคนที่ทำงานไปแล้วตั้งคำถามกับตัวเองว่างานที่ทำอยู่ค่าตอบแทนเหมาะสมรึเปล่า ซึ่งเป็นคำถามทั่วไปที่ตอบได้ยาก เพราะเราไม่รู้ว่าเงินเดือนของคนอื่นๆที่มีทักษะ ประสบการณ์ หรือตำแหน่งงานแบบเดียวกับเรา ได้ค่าตอบแทนเท่าไรหรือควรจะได้เท่าไร ถ้าไม่มีแหล่งข้อมูลที่มากพอหรือเวลาที่ใช้ในการหาข้อมูลเหล่านั้น ก็ไม่สามารถตอบได้อย่างมั่นใจเท่าไร,\n",
      "- พบ Thailand IT Salary Rates ซึ่งเป็นการประเมินเงินเดือนจากคนทำงาน 1,704 คนด้วย linear regression 7 ตัวแปร จึงใช้เป็น baseline ในการต่อยอด,\n",
      "- สร้างชุดข้อมูลจากการตอบแบบสอบถามสมาชิกกลุ่มหลังบ้านายอาร์ม ได้ 368 คน แบ่งเป็น train-valid-test ที่ 64:16:20,\n",
      "- ทำความสะอาดข้อมูลด้วยการรวบประเภท เช่น จังหวัด->[กรุงเทพ, อื่นๆ], ระดับการศึกษา->[ต่ำกว่าป.ตรี, ป.ตรี และสูงกว่าป.ตรี], ลบ outlier ของเงินเดือนที่สูงเกินความเป็นจริง, ลบ feature ที่ส่งสัญญาณต่อเงินเดือนน้อย เช่น อายุ, ประเภทการจ้างงาน, ภาษาโปรแกรมมิ่งที่เคยใช้, และสร้าง feature ใหม่จากข้อความอธิบายอาชีพ,\n",
      "- โมเดลใช้ 51 features จาก 6 หัวข้อใหญ่ คือ วุฒิการศึกษาสุดท้าย, จังหวัดที่ทำงานอยู่, ประสบการณ์การทำงานในองค์กร, ประสบการณ์การเขียนโปรแกรม/ฝึกฝนทั้งหมด, ขนาดองค์กรนับตามจำนวนพนักงาน, รายละเอียดตำแหน่งงานที่ทำ,\n",
      "- ใช้ AutoGluon ซึ่งเป็น open source AutoML ในการหาโมเดลที่ดีที่สุดจาก CatBoost, LightGBMLarge, LightGBMXT และ NeuralNetFastAI และทำ weighted ensemble ด้วย ridge regression,\n",
      "- ได้ผลดีกว่าโมเดล baseline คือ MAE 17798.86 (-21.83%), MSE 52472.00 (-52.78%); ตีความได้คร่าวๆว่าโมเดลประเมินคลาดเคลื่อนโดยเฉลี่ย 17,798 บาทต่อเดือน (มากที่สุดคือ 63,478 บาท น้อยที่สุด 756 บาท)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"8-8-22\"\n",
      "title: \"GANime-FullBody วาดรูปตัวละครอนิเมะ(สาวๆ)แบบเต็มตัว ด้วย Deep Learning\"\n",
      "builder: \"หิรัญกุล พิมพ์ศิริ (ไกด์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/59/01.jpg\"\n",
      "links:\n",
      "github: \"https://hrnph.github.io/GANime-FullBody/\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/445888770912901\"\n",
      "blog: \"https://medium.com/@hrnph/%E0%B8%A7%E0%B8%B2%E0%B8%94%E0%B8%A3%E0%B8%B9%E0%B8%9B%E0%B8%95%E0%B8%B1%E0%B8%A7%E0%B8%A5%E0%B8%B0%E0%B8%84%E0%B8%A3%E0%B8%AD%E0%B8%99%E0%B8%B4%E0%B9%80%E0%B8%A1%E0%B8%B0%E0%B8%AA%E0%B8%B2%E0%B8%A7%E0%B9%86-%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B9%80%E0%B8%95%E0%B9%87%E0%B8%A1%E0%B8%95%E0%B8%B1%E0%B8%A7-%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2-deep-learning-ganime-fullbody-9b3822e58934\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/59/01.jpg)\n",
      "\n",
      "- โมเดล Generative Adversarial Network (GAN) สำหรับสร้างรูปวาดตัวละครสาวน้อยอนิเมะ; แรงบันดาลใจจากความชื่นชอบในอนิเมะและประสบการณ์ในการทำเกมที่จำเป็นต้องออกแบบตัวละครใหม่เรื่อยๆ จึงคิดว่าน่าจะสะดวกขึ้นหากมีโมเดลที่สร้างสาวน้อยอนิเมะออกมาให้เลือกปรับใช้กับทั้งเกม, ไลท์โนเวล, รูปประกอบ ฯลฯ,\n",
      "- เลือกใช้ GAN มากกว่า Variational Autoencoder (VAE) เนื่องจากได้ภาพที่คมชัดกว่า; ด้วยข้อจำกัดทางเวลาและทรัพยากร ตั้งเป้าสร้างรูปขนาด 32², 64² หรือ 128² pixels,\n",
      "- สร้างชุดข้อมูลขึ้นมาเองด้วยมาตรฐานว่ารูปต้อง 1) ไม่มีพื้นหลัง (ขาวล้วน) 2) ลายเส้นและลักษณะตรงความต้องการ (เต็มตัว, ลายเส้นญี่ปุ่น, ตัวละครหญิง) 3) ชุดข้อมูลที่มีขนาดใหญ่ เนื่องจาก GAN ต้องใช้ชุดข้อมูลจำนวนมาก (10k ++),\n",
      "- เปรียบเทียบแหล่งข้อมูลที่จะรวบรวมมาเพื่อสร้างชุดข้อมูลหลายแห่ง เช่น Getchu ที่ปริมาณและคุณภาพดีที่สุดแต่การเชื่อมต่อไม่เสถียรพอ, Gelbooru ที่ปริมาณและคุณภาพดีเช่นกันแต่เต็มไปด้วยรูป 18+ จึงลงท้ายที่ Safebooru ซึ่งเป็น Gelbooru เวอร์ชั่นที่คัดรูป 18+ ออกแล้วโดยใช้แท้ก full_body solo, standing, 1girl, white_background เพื่อให้ได้รูปสาวน้อยอนิเมะเต็มตัวพื้นหลังสีขาว,\n",
      "- ทำความสะอาดข้อมูลด้วยการคัดรูปต่อไปนี้ออก 1) ตัวละครจิบิ (หัวโตตัวเล็ก) 2) ภาพที่มีมากกว่า 1 ตัวละคร 3) พื้นหลังสีฉูดฉาด/ท่ายืนแปลกๆ; โดยตัวละครจิบิเป็นรูปประเภทที่ไม่ต้องการที่เยอะที่สุด,\n",
      "- ทำโมเดลคัดแยกรูปที่ไม่ต้องการด้วย ResNet34 2 โมเดลคือ Chibi(~1k datasets) และ More Than 1(~0.3k datasets) ได้ผลอย่างดีเยี่ยม F1 0.96-0.98; เหลือชุดข้อมูลหลังทำความสะอาดแล้ว 12k รูป,\n",
      "- ขั้นตอนการเทรนเริ่มจากใช้ DCGAN พบว่า generator (โมเดลสร้างภาพปลอม) แทบไม่ได้เรียนรู้เลยเพราะ discriminator (โมเดลจับว่าภาพจริงหรือปลอม) เรียนรู้เร็วจนเกินไป คาดว่าปัญหาเกิดจาก vanishing gradients ของ BCE Loss ที่ใช้กับ discriminator จึงเปลี่ยนมาใช้ Wasserstein Loss และเพิ่ม gradient penalty เพื่อไม่ให้ loss ลดลงใกล้ 0 เร็วจนเกินไป,\n",
      "- จากนั้นปรับปรุงสถาปัตยกรรมโดยเปลี่ยนจาก DCGAN มาใช้ Progressive GAN ที่จะค่อยๆจับ Feature ที่ความละเอียดต่ำๆก่อน ในภาพ 4² เมื่อคุ้นชินแล้วก็จะเริ่มปรัปความละเอียดในสูงขึ้น เป็น 8² แล้วค่อยๆเพิ่มไปเรื่อยๆ จนถึง Scaling เป้าหมาย ที่ 128²,\n",
      "- เพิ่มประสิทธิผลของ generator อีกขั้นโดยการปรับใช้เทคนิคจาก StyleGAN คือ 1) Mapping Network จัดเรียง Random Noise ให้มีรูปแบบ 2) Adaptive Instance Normalization (AdaIN) เพื่อทำ style transfer; StyleGAN ได้ผลดีพอๆกับ Progressive GAN โดยใช้เวลาที่สั้นกว่า; เทรนโมเดลด้วยสถาปัตยกรรมและชุดข้อมูลนี้ เรียกว่า Model A,\n",
      "- เมื่อสถาปัตยกรรมเป็นที่พอใจแล้วกลับไปทำความสะอาดข้อมูลอีกรอบ เนื่องจากพบว่ารูปที่มี effect หรือชุดอลังการงานสร้างเกินไปจะทำให้โมเดลเรียนรู้ได้ยาก; ใช้ ResNet50 ในการคัดแยกรูปที่ต้องการและไม่ต้องการ โดยเทรนจากข้อมูลกำกับเองด้วยมือ 500 รูป, ได้ผลไม่ดีนัก (precision 0.4) ทำให้ข้อมูลถูกทำความสะอาดไปเหลือเพียงประมาณ 5 พันรูป,\n",
      "- ลองเทรน Model B บนข้อมูล 5 พันรูปนั้นแล้วพบว่าความสวยงามเป็นที่น่าพึงพอใจแม้ปริมาณรูปจะลดลงเกินครึ่ง,\n",
      "- ใช้ Fréchet inception distance (FID; ยิ่งน้อยยิ่งดี) ในการวัดผลเทียบรูปที่สร้างจาก Model A กับ Model B อย่างละ 1 หมื่นรูปกับรูปจริง พบว่า Model B ทำได้ดีกว่าเกือบเท่าตัว (data-centric มั้ยละคุณ!),\n",
      "- แม้จะมีผลลัพท์ที่ออกมาน่ากลัวอยู่บ้าง แต่โดยรวมแล้วผลลัพท์ที่ออกมา ถือว่าน่าพึงพอใจ โมเดลสามารถจับดีเทลขาได้อย่างสวยงาม ชุดที่ถูกลักษณะ ร่างกายที่สมส่วน และยังพยายามเติมหน้าเข้าไปในทุกๆโมเดล; สิ่งที่จะพัฒนาต่อหลังจากนี้คือ 1) การทดลองปรัป Noise ของโมเดล และทดสอบ Latent W เพื่อหา Style แต่ละส่วน 2) การทำให้ภาพชัดขึ้นที่ 256² 3) การหา Datasets ที่ดีขึ้นเพื่อเพิ่มคุณภาพของโมเดล 4) การ Deploy ที่ผู้ใช้สามารถปรัป Style ของรูปได้,\n",
      "- เปิดชุดข้อมูลลิขสิทธิ์การรวบรวมเป็น open source ที่: https://www.kaggle.com/datasets/hirunkulphimsiri/fullbody-anime-girls-datasets,\n",
      "- เปิด Docker Image สำหรับ deploy API เป็น open source ที่: https://gallery.ecr.aws/z1f5v2y8/ganime-fullbody/model0\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"9-8-22\"\n",
      "title: \"Find Water from Satellite Images Using U-Net Image Segmentation with Pytorch\"\n",
      "builder: \"วรกาญจน์ ลาสุดี (ปีใหม่)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/60/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/19xx47/Find-water-AI-builders-project\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/447914850710293\"\n",
      "blog: \"https://medium.com/@worakan.lasudee/found-water-from-satellite-images-by-segmentation-using-u-net-with-pytorch-7b3b0a8abf1d\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/60/01.jpg)\n",
      "\n",
      "- โมเดล semantic segmentation สำหรับหาแหล่งน้ำจากรูปถ่ายดาวเทียมโดยใช้ U-Net,\n",
      "- เทรนบนชุดข้อมูล Satellite Images of Water Bodies จาก Kaggle ซึ่งประกอบด้วยสองประเภทคือ Images และ Mask ซึ่งมีจำนวนข้อมูลทั้งหมด 2841 รูป,\n",
      "- สถาปัตยกรรม U-net เป็น CNN (convolutional neural networks) ที่แบ่งออกเป็นสองประเภทคือ Encoder และ Decoder ในส่วนของ Encoder เป็นการแปลงขนาดของ Input ให้มีขนาดเล็กลงแต่มี Channel ที่มากขึ้น นั่นคือเครือข่ายสามารถเรียนรู้ ความสัมพันธ์ที่ซับซ้อนได้มากขึ้นในภาพ Decoder มีโครงสร้างสถาปัตยกรรมเหมือนกับ Enconder ซึ่งทำหน้าที่แปลงขนาดภาพให้เป็นขนาดเดิม ใช้ Loss เป็น BCE-Dice Loss,\n",
      "- เลือกทำ U-net ด้วย Pytorch เพื่อนำมาเปรียบเทียบ U-net ด้วย Tensorflow เพื่อหา Model ที่มีประสิทธิภาพมากที่สุด เนื่องจากทั้งสองตัวต่างก็เป็น deep learning framework ที่เป็นที่นิยมเหมือนกัน แต่ Pytorch นั้นเรียนรู้ได้ง่ายเพราะมี document ที่อ่านได้เข้าใจง่าย มีชุมชนที่ใช้ในงานวิจัยเยอะและมีเครื่องมือ debugging มากมาย ส่วน Tensorflow นั้นแม้จะไม่มี debugging ที่ดีและชุมชนกระตือรือล้นเหมือน Pytorch แต่ Tensorflow เหมาะสำหรับการพัฒนาใน production environment และยังสามารถทำ data visualization ได้ง่ายกว่า Pytorch มาก,\n",
      "- ทดลอง Optimizer เป็น RMSProp, Adam และ NAdam ด้วย pretrained U-Net จาก Pytorch และ Tensorflow พบว่า Pytorch U-Net และ Adam ทำความแม่นยำระดับ pixel ได้ดีที่สุดที่ 80.7% บน test set\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"10-8-22\"\n",
      "title: \"Emotion Detection from Facial Micro-experessions\"\n",
      "builder: \"ครองภพ มั่นคง (ไบรท์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/61/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/Doraminn/Micro-expression/\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/449331850568593\"\n",
      "blog: \"https://medium.com/@brightkorn132/%E0%B9%80%E0%B8%88%E0%B9%87%E0%B8%9A%E0%B9%81%E0%B8%84%E0%B9%88%E0%B9%84%E0%B8%AB%E0%B8%99%E0%B8%81%E0%B9%87%E0%B8%95%E0%B9%89%E0%B8%AD%E0%B8%87%E0%B8%9D%E0%B8%B7%E0%B8%99%E0%B8%A2%E0%B8%B4%E0%B9%89%E0%B8%A1%E0%B8%A7%E0%B9%88%E0%B8%B2%E0%B9%84%E0%B8%A1%E0%B9%88%E0%B9%80%E0%B8%9B%E0%B9%87%E0%B8%99%E0%B9%84%E0%B8%A3-42c31e7cfdc1\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/61/01.jpg)\n",
      "\n",
      "- โมเดลตรวจจับอารมณ์เสี้ยววิหรือ Micro-expressions (Anger, Contempt, Happniess, Others, Surprise) จากรูปหน้า,\n",
      "- Micro-expression เป็นการแสดงอารมณ์ที่รู้สึกจริง ๆ แต่ต้องโกหกเอาไว้ และเกิดขึ้นเร็วมากจนมนุษย์ทั่วไปไม่สามารถรับรู้ได้เลย ถ้าสมมติมีโมเดลที่สามารถตรวจและระบุอารมณ์นี้ได้อย่างแม่นยำ ก็จะสามารถจับอารมณ์ที่โกหกอยู่ได้และมีประโยชน์เป็นอย่างมากเช่นการจับโกหกในการนำไปเป็นพยานหลักฐานของสืบสวนคดีต่าง ๆ,\n",
      "- ใช้ชุดข้อมูล SAMM dataset ประกอบไปด้วยรูปภาพที่แคปมาจากวิดีโอที่ถ่ายด้วยกล้องความเร็ว 200 fps มีทั้งหมด 29 subjects 159 samples แต่ละ sample มีรูปประมาณ 30-100 รูป,\n",
      "- ดูตัวอย่าง micro expression ได้ที่ https://www.facebook.com/aibuildersx/videos/1455685481578809,\n",
      "- ชุดข้อมูลมี 7 อารมณ์ ได้แก่ Happiness, Sadness, Anger, Disgust, Contempt, Fear และ Other แต่ Sadness, Fear และ Disgust มีจำนวนรูปน้อยเกินไปจึงตัดออกเพื่อป้องกัน label imbalance,\n",
      "- แต่ละเฟรมของชุดข้อมูลถูกจดไว้ว่าเป็น Onset frame (หมายเลขเฟรมที่เริ่มอัดคลิป), Apex frame (หมายเลขเฟรมที่เป็นจุดพีคของการเกิด micro-expression), Offset frame (หมายเลขเฟรมที่จบการอัดคลิป) และ Duration (จำนวนเฟรมที่จับได้ ซึ่งสอดคล้องกับจำนวนรูปในไฟล์),\n",
      "- จัดการแปลงรูปเพื่อเข้าสู่โมเดล 4 รูปแบบคือ 1) Original Apex frame — ใช้เฟรม ณ จุด Apex มาเป็น input 2) Difference of Apex frame and Onset frame — เนื่องด้วยเราได้แปลงข้อมูลภาพของเราเป็นตัวเลขเมื่อนำเข้าโมเดล จึงลองเอาผลต่างของ Apex กับ Onset มาเป็น input เพื่อแสดงว่าภาพตอนพีคกับตอนเริ่มต่างกันยังไง 3) Optical flow of Apex frame and Onset frame — เปลี่ยนจากผลต่างตัวเลขของ 2 เฟรมมาเป็น Optical flow ซึ่งก็คือแพทเทิร์นการขยับของภาพ โดยจะแสดงเป็นกลุ่มการไหลของแสง 4) Optical flow of Apex frame and Onset frame + Original Apex frame — คือการนำทั้ง Optical flow เมื่อกี้และภาพของ input แบบที่ 1 มารวมกันและนำไปเป็น input,\n",
      "- เลือกใช้ ResNet-18 ที่ pretrained มาจาก EfficientFace ซึ่งเทรนมาจาก MS-Celeb-1M และมีจำนวน class มากถึง 12,666 คน,\n",
      "- สร้างแบบทดสอบ 10 หน้าจากรูปที่ไม่ได้ใช้เทรนโมเดล โมเดลตอบถูก 6 จาก 10 ข้อเทียบกับมนุษย์ 29 คนที่ตอบถูก 2.759 ข้อโดยเฉลี่ย,\n",
      "- ปัญหาที่พบและน่าทำการแก้ไขในอนาคต 1) จำนวนข้อมูลที่มีน้อย 2) ความ Imbalance ของข้อมูลในแต่ละ class 3) sample บางคลิป แทบไม่ขยับหรือขยับน้อยมาก 4) sample บางคลิป มีตำแหน่งหน้า ที่ไม่ตรงกันใน Apex frame กับ Onset frame ทำให้ optical flow ฟุ้งกระจาย\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"11-8-22\"\n",
      "title: \"Automatic E2E Thai Question Generation with MT5\"\n",
      "builder: \"ปรินทพัฒน์ เพ็งพันธุ์ (ปริน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/62/01.jpg\"\n",
      "links:\n",
      "github: \"https://parinzee.github.io/ThaiQuestionGenerationMT5/\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/450060740495704\"\n",
      "blog: \"https://medium.com/@parinzee/studying-let-an-ai-generate-q-as-to-quiz-you-9ef27b1554d\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/62/01.jpg)\n",
      "\n",
      "- โมเดลสร้างคำถาม factoid จากบทความ; แรงบันดาลใจจาการเทคนิคการทบทวนบทเรียนส่วนตัวที่จะเน้นอ่านไวๆแล้วตอบคำถามท้ายบท ปัญหาคือบางคาบเรียน เช่น วิชาประวัติศาสตร์ ไม่มีคำถามท้ายบทให้ จึงทำโมเดลเพื่อสร้างคำถามขึ้นมาเองจากเนื้อหา,\n",
      "- สร้างโมเดล seq2seq ที่ทำงานประมาณนี้:, Input text: สร้าง 2 คำถาม: เฟซบุ๊ก (อังกฤษ: Facebook) เป็นบริการเครือข่ายสังคมสัญชาติอเมริกัน สำนักงานใหญ่อยู่ที่ เมนโลพาร์ก รัฐแคลิฟอร์เนีย เฟซบุ๊กก่อตั้งเมื่อวันพุธที่ 4 กุมภาพันธ์ ค.ศ. 2004, Output text: 1. เฟซบุ๊กคืออะไร A: บริการเครือข่ายสังคมสัญชาติอเมริกัน 2. เฟซบุ๊กก่อตั้งเมื่อไร A: วันที่ 4 กุมภาพันธ์ ค.ศ. 2004,\n",
      "- ใช้ชุดข้อมูล question answering (เอามากลับหัวกลับหางเป็น question generation) ได้แก่ XQuAD, Thai QA (SQuAD version), iapp-wiki-qa-dataset,\n",
      "- ทำความสะอาดข้อมูล เช่น HTML markup, ช่องว่างเกิน 1 ช่อง, วงเล็บที่ว่างเปล่า (ส่วนใหญ่เกิดกับบทความ Wikipedia); พบว่าหนึ่งบทความ (context) จะมีคำถามโดยทั่วไป 1-5 คำถาม,\n",
      "- เลือกใช้ mT5 ผ่าน Shivanandroy/simpleT5 เพื่อปรับจูนกับชุดข้อมูลที่มี; ใส่ seperator tokens (<SEP> และ <ตัวเลข>) ระหว่างคำถามเพื่อไม่ให้โมเดลงงกับการสร้างคำถามหลายข้อ โดยเฉพาะการที่โมเดลสับสนเลขบอกข้อคำถาม (1. xxx 2. xxx) กับเลขทศนิยม (1.2 ล้านคน),\n",
      "- ทำ data augmentation โดยการแตกคำถามสำหรับบทความเดียวกันเป็นหลายตัวอย่าง เช่น บทความที่มี 10 คำถาม แทนที่จะเป็นหนึ่งตัวอย่าง แตกให้เป็น 2 ตัวอย่าง ตัวอย่างละ 5 คำถาม เป็นต้น; ทำให้ได้จำนวนคำถามเพิ่มจาก 4,500 ข้อเป็น 14,000 ข้อ,\n",
      "- วัดผลด้วยเกณฑ์อ้างอิงจากโครงงานคล้ายกัน patil-suraj/question_generation คือ METEOR, GLEU, BLEU-4, Chr-F, และ ROUGE-L; พบว่าโมเดลที่ใช้ data augmentation ทำคะแนนได้ดีที่สุด แต่มีปัญหาว่าไม่สามารถสร้างคำถามได้ตามจำนวนที่ต้องการนัก,\n",
      "- ตรวจว่าคำถาม-ตอบ 449 คู่ที่ถูกสร้างขึ้นมาสำหรับ validation set นั้นถูกต้องแค่นั้น **ด้วยมือ** พบว่าถูกประมาณ 70%; คู่คำถาม-ตอบที่ผิดแบ่งได้เป็น อ่านไม่รู้เรื่อง (37.7%), ไม่มีคำตอบ (15.2%), จำนวนคำถามไม่ตรงตามที่ต้องการ (8.7%), คำตอบผิด (13.8%), สร้างคำถามซ้ำ ( 24.6%)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"12-8-22\"\n",
      "title: \"Using Machine Learning to create Auto Pitch Writer for UTAU\"\n",
      "builder: \"จิรา กุลจิราพงษ์ (จิรา)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/63/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/CCSleep/utau-pitch-ml/\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/450681343766977\"\n",
      "blog: \"https://medium.com/@CCSleep/using-machine-learning-to-create-auto-pitch-writer-for-utau-eec2d104236a\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/63/01.jpg)\n",
      "\n",
      "- โมเดลปรับแต่งพิช (Auto Pitch Writer) สำหรับโปรแกรมสร้างเพลง UTAU (คล้าย Vocaloid),\n",
      "- [สำคัญมาก] ก่อนอื่นทำความเข้าใจ Tuning ใน UTAU ด้วยวิดีโอ https://youtu.be/ciJlUPlS7dU, , ตัวอย่างเพลงที่ไม่ได้ tune: https://youtu.be/ciJlUPlS7dU?t=59, ตัวอย่างเพลงที่ tune แล้ว: https://youtu.be/ciJlUPlS7dU?t=723, ,\n",
      "- ปัญหาที่ต้องกาจะแก้คือการทำให้เพลงที่สร้างด้วยโปรแกรม \"ฟังเป็นธรรมชาติขึ้น\" เนื่องจากหากเราแค่ใส่พิชของแต่ละตัวโน้ตต่อกันไปเรื่อยๆจะทำให้ได้เพลงที่เหมือนหุ่นยนต์ร้อง จึงต้องมีการปรับพิชระหว่างตัวโน้ต (pitchbends) ซึ่งปกติทำด้วยมือคนแต่ง,\n",
      "- เก็บข้อมูลจากลิสต์ไฟล์ UST (UTAU sequence text) ที่ถูกรวบรวมไว้ที่ https://docs.google.com/document/d/1yKn3jN3rLoVFSXcPUET_iYsmbUi-nThRktgIAyXc230/edit และใช้ไฟล์ที่ถูกเก็บด้วย Mediafire ทั้งหมด,\n",
      "- UTAU แสดง pitchbends ด้วยตัวแปร 3 ตัวในรูปแบบ, , PBS=-66;-50 (เวลาเริ่ม;พิชเริ่ม), PBW=38,71,-3,141,50 (ค่าบนแกน Y นั่นคือแกนพิช สำหรับจุดถัดไป ในที่นี้คือ 4 จุด), PBY=-17.9,-18.6,-0.7,0,0 (ค่าความห่างจากจุดที่แล้วตามแกน X นั่นคือแกนเวลา), ,\n",
      "- ก่อนอื่นปรับ PBS ด้วยกฎโดยให้เวลาเริ่มคือเริ่มจาก 20% สุดท้ายของความยาวโน้ตตัวที่แล้ว และเริ่มจากพิชของโน้ตตัวที่แล้ว,\n",
      "- สำหรับ PBW และ PBY นั้น ใช้วิธีการสร้างโมเดล machine learning เพื่อทำนาย \"เทรนด์การขึ้นลง\" ของ PBY (ขึ้นเป็น 1 ลงเป็น 0; ตัวเลข 4 ตัว รวม 63 คลาส) เช่น [0,1,0,0], [0,1,1,1], ...,\n",
      "- จากนั้นใช้ประสบการณ์การแต่งเพลง สร้างกฎเปลี่ยนคำทำนายกลับเป็น PBW และ PBY,\n",
      "- สำหรับ feature ในการทำนาย ใช้ความยาวและพิชจากโน้ตทั้งสองตัวสร้างขึ้นด้วย pyUTAU,\n",
      "- ใช้ baseline เป็นการสร้าง pitchbends ด้วย Portamento ใน UTAU คือแค่ลากเส้นขึ้น-ลงแบบเป็นเส้นตรง แน่นอนว่าจะได้เสียงที่ไม่เป็นธรรมชาตินัก,\n",
      "- ใช้ random forest ได้ accuracy 61% บน test set เทียบกับ 27% ของ Portamento baseline จาก 63 classes,\n",
      "- สังเกตว่าโมเดลทาย class 0 (ไม่มีพิช) และ 1 (พิชลง) มากกว่าปกติมาก (ทั้งสองคลาสเป็น 2/3 ของตัวอย่างทั้งหมด) จึงลองสร้างโมเดล logistic regression เพื่อดูว่าโมเดลคิดอย่างไร; พบว่าสำหรับ 0 โมเดลมองว่าถ้าโน้ตตัวหน้าเป็น rest แทบจะแน่นอนว่าต้องทายว่าไม่มีพิช สำหรับ 1 โมเดลมองว่าถ้าโน้ตตัวหน้าสั้นกว่าส่วนใหญ่จะเป็นพิชลง ซึ่งตรงกับสัญชาติญาณของนักแต่งเพลงที่เป็นมนุษย์\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"13-8-22\"\n",
      "title: \"Object Detection in White Blood Cells for Leukemia\"\n",
      "builder: \"แพรวา ชูบ้านนา (แพรว)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/64/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/praewery/objectdetction-White_blood_cell\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/451374247031020\"\n",
      "blog: \"https://medium.com/@cytokinin8/object-detection-in-white-blood-cell-60273002fdb3\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/64/01.jpg)\n",
      "\n",
      "- โมเดลจับและแยกแยะภาพเซลล์มะเร็งเม็ดเลือดขาวด้วย Faster CNN, YOLO v5 และ Swin Transformer,\n",
      "- มะเร็งเม็ดเลือดขาวชนิดเฉียบพลันจัดเป็นโรคมะเร็งที่มีความรุนแรงสูง พบได้ทุกเพศทุกวัย พบมากขึ้นในผู้สูงอายุ และเป็น 1 ใน 10 โรคมะเร็งที่พบบ่อยในประเทศไทย; เซลล์มะเร็งเม็ดเลือดขาวมีหลากหลายชนิด การแบ่งชนิดของมะเร็งเม็ดเลือดขาวจะมีผลต่อการเลือกวิธีการรักษา เนื่องจากมะเร็งเม็ดเลือดขาวแต่ละชนิดมีการดำเนินโรคและการพยากรณ์โรคที่แตกต่างกัน,\n",
      "- ในปัจจุบันการวินิจฉัยมะเร็งเม็ดเลือดขาว จะทำการตรวจไขกระดูก (bone marrow smear or biopsy) หรือการดูจากเลือดที่เจาะจากหลอดเลือดดำ (vein)เช่น ที่แขน โดยทั้งสองวิธีนั้นจะนำเลือดมาไถดูบนสไลด์ เพื่อดูผ่านกล้องจุลทรรศน์ เรียกว่า (peripheral blood smear) เพื่อนับจำนวนเซลล์ตัวอ่อน และแยกชนิดของเซลล์ เพื่อพยากรณ์โรค ทั้งนี้ การแบ่งชนิดของมะเร็งเม็ดเลือดขาวจะมีผลต่อการเลือกวิธีการรักษาทำให้สำคัญมากๆ จำเป็นต้องอาศัยบุคลากรทางการแพทย์และผู้เชี่ยวชาญในการจำแนก จึงเป็นเหตุผลที่ดีถ้าเราจะนำ AI เข้าไป screening tools ช่วยบุคลากรทางการแพทย์ เพื่อเพิ่มประสิทธิภาพทางการรักษาได้มากยิ่งขึ้น,\n",
      "- ใช้ชุดข้อมูล microscopic image of white blood cells จาก โรงพยาบาลศิริราช โดยภายใน Dataset ประกอบด้วยรูปภาพ ตัวอ่อนของเม็ดเลือดขาวของกลุ่มคนประเภทหนึ่ง ซึ่งสามารถแบ่งเป็น 12 ชนิดด้วยกันได้แก่ Atypical lymphocyte, Band Neutrophil, Basophil, Blast, Eosinophil, Lymphocyte, Metamyelocyte, Monocyte, Myelocyte, NRC, Promyelocyte, Segmented neutrophil; ทั้งหมดจำนวน 3,376 ภาพ เป็น train set จำนวน 2700 ภาพ, validation set จำนวน 338 ภาพและ test set จำนวน 338 ภาพ,\n",
      "- ทำ data augmentation หรือ การเพิ่มจำนวน dataset เพื่อให้โมเดลได้ train ข้อมูลที่เยอะมากขึ้น จากการ rotation, cropping, horizintal flips ภาพใน dataset และ ปรับขนาดรูปภาพของเรา,\n",
      "- ทดลองใช้สถาปัตยกรรม Faster CNN (accuracy 33.53%), YOLO v5 (accuracy 51.63%) และ Swin Transformer (accuracy 56.37%),\n",
      "- จาก test set ทั้งหมด 337 ภาพสามารถทายถูก 190 ภาพและ ทายผิด 71 ภาพ และมีอีก 76 ภาพที่โมเดลของเราไม่ detect ซึ่งพอไปตรวจสอบรูปภาพเหล่านั้นพบว่าส่วนมากจะเป็นรูป ที่มีปริมาณเม็ดเลือดเกาะตัวเป็นกลุ่มทำให้ โมเดลเกิดการสับสน และจับภาพ ออกมาได้ไม่ครบถ้วนและเมื่อลองดูจากจำนวน dataset แล้วจะเห็นได้ว่า จำนวนตัวอย่างของ Promyelocyte มีจำนวนน้อยมากๆทำให้โมเดลสามารถเรียนรู้ได้น้อยและทายผิดอยู่บ้าง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n",
      "---\n",
      "date: \"14-8-22\"\n",
      "title: \"Single Note Music Classification\"\n",
      "builder: \"ณภัทร เสรีรักษ์ (นีร)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/65/01.jpg\"\n",
      "links:\n",
      "github: \"https://github.com/neennera/AI_single-music-note-classification\"\n",
      "facebook: \"https://facebook.com/aibuildersx/posts/452054363629675\"\n",
      "blog: \"https://neennera.medium.com/single-note-music-classification-by-convolutional-neural-networks-5f72434d139a\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/65/01.jpg)\n",
      "\n",
      "- โมเดลแยกแยะโน้ตเพลงรายตัวจากไฟล์ MIDI ด้วย Convolutional Neural Networks (CNN),\n",
      "- แรงบันดาลใจจากความคิดง่ายๆอย่าง “ถ้ามี AI ที่พอฟังเราฮัมเพลงแล้วทายโน๊ตถูกเลยคงดีนะ” ในช่วงนั้นเราได้รู้จักคำว่า “Perfect Pitch” ซึ่งเป็นคำเรียกกลุ่มคนที่ฟังเพลงแล้วรู้โน๊ตในทันที สามารถแยกแยะเสียงโน๊ตได้ตั้งแต่เกิดหรือฝึกเอา จาก ear training บ่อยๆ ประจวบกับโครงการ AI Builders ประกาศพอดี เลยถือโอกาสมาลองฝึก “Perfect Pitch” กับ Model ดู,\n",
      "- ชุดข้อมูลจากไฟล์เสียง MIDI ที่สร้างขึ้น ประกอบไปด้วยเสียงโน๊ตตั้งแต่ C0-B9 ที่เล่นโดยเครื่องดนตรีต่างชนิดกัน มีไฟล์เสียงทั้งสิ้น 26,643 ไฟล์,\n",
      "- จัดการข้อมูลโดย 1) resample เสียงให้มีความละเอียดที่ 16000 Hz 2) mix down ในกรณีที่ไฟล์บางไฟล์มีการแยก channel ซ้าย/ขวา เราจะรวมเสียงให้มาอยู่ใน mono channel 3) เปลี่ยนเป็น mel spectrogram ซึ่งเป็น short-time fourier transform ที่เน้นแค่คลื่นเสียงต่ำอันเสียงออกมาเป็นค่าที่ใกล้เคียงกับค่าที่มนุษย์ได้ยิน; ที่จริงเรายังสามารถ take log ลงไปเพื่อให้ range ของข้อมูลไม่กว้างและกระโดดมาถึง 20,000 แต่เนื่องจากการ predict note เราดูแค่ frequency เสียงที่โดดขึ้นมา จึงไม่ได้มีผลต่อการทำนายมากนัก กลับกัน หากเป็น speech ก็จะทำให้เกิดปัญหาตามมาได้,\n",
      "- โมเดลรับข้อมูล tensor ของ data ที่มี size เป็น (128,50) แล้วส่งเข้าโมเดลก่อนจะ predict ค่ามาเป็น index ของ classmap ตั้งแต่ 0–12 (classmap=[“C”,”C#”,”D”,”D#”,”E”,”F”,”F#”,”G”,”G#”,”A”,”A#”,”B”]),\n",
      "- เทรน 1D CNN 3 layers (ขนาด channel 128 -> 256 -> 512) ด้วย cross-entropy loss; ใช้ BatchNorm1D มา normalization ข้อมูลก่อนออกจาก layer ก่อนจะใช้ Activation ReLU เพื่อจะกำจัดค่าที่น้อยกว่า 0 ออกเป็นตอนสุดท้ายเพราะความถี่เสียงมีค่าติดลบไม่ได้,\n",
      "- ได้ accuracy 96.48% หลังเทรนไป 20 epochs,\n",
      "- นอกจากนี้ยังได้ทำอีกโครงการสำหรับแยกแยะโน้ตที่เรียงกัน 1,500 time steps จากชุดข้อมูล MusicNet (https://zenodo.org/record/5120004#.YrHWQLlBxQI) อีกด้วย; ทดลองสถาปัตยกรรมากมายได้แก่ Conv1d -> Conv1d -> Linear, Conv1d -> RELU -> Linear(บนแกน time) -> LSTM(บนแกน feature), Convo1d -> LSTM(time) -> Linear(time) -> LSTM(feature), Conv1d(kernel = 6) -> ReLU -> Conv1d(kernel = 8) -> LSTM แต่ปัญหาการทายโน้ตหลายตัวพร้อมกันยังยากกว่าทายตัวเดียวมาก (อ่านต่อได้ที่ https://neennera.medium.com/%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%9E%E0%B8%B1%E0%B8%92%E0%B8%99%E0%B8%B2-model-%E0%B9%81%E0%B8%A2%E0%B8%81%E0%B9%82%E0%B8%99%E0%B9%8A%E0%B8%95%E0%B8%94%E0%B8%99%E0%B8%95%E0%B8%A3%E0%B8%B5%E0%B9%83%E0%B8%99%E0%B9%80%E0%B8%9E%E0%B8%A5%E0%B8%87-%E0%B9%82%E0%B8%94%E0%B8%A2-pytorch-b239dc0e956c)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n"
     ]
    }
   ],
   "source": [
    "for x in posts:\n",
    "    print(make_md(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./posts/2022/BACK(BlindAllCanKnow)-ActionCaptioningforBlinds.md\n",
      "./posts/2022/ViolenceDetection.md\n",
      "./posts/2022/FakeProductDetectiononOnlineRetail.md\n",
      "./posts/2022/CactusClassificationwithFastai.md\n",
      "./posts/2022/FoodIngredientsLabelReaderforFoodAllergy.md\n",
      "./posts/2022/Edge-to-Face.md\n",
      "./posts/2022/TextDoeโมเดลจำแนกแวดวงบทความสิ่งพิมพ์.md\n",
      "./posts/2022/AutoLyricRecognizer.md\n",
      "./posts/2022/ImageTransferDay-to-NightandNight-to-Day.md\n",
      "./posts/2022/MusicRecognition.md\n",
      "./posts/2022/vTranslatorTranscribeandTranslateVTuberusingWav2Vec2.md\n",
      "./posts/2022/Text-to-imagesynthesiswithVQGAN-ThCLIP.md\n",
      "./posts/2022/GameRecommendationbyusingNeuralNetworkEmbeddings.md\n",
      "./posts/2022/ChaosEDMGeneratingEDMSongwithVAE(VariationalAutoencoder)Spectrogram.md\n",
      "./posts/2022/WanchanBERTaThaiGrammarly.md\n",
      "./posts/2022/GarbageDetectionwithTensorflowLite.md\n",
      "./posts/2022/SickPigClassifier.md\n",
      "./posts/2022/NLPforgenrepredictionsonFFnetanantithesistoutilitarianism.md\n",
      "./posts/2022/AIแยกแยะแมงดาจานกับแมงดาถ้วย.md\n",
      "./posts/2022/IsthataSupra.md\n",
      "./posts/2022/Microplasticdetectionandcollectstatisticaltebulardata..md\n",
      "./posts/2022/DebunkerMLตรวจจับข่าวลวง.md\n",
      "./posts/2022/BrainTumorSegmentationusingSegResNet.md\n",
      "./posts/2022/ClassicalMusicGenerator.md\n",
      "./posts/2022/LamiaceaeClassification.md\n",
      "./posts/2022/สร้างสรรบทเพลงUndertaleผ่านLSTMและTeacherForcingRNN.md\n",
      "./posts/2022/PlantDiseaseClassification.md\n",
      "./posts/2022/TLDR;TermsandConditionsSummarizer.md\n",
      "./posts/2022/RLinTrafficManagement.md\n",
      "./posts/2022/LearnChineseFasterbyUsingHandwrittenChineseCharacterRecognition(HCCR).md\n",
      "./posts/2022/Crossecระบบส่งเสริมการทำปฏิบัติการเนื้อเยื่อพืชด้วยปัญญาประดิษฐ์.md\n",
      "./posts/2022/AmericanSignLanguage.md\n",
      "./posts/2022/ALipReader.md\n",
      "./posts/2022/ObstacleDetectionforBlindpeopleช่วยเหลือผู้พิการทางสายตาด้วยDeepLearning.md\n",
      "./posts/2022/DetectandcollectCOVID-19datamorefasterbyusingATK-OCRClassification(AOC)model.md\n",
      "./posts/2022/โมเดลCNNสำหรับการจำแนกสัญญาณสมองในระบบSSVEP-BCIสำหรับไมเกรน(ACNNforClassificationTaskinSSVEP-BCIforMigraine).md\n",
      "./posts/2022/PsychNLPABERT-basedNLPmodelasascreeningtooltohelpclassifytherisksofdepressionandsuicide.md\n",
      "./posts/2022/MyLittleHRโมเดลประเมินเงินเดือนอาชีพสายITในประเทศไทย.md\n",
      "./posts/2022/GANime-FullBodyวาดรูป.md\n",
      "./posts/2022/FindWaterfromSatelliteImagesUsingU-NetImageSegmentationwithPytorch.md\n",
      "./posts/2022/EmotionDetectionfromFacialMicro-experessions.md\n",
      "./posts/2022/AutomaticE2EThaiQuestionGenerationwithMT5.md\n",
      "./posts/2022/UsingMachineLearningtocreateAutoPitchWriterforUTAU.md\n",
      "./posts/2022/ObjectDetectioninWhiteBloodCellsforLeukemia.md\n",
      "./posts/2022/SingleNoteMusicClassification.md\n"
     ]
    }
   ],
   "source": [
    "def naming_sense(text, root='./posts/2022/'):\n",
    "    # tokenize\n",
    "    tokens = pythai.word_tokenize(text)\n",
    "    x = ''.join(tokens[:6])\n",
    "    if len(x) < 30:\n",
    "        x = text\n",
    "    elif len(x) > 30:\n",
    "        x = x = ''.join(tokens[:3])\n",
    "        \n",
    "    naming = x.replace(' ', '').replace('!', '').replace('?', '').replace(':','')\n",
    "    path = f\"{root}{naming}.md\"\n",
    "    return path\n",
    "\n",
    "for post in posts:\n",
    "    data = make_md(post)\n",
    "    if naming_sense(post['title']) in ['ChaosEDM', 'Crossec', 'Debunker', 'Edge-to-Face', 'MyLittleHR', 'NLPforgenrepredictionsonFFnet', 'PsychNLP', 'TextDoe', 'vTranslator']:\n",
    "        print(post['title'])\n",
    "\n",
    "    # test naming\n",
    "    print(naming_sense(post['title']))\n",
    "    with open(naming_sense(post['title'], \"./posts/2022/\"), 'w', encoding='utf8') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- โมเดลอธิบายรูปภาพ (image captioning) เพื่ออธิบายภาพตรงหน้าให้กับผู้พิการทางสายตา,',\n",
       " '- CLIPCap นำ pretrained CLIP เพื่อสร้าง image embeddings เป็น input ให้กับ pretrained GPT2 สร้างข้อความที่ตรงกับภาพ,',\n",
       " '- เทรนโมเดลด้วย Flickr30k (รูป-คำบรรยายภาษาอังกฤษ) เป็นเวลา 17 ชั่วโมง (10 epochs),',\n",
       " '- ตัดสินใจใช้ Flickr30k ทั้งที่จำนวนข้อมูลน้อยกว่า COCO เพราะทำแบบสอบถามแล้วพบว่าข้อมูลคำบรรยายของ Flickr30k มีคุณภาพมากกว่า,',\n",
       " '- ใช้ PyThaiNLP Translate ในการแปลภาษาคำบรรยายเป็นภาษาไทย เนื่องจากแบบสอบถามพบว่าเป็นธรรมชาติกว่า Google Translate API ในบริบทนี้,',\n",
       " '- ใช้ Google TTS ในการเปลี่ยนคำบรรยายที่ถูกแปลเป็นเสียงพูด,',\n",
       " '- นอกจากการเทรนโมเดล CLIPCap ตรง ๆ แล้วยังมีการนำมาประกอบการใช้งานกับ pretrained models อื่น ๆ เช่น PyThaiNLP Translate และ Google TTS อีกทั้งการต่อสู้กับคุณภาพข้อมูลอย่างสมศักดิ์ศรี เช่น ลบรูปซ้ำ, แก้ข้อมูลตาราง, แก้คำบรรยายที่มีมากกว่าหนึ่งประโยคต่อกัน ฯลฯ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[0]['summary']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e73a464379447ddfc8ee4935215540133560b3ea78e2ab4739eadfcb8582468"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
