{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from facebook_scraper import get_posts\n",
    "import pythainlp as pythai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('showcase_data_cleaned(2022).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'ID', 'summary', 'title_image', 'images', 'links', 'reason',\n",
       "       'author', 'fulltext', 'post_url', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "ID             0\n",
       "summary        0\n",
       "title_image    0\n",
       "images         0\n",
       "links          0\n",
       "reason         0\n",
       "author         0\n",
       "fulltext       0\n",
       "post_url       0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {'date': \"\",  \"title\": \"\", \"builder\": \"\", \"builder_info\": \"\", \"thumbnail\": \"\", \"links\": {\"github\": \"\", \"facebook\": \"\", \"blog\": \"\"}, \"title_image\": \"\", \"summary\": \"\", \"reason\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://facebook.com/aibuildersx/posts/405337768301335\n"
     ]
    }
   ],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    print(data['post_url'][i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_summary(x: str) -> list[str]:\n",
    "    newx = x.split('- ')\n",
    "    x = [x for x in newx if x != '']\n",
    "    return newx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_link(link: str) -> list[str]:\n",
    "    newx = link.split('\\n')\n",
    "    newx = [x for x in newx if x != '']\n",
    "    medium = [x for x in newx if 'medium' in x or 'อ่านรายละเอียดเพิ่มเติม:' in x][0].split(': ')[-1]\n",
    "    github = [x for x in newx if 'github' in x][0].split(': ')[-1]\n",
    "    return medium, github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_author(link: str) -> list[str]:\n",
    "    newx = link.split('/')\n",
    "    name = newx[0]\n",
    "    bio = '/'.join(newx[1:])\n",
    "    return name, bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:00<?, ?it/s]C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      " 51%|█████     | 23/45 [00:00<00:00, 223.30it/s]C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "C:\\Users\\hirun\\AppData\\Local\\Temp\\ipykernel_22224\\1831855856.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
      "100%|██████████| 45/45 [00:00<00:00, 234.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เคยเข้าร่วมโครงการ Samsung Innovation Campus มาแล้ว (ได้เรียนพื้นฐานของ Python และ AI มาบ้างเล็กน้อย) และอยากเรียนรู้เรื่องการทำ AI ที่มากขึ้นเพื่อสามารถนำไปต่อยอดในการทำโปรแกรมที่อยากทำ  อนาคตใฝ่ฝันอยากเป็นโปรแกรมเมอร์ ตอนนี้เลยเริ่มศึกษาหาความรู้เกี่ยวกับการเขียนโค้ด และเก็บเกี่ยวประสบการณ์ให้ได้มากที่สุดเท่าที่จะทำได้ และอยากมีโปรแกรมเป็นของตัวเองที่สามารถใช้แก้ปัญหาได้จริง และอยากนำความรู้ที่ได้ไปต่อยอดทำแอปฯ ที่ช่วยเหลือสังคมในอนาคต (BACK)  สิ่งที่อยากทำคือ Blind All Can Know (BACK) เป็นแอปพลิเคชันที่ช่วยบรรยายการกระทำต่าง ๆ ออกมาเป็นเสียง ที่สามารถทำได้แบบ real-time เพื่อช่วยเหลือผู้พิการทางการมองเห็น จะได้สามารถรับรู้ว่าเกิดอะไรขึ้นบ้าง ช่วยให้การใช้ชีวิตสะดวกสบายมากขึ้น (https://news.samsung.com/th/sic-coding-for-students ป.ล. Can Know ไม่ใช่ Can See ;-;;)\n",
      "ถ้ามีโอกาสได้เข้ามาศึกษาหาความรู้ ผมจะเอาความรู้ที่ได้ไปลงแข่งขันในรายการ TH National Software Contest อย่างแน่นอน ซึ่งจะทำอย่างสุดความสามารถเพื่อเป็นเกียรติแก่ความรู้ทั้งหมดที่จะได้รับมากจากโครงการนี้ ผมจะไม่หยุดแค่ได้เข้ามาเรียนรู้แล้วรู้สึกว่ามันเปิดโลกมากมายแล้วจบไปแค่นั้น แต่หลังจากนั้นผมจะทำโครงการให้สำเร็จและ จะสร้างสรรค์ไอเดียใหม่ๆออกมาเรื่อยๆอย่างต่อเนื่องครับ  ตั้งใจไว้ว่าจะลงแข่งขัน NSC ในปีหน้า จึงต้องการความรู้เรื่อง Machine learning อย่างมาก เพื่อไปทำโปรเจคส่งเข้าประกวดการแข่งขัน NSC ซึ่งผ่านมาเห็นโครงการ AI Builder พอดี และส่วนตัวเองก็มีความรู้เรื่อง Python มาพอสมควรแล้ว แต่ยังไม่แน่นเรื่อง Machine learning จึงเป็นโอกาสดีที่จะส่งเข้ามาคัดเลือกในโครงการนี้  อยากทำ Action Recognition ประมวลผลท่าทางภาษามือแล้วแปลงเป็นข้อความ เพื่อเอาไว้เข้าใจผู้ที่ใช้ภาษามือในการสื่อสาร เพื่อให้สามารถเข้าใจภาษามือได้ง่ายและสามารถสื่อสารกับผู้ที่บกพร่องการสื่อสารได้ง่ายมากขึ้น โดยจะอิงข้อมูลจาก กองทุนส่งเสริมและพัฒนาคุณภาพชีวิตคนพิการ\n",
      "ผมชอบและถนัดทางคณิตศาสตร์ครับ การแก้ปัญหาต่าง ๆ และชอบลองอะไรใหม่ ๆ ผมมีประสบการณ์ภาษา python มาบ้างรวมทั้งการใช้ libraries อื่น ๆ เช่น numpy pandas matplotlib  ผมอยากใช้เวลาว่างในช่วงปิดเทอมนี้เรียนรู้ในสิ่งที่ผมสนใจ ส่วนตัวผมรู้ตัวช้าไปว่าสนใจในด้านนี้ จึงอยากจะหาความรู้ให้ทันคนอื่น และนำความรู้ที่ได้ตรงนี้ไปต่อยอดในโครงงานต่อ ๆ ไป อีกอย่างผมเองก็สนใจทางด้าน AI มาสักพักหนึ่งแล้วเลยอยากใช้โอกาสที่ทาง AI Builders จัดโครงการดี ๆ แบบนี้ศึกษาเรื่องนี้ไปพร้อมกับโครงการเลย  โมเดลเช็คว่าสินค้ามีโอกาสเป็นของปลอมหรือไม่ ช่วยในการแก้ปัญหาสินค้าปลอมที่เห็นตามแพลตฟอร์มออนไลน์ต่าง ๆ โดยหาชุดข้อมูลจากการทำ web scraping ในหมวด เรตติ้ง ความคิดเห็น คะแนนร้านค้า รูปภาพ ราคา และนำมาเปรียบเทียบข้อมูลกับสินค้าประเภทเดียวกันอื่น ๆ\n",
      "ผมมีความรู้ python ประมาณนึง และยังสามารถเขียนภาษา html css javascriptได้ครับ ผมคิดว่าจะนำเอาความรู้จากโครงการนี้ไปพัฒนาตัวเองต่อไปครับ  ได้มีเพื่อนของผมคนนึงได้สอนผมเขียน html css และ javascript และเขาได้แนะนำผมมาว่า\"ลองมาศึกษาเรื่อง ai ดูมั้ย\" ผมก็มีความคิดว่าเอ้อน่าสนใจดี ผมก็เลยคิดว่าจะได้รับประสบการณ์ใหม่ๆในโครงการครั้งนี้ครับ  ผมมีงานอดิเรกในการปลูกแคคตัสและบางทีผมก็เลี้ยงแคคตัสและผมต้องการจะรู้สายพันธุ์ของแคคตัสเพื่อที่จะได้ไปศึกษาวิธีดูแลต่อไป ผมจึงสนใจในการทำ ai ที่สามารถระบุสายพันธ์ของแคคตัสได้ครับ ชุดข้อมูลสามารถหาได้จาก internet หรือไปศึกษาและเก็บข้อมูลจากสวนแคคตัส\n",
      "ต้องยอมรับ ณ ตรงนี่เลยนะครับว่าผมไม่ได้มีผลงานี่โดดเน้น แต่จะบอกว่าผมเป็นเป็ดที่พอจะสามารถเรียนรู้หลายๆอยากได้แต่ไปไม่สุดสักทาง ผมจึงมีความสนใจนี่อยากจะเอาAIมาประยุกต์ใช้กับการทำงานแขนงอื่นๆให้เกิดความสะดวกสะบาย  ผมอยากเข้าไปเรียนรู้การสร้างAIเพื่อในอนาตค อาจทำAIมาใช้ในการผลิตสื่อต่างๆเพื่อให้ความบันเทิง เข่น การตัดต่อภาพอัตโนมัดิ การปรับเพิ่มลดเสียงเพลงเองตามเสียงระดับเสียงคนร้อง เป็นต้น  ผมอยากทำAI motion capture ที่ให้ตรวจจับมือแล้วใช้ร่างการนั้นในการควบคุมระดับเสียงเพลงและความเร็วของเพลง ตาม กราฟ2มิติ ให้ระดับเสียงเป็น Y ให้ความเร็วเป็น X อาจมีการใส่เอฟเฟคที่เกิดจากmotionต่างๆเช่นหากมือมาโดนกันจะเกิดเสียงตบมือ โดนจะต้องหาชุดข้อมูลคือการข้อมูลรูปภาพมือเพื่อการให้AIรู้จักมือแล้วใช้มือในการควบคุมคล้าย/เหมือนกับ เมาส์ที่ใช้กัน โครงงานสามารถเอาไปต่อยอดในการทำสื่อหรือการแสดงได้และยังสามารถนำไปดักแปรงใช้กับควบคุมสำหรับผู้พิการอีกด้วย\n",
      "ผมมีแรงบันดาลใจมาจากวีดีโอใน youtube ที่สอนให้ AI เดินได้ใน engine unity ผมคิดว่ามันเท่ดีผมเลยอยากเรียนรู้เรื่องเกี่ยวกับ ML และ AI เพิ่มขึ้นครับ  ผมอยากทำ AI ที่ช่วยเกี่ยวกับการคนตาบอดในการเดินทางดวย object detection ปกติพอเวลาคนตาบอดจะเดินทางแลวจะใช้ไม้เท้าในการเดิน AI ของผมจะบอกคนตาบอกวาข้างหน้ามีอะไรด้วยเสียงและเตือนคนตาบอดเวลาจะขามถนนพร้อมกับช่วยนำไปถงทางมาลายและตรวจจบไฟจราจรหาชดขอมลจาก pov ของนักเดินทางใน google และนำมาแมสสิ่งของเองหรือหาจากเว็ปที่ทำ preset video มาให้แล้วครับผมยังไม่แน่ใจนะครับว่าจะเปลี่ยนหรือเปล่า  สัปดาห์แรกที่ผมเข้าค่ายนี้ผมแทบไม่รู้อะไรเกี่ยวกับ ML เลยครับ 5555 ผมคิดว่าตัวเองได้เรียนรู้เยอะมากๆใน 10 สัปดาห์ที่ได้เข้าร่วมโครงการนี้ตั้งแต่ไม่รู้จักคำว่า GAN จนได้มาลองทำเองผมรู้สึกโชคดีมากครับที่ได้มาเป็นส่วนหนึ่งในโครงการนี้ขอขอบคุณพี่ๆเพื่อนๆในค่ายที่ค่อยช่วยเหลือผมตลอดและทำให้ผมรอดมาได้นะครับ\n",
      "เพราะผมมีความชื่นชอบในแวดวง คอมพิวเตอร์และเทคโนโลยีเป็นอย่างมาก ทำให้ผมคอยที่จะมองหาโอกาสที่จะพัฒนาทักษะความรู้ความสามารถที่เกี่ยวข้องกับสาขา คอมพิวเตอร์อยู่ตลอดเวลา อาทิเช่น การฝึกฝนเขียนโปรแกรม และ การศึกษาความรู้ที่เกี่ยวข้องกับคณิตศาสตร์ประยุกต์ เป็นต้น ปัจจุบันผมมีความสนใจที่จะศึกษา และ เพิ่มพูนประสบการณ์ที่เกี่ยวข้องกับสาขาปัญญาประดิษฐ์ ผมจึงหวังเป็นอย่างยิ่งว่า โครงการที่จัดขึ้นในครั้งนี้ จะช่วยทำให้ผมสามารถพัฒนาทักษะต่างๆทีเกี่ยวข้อง เพื่อนำไปสู่การสร้างสรรค์โครงงานปัญญาประดิษฐ์ ที่ก่อให้เกิดประโยชน์ต่อสังคมส่วนร่วมต่อไป\n",
      "อยากเรียนรู้การทำAIในรูปแบบต่างๆ เพราะผมเคยทำโครงงานด้านนี้และรู้สึกสนใจอยากศึกษาจริงจัง และคิดว่าค่ายนี้จะสามารถเพิ่มความรู้และความเข้าใจเกี่ยวกับAIเพิ่มขึ้นนำความรู้ไปพัฒนางานหรือโครงงานที่ทำให้มีประสิทธิภาพและความถูกต้องที่เพิ่มขึ้น หรือได้เรียนรู้หลักการ เทคนิคต่างๆในการเทรนด์โมเดลที่ใช้ในการประมวลผล และสามารถนำความรู้นี้ไปต่อยอดงานด้าน AI ในอนาคตของผมได้\n",
      "เพราะโครงการ AI Builders และ อาจารย์หรือนักวิจัยหลายๆที่ได้รับเชิญเป็นหนึ่งในแรงบันดาลใจ ทำให้เริ่มต้นเส้นทางสาย AI ด้วยการศึกษาจากในอินเตอร์และเน็ตจึงทำให้มีพื้นฐาน ภาษาpython การใช้ numpy pandas ในการจัดการข้อมูล แล้วนำมาทำ Data visualization สามารถทำ web scraping ได้ รู้จักโมเดล machine learning ต่างๆ มีพื้นฐาน deep learning เล็กน้อย  เหตุผลที่ทำให้อยากเข้าร่วมโครงการเริ่มจากในปีที่แล้วได้เห็นโครงการที่มีชื่อว่า AI Builders และเกิดความสนใจเป็นอย่างมากแต่เนื่องจากปิดรับสมัคร จึงตัดสินใจติดตามกิจกรรมที่ได้ลงย้อนหลังใน facebook เป็นจุดเริ่มต้นที่จุดประกายความชอบด้าน AI จึงได้เริ่มศึกษาการเขียนโปรแกรมภาษา python และ library ต่างๆที่ใช้การจัดข้อมูลทำให้รู้สึกสนุกกับคณิตศาสตร์มากขึ้นเพราะไม่ได้ใช้คิดคำนวนเพียงในห้องเรียน แต่สามารถนำมาประยุกต์ตอบปัญหาต่างๆได้ ต่อมาค่อยศึกษาด้าน AI มากขึ้นพบว่าศาสตร์นี้มีความน่าหลงใหล ทั้งในเรื่องของการใช้แก้ปัญหา และ ในด้านแนวคิดเชิงปรัชญาในกระบวนการทำงานของ AI เมื่อโอกาศที่ดีอย่างโครงการนี้กลับมาอีกครั้งผมเลยคิดว่าต้องลงให้ได้ ถ้าได้รับคัดเลือกผมจะนำความรู้ด้านต่างๆ เช่น NLP image pocessing ฯลฯ และ ประสบการณ์ที่ได้ถ่ายถอด เหล่าพี่ๆ mentor ไปทำ project ที่ก่อให้เกิดประโยชน์ต่อสังคมไม่มากก็น้อย ขอบคุณครับ  ปัญหาเมื่อมีการบึกทึกภาพในที่มืดแล้วนั้นทำให้รายละละเอียดภายในภาพไม่ชัดเจนและคลุมเครือ และ อาจนําไปสู่การตีความสิ่งอยู่ในภาพผิดไปจากความเป็นจริง ซึ่งการเพิ่มแสงด้วยโปรแกรมแต่งภาพจะทำให้รายละละเอียดไปได้หากไฟล์คุณภาพต่ำ ผมจึงอยากจะทำAI ที่สามารถ generate ภาพจากภาพที่มืดและมีรายละเอียดไม่ชัดเจนให้มีความสว่างให้สามารถมองเห็นสีและรายละเอียดวัตถุภายในภาพได้ชัดเจนเหมือนตอนกลางวัน ในส่วนของ Data set จะเป็นถ่ายภาพในสถาที่และมุมกล้องเดี่ยวกันแต่แบ่งออกเป็น ภาพที่สว่าง และ ภาพที่มืด\n",
      "เป็นคนที่มีความรู้ความชื่นชอบทางด้านคณิตศาสตร์เป็นอย่างมาก คณิตศาสตร์ถือเป็นวิชาที่ถนัดที่สุดสำหรับผม เป็นคนที่ถ้าได้ตั้งใจทำอะไรบางอย่างแล้วก็จะทุ่มเทให้กับสิ่งนั้น แบบ มี 100 ให้ 100 ไปเลย, มีผลงานที่เป็นผลจากความทุ่มเทอยู่บ้างเช่น การแข่งหุ่นยนตร์ รายการ wrg , สพฐ 9ล9 และกิจกรรมการเข้าร่วมกับค่าย ที่เกี่ยวกับคอมพิวเตอร์และเทคโนโลยีต่างๆ, มีเวลา พร้อมที่จะสละให้กับโครงการนี้อย่างเต็มที่, มีความสามารถเข้ากับคนอื่นได้ง่าย, และมีความสนใจในปัญญาปัญญาประดิษฐ์!  อยากเข้าเพราะ ตั้งแต่ที่ได้เห็นพัฒนาการของเทคโนโลยีตั้งแต่เด็ก จนถึงปัจุบันที่สิ่งต่างๆเติบโตขึ้นเร็วมาก มีสิ่งใหม่ๆออกมาให้เราเห็นทุกวัน ทุกอย่างทั้งน่าตื่นเต้น และน่าสนใจ จนเราเอง ก็อยากเป็นคนที่ได้ร่วมพัฒนาสิ่งเหล่านั้นแหละเติบโตไปพร้อมกับมัน แต่เนื่องจากผมไม่ได้มีประสบการณ์ในด้านนี้มาก มีแต่ความตั้งใจและความรู้ทางด้านคณิตศาสตร์ โครงการนี้จึง \"สำคัญกับผม\" ที่จะทำให้ผมได้เริ่มต้นเส้นทางนี้อย่างจริงจัง! และจะเป็นอีกหนึ่งประสบการณ์ที่จะช่วยต่อยอดการทำโครงงานจบ และการเรียนต่อมหาลัยในอาคต  อีกทั้ง เรื่องความดูแลเอาใจใส่ที่มีมาให้ตั้งแต่ยังไม่ได้ร่วมโครงการเลยด้วยซ้ำ เช่นเรื่อง Pre-course Workhop เพื่อปรับพื้นฐาน, ตารางการเรียนที่ชัดเจนจริงจัง, แบบทดสอบที่มีมาให้ม รุ่นพี่ที่ผ่านโครงการนี้มาปีที่แล้ว ก็มีแต่ผลงานเจ๋งๆ มีคุณภาพ ออกมา แบบนี้ใครจะไม่อยากเข้าร่วมโครงการนี้ครับ!! ผลงานแบบนี้ต้องมี mentor และ TA เก่งๆคอยให้คำแนะนำแน่นอน! :) ขอบคุณครับ  อยากทำ ai ที่ ช่วยเราหา \"เพลง\" เพื่อแก้ปัญหา => เวลาที่จำได้แค่ทำนองเพลง หรือถึงจำเนื้อร้องได้ แต่เนื้อร้องดันเป็นภาษาอะไรก็ไม่รู้ ทำให้เรารู้สึกหงุดหงิด คิดไม่ออกสักทีว่า เพลงที่ร้องแบบนี้มันชื่อเพลงอะไรนะ!?? มีรูปแบบการทำงานคร่าวๆ เริ่มต้นที่ รับข้อมูลเสียง(เสียงทำนอง,เสียงร้อง) > ai ประมวลผล > แสดงเพลงที่ประมวลผลได้ออกมาให้ผู้ใช้ ใช้ชุดข้อมูล จำพวก เนื้อเพลง และ เสียงเพลง มาจาก kaggle\n",
      "ผมเคยเข้าร่วมคอร์สการจัดการข้อมูลโดยใช้ Excel เพื่อหาวิธีการที่มีประสิทธิภาพที่สุด , Data Science เบื้องต้น และการใช้ AI เพื่อสร้างเสียงเสมือน  อยากลองเรียนสายอื่นดูบ้างครับ เพราะตอนนี้เรียนอยู่เป็นเอก DE ที่จะเน้นการจัดการข้อมูลใน Database เป็นหลัก อยากลองทำอย่างอื่นบ้างอะครับ (และก็มาหา Portfolio ไปเผื่อเข้ามหาวิทยาลัยด้วยครับ)  อยากจะทำการประมวลผลภาษาให้ได้ Real-Time เพื่อจะได้ลดช่องว่างระหว่างภาษาและสามารถเข้าใจกันได้ง้ายขึ้น ปัจจุบันก็มีบ้างแล้วแต่ยังไม่แม่นและแพร่หลายขนาดนั้น\n",
      "ผู้เขียนมีความสนใจทางด้าน machine learning เป็นอย่างมากและยังมีความมุ่งมั่นที่จะทำให้สำเร็จ ปัจจุบัน machine learning & AI มีบทบาทกับเราแทบทุกด้าน แต่การจะทำให้ AI ใช้งานได้ในแต่ละด้านนั้นแตกต่างกันอย่างสิ้นเชิง ผู้เขียนจึงอยากเก็บเกี่ยวประสบการณ์ตั้งแต่การสร้างไปจนถึงการนำไปใช้ของ Machine learning & AI ในแต่ละด้านเพื่อขยายขอบเขตไอเดียของตัวเองและเมื่อไอเดียที่เข้าท่ามาถึง ผู้เขียนก็สามารถลงมือทำได้เลย โดยรู้ว่าด้านที่จะทำนั้นต้องใช้ model ประมาณนี้ รู้แหล่งชุดข้อมูลและรู้คีย์เวิร์ดที่จะศึกษาเพิ่มเติม นอกจากนั้นการเข้าโครงการนี้จะทำให้เราได้เจอกับเมนเทอร์และเพื่อนร่วมโครงการที่มีความชอบ เหมือนๆ กัน เมื่อเค้ามีความถนัดในด้าน machine learing ที่เราจะทำเราก็สามารถขอคำแนะนำจากเค้าได้และในทางกลับกันเราก็สามารถให้คำแนะนำในด้านที่เราถนัดแก่เพื่อนร่วมโครงการได้เช่นกัน เป้าหมายของผู้เขียนคือการสร้างนวัตกรรมหรือสิ่งประดิษฐ์ที่ทุกคนสามารถใช้ได้อย่างแพร่หลายและเกิดประโยชน์จากการใช้งานนั้น ซึ่งปัจจุบันผู้เขียนอยากศึกษาเพิ่มเติมทางด้าน Machine learning & AI อยากลองศึกษาศาสตร์แขนงใหม่ๆของ machine learing อาทิเข่น NLP, time series, GAN และอยากศึกษาวิธีการนำไปปรับใช้กับปัญหาในชีวิตจริง  อยากทำการสร้างรูปสังเคราะห์จากข้อความภาษาไทย (text to image genarator) เพื่อจำลองการออกแบบผลิตภัณฑ์เบื้องต้นจากไอเดียแล้วนำไปประเมิณว่าสามารถนำไปต่อยอดได้มากเพียงใดหรือเพื่อค้นพบไอเดียใหม่จากรูปที่สังเคราะห์ขึ้นมา เช่น อยากออกแบบดีไซน์เก้าอี้จึงพิมพ์ไปว่าเก้าอี้ทรงทุเรียน ตัวโมเดลอาจจะให้ผลลัพธ์เป็นเก้าอี้ที่มีหนามทุเรียนเป็นขาหรือเก้าอี้ที่ใช้หนามมนเป็นที่นั่ง และอื่นๆที่ผู้เขียนคาดไม่ถึง ชุดข้อมูลรูป ใช้จาก COCO โดยส่วนมากจะเป็นรูปสิ่งของต่างๆ, ชุดข้อมูลคำ ใช้คำที่ผ่านการ embedded มาแล้วโดยใช้ thai2vec ด้วย PyThaiNLP, นอกจากนี้ถ้าเปลี่ยนชุดข้อมูลใหม่โดยใช้รูปหน้าคนแล้วเทรนให้โมเดลสร้างหน้าคนจากคำบอกเล่าของพยานก็จะสามารถสร้างรูปคนร้ายเพื่อใช้ในการตามหาตัวหรือทำรูปติดประกาศจับ การทำแบบนี้จะสามารถลดระยะเวลาการสเก็ตช์ภาพขั้นต้นและสามารถโฟกัสกับการปรับแต่งขั้นสุดท้ายให้ภาพตรงกับคนร้ายที่พยานเห็นมากที่สุด ก็เป็นอีกโครงงานหนึ่งที่น่าทำเช่นกัน\n",
      "ผมได้เข้าค่าย สอวน. ค่าย 1 และ 2 วิชาคอมพิวเตอร์ ที่มหาวิทยาลัยนเรศวร ทำให้ผมได้รู้จักกระบวนการคิดต่างๆ ตั้งแต่ เบสิกของการเขียนโปรแกรม ตั้งแต่ การปริ้น, อินพุต, if-else, loop ไปจนถึงการสร้าง Function, Data Structure และ การทำงานของ Algorithm ต่างๆ นี่เป็นจุดเริ่มต้นที่ทำให้ผมสนใจ ในการเขียนโค้ดตั้งแต่นั้นมา  ผมมีประสบการณ์ การทำ data analytic จากโครงงานเรื่อง การวิเคราะห์อารมณ์ของคอมเมนต์เกี่ยวกับสมาร์ทวอทช์ผมได้ท ากระบวนการของ data science ตั้งแต่การเก็บข้อมูล, การหาแหล่งข้อมูลจากที่ต่างๆ การทำ data cleansing เพื่อเช็คว่า คอมเมนต์นั้นใช้ได้ไหม เช่น การตัดข้อความที่เป็นอิโมจิออก, การวิเคราะห์ข้อมูล และการทำให้ข้อมูลสามารถเข้าใจได้ง่าย จากการทำ data visualization  ผมอยากทำความเข้าใจเกี่ยวกับ ปัญญาประดิษฐ์ มากยิ่งขึ้น รวมถึงกระบวนการทาง data science ตั้งแต่การเก็บข้อมูล, การทำ data cleansing วิเคราะห์ข้อมูล จนไปถึง การทำ data visualization เพื่อที่จะ สามารถทำการวิเคราะห์ข้อมูลได้อย่างมีประสิทธิภาพ ผมอยากเห็นแรงบันดาลใจ จากกลุ่มคนที่สนใจ ในเรื่องเดียวกับผม มาพยายามทำความเข้าใจศึกษา และพัฒนาความรู้ เพื่อที่จะสามารถนำไปพัฒนาต่อยอดในอนาคต เพื่อสรรสร้างปัญญาประดิษฐ์เป็นฉบับของตนเอง\n",
      "กระผมเคยได้มีโอกาสในการร่วมเข้าการแข่งขันในงาน TMLCC เมื่อปี 2021 โดยที่ผมได้ช่วยเหลือในการนำ dataset มา clean และ select data ที่น่าสนใจนำไปใช้ใน algorithm มีแรงบันดาลใจที่จะเขียนโค้ดจากเพื่อนของผมที่แสดงให้เห็นถึงความสำคัญและศักยภาพของ AI ทำให้ผมได้ศึกษาและเรียนรู้การเขียนโค้ดมาเรื่อยๆในระยะเวลา 1 ปีที่ผ่านมานี้แต่ยังไม่ได้เริ่มเขียนโปรเจคแบบจริงๆจังๆสักครั้งเลยอยากจะลองทำดูในโครงการนี้ครับ  เหตุผลที่ผมอยากเข้าร่วมโครงการนี้เริ่มต้นมาจากการได้เห็นเพื่อนของผมคนหนึ่งที่ได้มีความสนใจในด้าน AI ได้ชวนผมมาทำโครงงานแข่งด้าน AI แล้วและยังเคยเข้าร่วมโครงการนี้ได้มาชวนผมให้มาลองศึกษาและเข้าใจการทำงานและการสร้าง AI อีกทั้งผมยังเคยได้เข้าค่ายแพทย์ของมหาลัยวิทยาลัยธรรมศาสตร์ โดยในค่ายนั้นได้มีการบรรยายเกี่ยวกับ Digital Hospital ในหัวข้อของ AI ทำให้ผมมีความสนใจในด้านนี้อยู่แล้วได้ตัดสินใจที่จะเข้าร่วมโครงการนี้ ทั้งนี้ผมเลยเห็นโครงการนี้เป็นโอกาสอันดีที่ควรจะคว้าไว้เพื่อต่อยอดในการศึกษาและการงานของผมในอาชีพแพทย์ได้ครับ  เพลงในโลกนี้มีมากกว่าที่จะนับได้ทั้งหมด ทั้งเป็นเพลงที่เป็นที่รู้จักกันอย่างดีหรือมีคนรู้จักเพียงหยิบมือ แต่ทั้งนี้เพลงก็จะถูกแบ่งประเภทด้วยสิ่งที่เรียกว่า Genre หากแต่เป็นเพียงสมัยก่อนยุคเพลง Digital การใช้หูฟังเพื่อแบ่งแยกนั้นอาจไม่ต้องการประสบการณ์ในการฟังเพลงที่มากนัก แต่กระนั้นเองยุคสมัยในการผสมผสานการทำเพลงแบบดิจิตอลก็เข้ามาถึงทำให้เกิดเพลงประเภทหนึ่งขึ้นมานั้นคือ Electronic Music แต่ส่วนมากเราจะได้ยินกันทั่วไปคือ EDM หรือ Electronic Dance Music อย่างไรก็ตาม electronic music นั้นเป็นเพลงที่เกิดขึ้นจากเสียงสังเคราะห์ทำให้เกิดความหลากหลายที่มากกว่าเดิมจากเพลงที่เกิดจากเครื่องดนตรีตามปกติทำให้เกิด genre และ subgenre ขึ้นมากมายและมีจำนวนเพิ่มขึ้นอย่างไม่หยุดอันเป็นเหตุทำให้ทำให้หลายบุคคลเกิดความสับสนและโต้แย้งกันถึง genre ของเพลงบางเพลงจนถึงวันนี้ ตัวอย่าง genre สามารถหาดูได้ทางนี้ https://www.reddit.com/r/electronicmusic/comments/dbxf5x/extremely_genre_specific_relectronicmusic/ ผมจึงมีความคิดที่จะทำ AI ที่สามารถรับไฟล์เพลง หรือถ้าเป็นไปได้ก็รับค่า input จากเพลงที่เล่นอยู่และบอก Genre ใหญ่ๆให้คนทั่วไปเข้าถึง Genre ของ EDM ได้มากขึ้น ส่วนชุดข้อมูลนั้นเราสามารถหาโหลดได้จาก Youtube, Spotify, Soundcloud, Mixcloud เป็นต้น\n",
      "ผมมีความพร้อมและความปรารถนาในการเรียนรู้และประยุกต์ AI ผมมีพื้นฐานการเขียนโปรแกรม และผมยังมีความเข้าใจใน computer science ระดับหนึ่งจากโครงการคอมพิวเตอร์โอลิมปิกวิชาการ ในระดับค่ายสสวท. 1 นอกจากนี้ผมเคยเข้าโครงการ FIBO-School Consortium รุ่นที่ 5 ในสาขา deep learning ที่ผมได้เรียนรู้ intuition ของ neural network, CNN, fine-tuning และผมมีประสบการณ์ใน web development โดยผมมีโครงงานคอมพิวเตอร์ที่ใช้ Google Geolocation API ในการกำหนดพื้นที่แชร์ไฟล์ ส่วนตอนนี้ผมกำลังสร้างโปรเจคโดยใช้ MERN stack (MongoDB, Express, React, Node)  เมื่อก่อนนั้น AI เป็นสิ่งที่ค่อนข้างจะไกลตัว ไม่ว่าจะเป็นในด้านการใช้ประโยชน์หรือการหา resource เรียน แต่ในตอนนี้ AI กลายเป็นสิ่งที่มันเริ่มคืบคลานเข้ามาในชีวิตเรามากขึ้นและทุกคนก็สามารถเริ่มได้ แต่ด้วยประสบการณ์ของผมที่เคยเรียนสาย web development ผมบอกได้เลยว่า resource ของการเรียนเช่น MERN stack มันหาง่ายและ intuition ง่ายกว่าการเรียน AI ด้วยตัวเอง ผมเลยอยากจะใช้โอกาสนี้เพื่อศึกษา ทำความเข้าใจ และนำ AI มาปฏิบัติจริงในโครงการ AI Builder 2022 ที่มี mentor ผู้สามารถทำให้ผมกระจ่างในข้อสงสัยต่าง ๆ และเพื่อน ๆ ในโครงการที่จะคอยเรียนและผลักดันไปด้วยกัน ตอนนี้ผมพร้อมแล้วที่จะเข้าสู่ discipline แขนงนี้ไม่เหมือนเมื่อก่อนที่ผมยังขาด intuition บางส่วน เช่นการเขียนโปรแกรมเบื้องต้น หรือคณิตศาสตร์บางบท นอกจากนี้แล้วผมยังอยากจะมาสร้าง connection กับคนในโครงการนี้ไม่ว่าจะเป็น mentor หรือผู้สมัครโครงการ เพราะผมเชื่อว่าเป็นการเก็บจุดที่จะได้ใช้ในอนาคตแน่นอน เช่นผมอาจจะมีการทำงานร่วมกับคนในโครงการนี้ในอนาคต และผมรู้สึกว่า community ที่เกี่ยวกับคอมพิวเตอร์ในไทยนั้นมีความเกี่ยวพันกันมาก ผมก็พอจะสังเกตเห็นหลายคนที่มีส่วนร่วมในโอลิมปิกวิชาการมาทำ AI ฉะนั้นการทำความรู้จักคนมากก็ไม่ใช่สิ่งที่เสียหาย และยังอาจจะเปิดโอกาสให้ผมได้เรียนรู้จากคนอื่น ๆ อีกมากมาย\n",
      "I wish to join the organization AI Builders because of my interest within the AI field. I had first been introduced to this field from a background of playing video games. I played these video games and gained an interest in what ran in the background of video games. I wanted to know how these games worked and soon began pursuing a way in which to learn how to code. I started of attempting to learn how to code in a language called LUA. It wasn\\t easy nor very successful but it opened my eyes to what was possible with the lines of code that you could write. Wanting to know more about this, I soon ventured into a course known as CS50 (https://cs50.harvard.edu/x/2021/). I learned the basics about coding such as python, c, sql, html, etc. during this course. Wanting to know more, I continued learning after finishing this course. As someone recommended to me that there was a CS50Ai course (https://cs50.harvard.edu/ai/2020/) after that I continued to expand my knowledge and finished the course. At the same time I took \"Take The World Forward Fellowship\" (https://learnwithleaders.com/taketheworldforwardfellowship/) in order to attempt to apply my knowledge to make something that could be applicable in the real world. Now I believe that the next step for me is to join \"AI Builders\" in order for my next step to apply my knowledge into something in the real world.  I wish to be a part of AI Builders because I have an interest in the AI field. I believe that AI, in the future, will be a major part of our lives. I think that by joining with this organization, I build upon and learn new concepts and lessons and apply them to the projects that I can make in the real world. I think that this organization is greater than doing it individually since we can ask the mentors from the organizations and our peers for advice on for our specific project. These mentors have experience in doing this type of stuff so it would be greatly beneficial to have them guide us through this experience. Another benefit of this organization is that they have prepared us lessons which can also guide us when creating this project. We can learn new concepts in which we can immediately use them in the real world by incorporating them into the projects that we are making.  During my time at the \"AI builders\" program, I plan to construct garbage classification machine. It should be able to the differentiate the different types of materials. An image from a camera set up inside the machine take a picture of the garbage that the user puts in. Then, based on the image, an AI will classify the type of garbage that it is. It can classify the items by the material of the item. Lastly, there will be a mechanism in the machine that can push the garbage into its specific garbage chute. This machine will help group the same types of material together, hopefully making recycling easier since the garbage is classified into different materials.\n",
      "I am a highly-motivated person who strives to make a difference in Thai society. I have a habit of observing the problems that various groups of people around me have been facing and thinking about the solutions to their problems. For instance, as flooding becomes a frequent natural disaster that affects people in Lopburi, my friends and I have helped plant trees at Pasak Chonlasit Dam to alleviate the problem for the past few years. More recently, I was selected to participate in the Young Changemakers Program organized by the School of Changemakers organization. There, I teamed up with my peers to raise awareness about cybercrimes in Thailand. Also, I realized that I’m passionate about applying technologies, including AI, to address social issues. Though I still lack the advanced math and computing background that I believe is a prerequisite for being a great AI developer, I have the willingness to learn and the motivation to excel in whatever I do, as well as my love of helping others.  \"With my limited experience in the field of AI, I had a major preconception of what an AI was. I always thought that anything related to AI was daunting and complex. To me, it wasn’t something that a high-schooler would be able to comprehend. However, when I got a chance to work with a professor at KMITL on an image processing project to closely observe a cricket population, my perception of AI has been shifted. In the beginning, I didnt know anything about image processing, so I started studying computer programming and image processing algorithms. Looking back, I was elated that I took on this research journey. I was fortunate that I had a KMITL student and my professor to help me navigate the enormous world of AI. It has been challenging, but rewarding, and I started to believe that I, as a high-schooler, can appreciate the versatility of AI as well. Also, I realized that there is so much more to see in this particular field. So, I decided to apply to this AI Builders program, with a strong determination to learn as much as I can about AI and explore the many ways to use its capability to build something to impact our society. With the guidance from AI experts in this program, I believe I will get to where I set to achieve.\",  My inspiration for this project derives from my ongoing work on cricket population surveys using image processing to help farmers keep track of their cricket farms. It led me to wonder about how to assist other farmers in taking care of their livestock. Population counting is just one of the measures of animal well-being, sanitation, and farm productivity. For other animals, there are other measures. For example, recently, there has been a national-level incident involving African Swine Fever, causing deaths in pigs throughout the country and the prices of pork to skyrocket. With early intervention using AI, it may be possible for farms to prevent such catastrophes from happening again. Data for this project can come from live video footage from cameras installed on the farm and sensors that attach to animals to detect anomalies, as well as “cleanliness” sensors at all the gates to assess the farm sanitation.\n",
      "Although I do not have much in the way of experience in actual coding or machine learning (my projects mostly being minuscule in scope and being limited to some facet of regex or language learning with Python serving as the consistent backdrop), I believe I do have a general background in the mathematical (though not so much the statistical) foundations of the course; I am comfortable with most of the basic knowledge required to do derivative and integral calculus, having learned and relearned them previously many times; however, I unfortunately do not believe I have covered the necessary background required for vector calculus, by extension from the requirement given for understanding of partial derivatives. I have in the past attempted to teach myself linear algebra as well, although I have retained little from that. I do believe, however, that my ability to focus and diligently persevere, while keeping an eye out for more efficient methods, as alluded to in the examples in regards to my mathematical education, will be a boon, should I be able to take part in the project.  I also, of course, believe in the spirit of open-source; the ability to open doors for those less fortunate than oneself should be a motivating factor for anyone, especially in a country so rife with inequality as ours. Ultimately, I wish to assist in addition to myself the general public, in order to better the opportunities afforded to anyone and everyone, regardless of social standing, geographical isolation, or otherwise.\n",
      "เนื่องจากโรงเรียนของผมเป็นโรงเรียนวิทยาศาสตร์ทำให้ผมได้ทำโครงงานวิทยาศาสตร์ที่ต้องศึกษาหาความรู้ด้วยตนเองแล้วก็มีอาจารย์ครูที่ปรึกษามาแนะนำเกี่ยวกับโปรเจคการปรับปรุงน้ำดิบเพื่อนำมาผลิตน้ำประปา ที่ได้ผลิตน้ำประปาเองเป็นส่วนใหญ่เนื่องจากน้ำประปาที่ส่งมาจากการประปาไหลมาไม่เพียงพอต่อบุคคลในโรงเรียน โดยโรงเรียนได้มีการผลิตน้ำเองมาก่อนหน้านี้แล้ว แต่ยังพบว่าน้ำไม่ค่อยได้มาตราฐาน จึงทำให้ผมและคุณครูได้คิดที่จะทำเครื่อง Jartest (สามารถดูเพิ่มเติมได้ในผลงานครับ) ที่ใช้ในทดลองเพื่อหาปริมาณของสารเคมีที่เหมาะสมต่อการผลิตน้ำประปา และเมื่อทำเครื่องเสร็จผมพบกับปัญหาที่ว่า น้ำดิบมีคุณสมบัติไม่เหมือนกันตลอดทั้งวัน ทำให้ต้องมีการทำ Jartest 3 ครั้งต่อวันเพื่อปรับเปลี่ยนอัตราส่วนของสารเคมีให้เหมาะสมต่อการปรับปรุงน้ำดิบ ผมจึงได้หาข้อมูลต่อที่จะช่วยทำให้การปรับปรุงน้ำดิบได้รวดเร็วมากขึ้น ซึ่งเป็นการนำ deep learning มาประมวลผลข้อมูลทางสถิตจากข้อมูลก่อน-หลังการทดลองและปริมาณสารที่เติม และประมวลผลภาพของขนาดตะกอน แล้วผมก็มาพบกับโครงการ AI Builders ที่มีการอบรมเกี่ยวกับ Data Sci และ AI ซึ่งตอบโจทย์ต่อโปรเจคที่ผมสนใจเป็นอย่างมาก แล้วมีการประยุกต์องค์ความรู้ที่เรียนมาใช้ในการแก้ไขปัญหาในชีวิตประจำวันได้อีกด้วย ดูได้จากการนำเสนอผลงานของรุ่นที่แล้วมีความน่าสนใจมากครับ แล้วผมมั่นใจว่าโครงการจะมอบประสบการณ์และเทคนิคในการทำงานเกี่ยวกับAi ให้ผมอย่างมากครับากครับ จึงทำให้กระผมอยากเก็บเกี่ยวประสบการณ์เกี่ยว AI จากโครงการนี้ครับ\n",
      "ผมมีความรู้ด้านฐานข้อมูลเบื้องต้น พอสมควร จากการเรียนในเอก DE : Digital Engineering ของโรงเรียน เข้าใจหลักการทำงานของฐานข้อมูลเบื้องต้น แต่จุดด้อยของผมคือการเขียนโปรแกรมที่ยังเขียนได้แค่พื้นฐาน แต่ผมก็พร้อมที่จะเรียนรู้ และทำความเข้าใจการเขียนโปรแกรมที่สูงขึ้น ผมพร้อมจะไปหาข้อมูลเพิ่มเกี่ยวกับเรื่องที่ผมยังไม่รู้ และยังไม่เข้าใจ ครับ  ที่ผมอยากเข้าก็เพราะอยากฝึกการเขียนโปรแกรมในระดับที่สูงขึ้นกว่าเดิม อยากจะพบเจอพี่ เพื่อน หรือน้อง ที่มีความรู้และความสนใจในด้านนี้เหมือนกันเพื่อที่จะได้แลกเปลี่ยนข้อมูลกัน อีกอย่างคือผมอยากที่จะลองสร้างระบบที่มีการใช้ฐานข้อมูล และเอไอ มาช่วยคำนวณสิ่งต่างๆ ในชีวิตประจำวันเหมือนกับที่ประเทศญี่ปุ่นที่มีการนำระบบมาใช้ในร้านแห่งหนึ่ง มันเป็นระบบที่จะคำนวณหาจำนวนวัตถุดิบที่ต้องใช้ จากสถิติการสั่งเมนูของลูกค้า ซึ่งผลออกมาเป็นที่น่าพึ่งพอใจอย่างมาก ทางร้านมียอดขายที่เพิ่มขึ้น และวัตถุดิบที่สั้งมาก็เพียงพอกับจำนวนของลูกค้า โดยวัตถุดิบไม่เกินความจำเป็น อยากจะนำความรู้จากการเรียนที่โรงเรียนเกี่ยวกับฐานข้อมูลมาลองปรับใช้ดูในการเขียนโปรแกรมจริงๆ ครับ  หนึ่งโครงงานที่ผมแยกาทำคือการคำนวณการเปิดปิดไฟแดง โดยการใช้ image processing ในการนับจำนวนรถในแต่ละแยกแล้วนำมาคำนวณว่าควรจะปล่อยแยกไหนก่อน เพื่อลดปัญหาการจารจรติดขัดครับ\n",
      "ผมมีความมุ่งและมีความฝัน ที่จะผลิต คิดค้น นวัตกรรมใหม่เพื่อให้ตอบโจทย์ปัญหาทางสังคมใน ประเทศไทย และ ทั่วโลก เพื่อให้ผู้คนมี การเป็นอยู่ที่ดียิ่งขึ้น โดยการใช้เทคโนโลยี ร่วมกับ สาขาวิชา ต่างๆ อาชีพที่ผมใฝ่ฝันที่จะเป็น คือ วิศวะกรรมคอมพิวเตอร์ เพราะผมต้องการหาความรู้ด้าน คอมพิวเตอร์ เพื่อที่จะนำความรู้ที่มีมากขึ้นมาสร้าง นวัตกรรมใหม่ๆ ให้สังคม และสาขาที่อยากเรียน เสริม คือการบริหารธุรกิจ เพราะการเงินเป็นเรื่องสำคัญสำหรับทุกคน จึงอยากได้ความรู้ด้านการเงิน ควบคู่กับการสร้างนวัตกรรม เพื่อพัฒนา สังคม เเละ เศรฐกิจของไทยอย่างมั่นคงเเละยั่งยืน\n",
      "- ผมมีความสนใจในวิทยาศาสตร์ข้อมูล และกำลังทำโครงงานกลุ่ม เกี่ยวกับ “การใช้ AI ตรวจจับข่าวลวง” - ก่อนหน้านี้ ผมมีความรู้ Machine learning และ NLP เบื้องต้น จึงได้ลองพัฒนาโมเดล AI จัดจำแนกข่าวลวงภาษาอังกฤษ (ใช้ dataset ใน Kaggle.com) แต่ได้ความแม่นยำ ค่า recall และ F1-score ออกมาต่ำ ไม่เพียงพอต่อการใช้จริง (ถ้าหากนำไปใช้จริง อาจเกิดอันตรายต่อผู้ใช้งาน) - จากการค้นคว้าข้อมูลเพิ่มเติม ผมพบว่า ผมยังไม่ได้ลองใช้ deep learning และ transformer อย่างเช่น BERT ที่อาจให้ความแม่นยำสูงกว่า ในการแก้ปัญหานี้ - ** จากหลักสูตรของโครงการ ผมคิดว่าโครงการนี้ จะช่วยเสริมสร้างความรู้และทักษะที่เพียงพอสำหรับการสร้างโมเดล Deep learning ที่มีความแม่นยำสูง รวมทั้งชี้แนะแนวทางในการ Deploy โมเดลให้เป็นเครื่องมือ AI ตรวจจับข่าวลวง (ทั้งภาษาไทย และอังกฤษ) ที่ใช้งานได้จริง และสร้างคุณค่าให้สังคม ** - ป.ล. ผมยังมีความสนใจด้าน Text Generation เนื่องจากผมเป็นคนชอบเขียนบทกวี ผมมีความคิดว่า สักวัน จะสร้าง AI ที่แต่งกลอนได้ไพเราะเท่าท่านสุนทรภู่\n",
      "หนูเคยเข้าร่วมการาแข่งขันคอมพิวเตอร์โอลิมปิกระดับชาติ ทำให้มีทักษะกระบวนการคิดที่เป็นเหตุเป็นผล เป็นลำดับอยู่พอสมควรและถึงหนูจะไม่ค่อยมีประสบการณ์ด้าน AI แต่หนูมีความเชื่อมั่นและมีความมุ่งมั่นที่จะทำมันให้ได้ค่ะ และเป็นคนที่ชอบค้นคว้าอยู่แล้ว จึงคิดว่าหนูสามารถที่จะเรียนรู้และพัฒนาตัวเองได้ค่ะ ในด้านของการทำงาน หนูเคยได้รับเชิญเป็นผู้ช่วยวิทยากรในการอบรมคอมพิวเตอร์โอลิมปิกค่าย 1 ทำให้มีทักษะการทำงานเป็นทีมร่วมกับทีมวิทยากร  เหตุผลที่อยากเข้าร่วมโครงการนี้เพราะ เป็นคนที่พอมีพื้นฐานการเขียนโปรแกรมอยู่บ้าง เนื่องจากผ่านการเข้าค่ายสอวน.คอมพิวเตอร์ และมีความชื่นชอบในการเขียนโปรแกรม จึงพยายามศึกษาด้วยตนเองในการเขียนภาษา python จึงคิดว่าอยากนำความรู้พื้นฐานที่มีตอนนี้ พัฒนาต่อยอดให้เกิดประโยชน์มากขึ้นได้ก็จะดีมาก โดยได้เล็งเห็นว่า AI เป็นสิ่งที่น่าสนใจมาก สามารถทำหลายอย่าง และแม่นยำได้มากกว่ามนุษย์ และโครงการนี้ก็จะเปิดโอกาสให้หนูได้เรียนรู้และเข้าใจเกี่ยวกับ AI มากขึ้นได้ และอยากได้ลองปฏิบัติจริงเพราะคาดหวังว่าโครงงานของหนูหากได้ทำสำเร็จแล้วจะเป็นประโยชน์กับกลุ่มเป้าหมายค่ะ\n",
      "หนูสนใจการเขียนโปรแกรมและเอไอจากการเล่นเกมและก็ดูหนังเกี่ยวกับการเขียนโปรแกรมค่ะ หนูรู้สึกว่าการสร้างเกม แอพ เว็บไซต์ สร้างหุ่นยนต์มันเท่มากเลยค่ะ และมันก็น่าหลงไหลมาก หนูชอบที่จะเรียนรู้และก็เขียนโค้ดทำเกมมากเลยค่ะ กิจกรรมที่หนูเคยเข้าร่วมเกี่ยวกับประสบการณ์ทางด้านนี้ก็มีการทำรถหุ่นยนต์ค่ะ หนูอยากเป็นส่วนหนึ่งของค่ายนี้จริงๆค่ะ หนูอยากเรียนรู้และก็พัฒนาทักษะทางด้านนี้และนำไปพัฒนาเทคโนโลยีต่างๆในอนาคตค่ะ ฝากพี่ๆพิจารณาด้วยนะคะ  หนูอยากมีประสบการณ์ทางด้านนี้ให้มากขึ้นค่ะ หลังจากหนูได้เข้าร่วมชมปรับพื้นฐานแล้วหนูรู้สึกว่าหนูมีความชอบและสนใจเรื่องนี้มาก พี่ๆที่สอนปรับพื้นฐานก็สอนเข้าใจง่ายและหนูรู้สึกว่าถ้าหากพลาดค่ายนี้หนูจะต้องเสียดายมากแน่เลยค่ะ หนูอยากเข้าร่วมเป็นส่วนหนึ่งของโครงการและเก็บเกี่ยวความรู้และประสบการณ์ให้ได้มากที่สุดค่ะ\n",
      "ผมมั่นใจว่าผมจะสามารถพัฒนาคนเองและ นำองค์ความรู้ที่ได้รับจากโครงการนี้ไปใช้พัฒนาต่อยอด หรือสร้างสรรค์นวัตกรรมใหม่ ๆ เพื่อสร้างประโยชน์ให้แก่ส่วนรวมได้ โดยแรงบรรดาลใจได้มาจากการที่ตนได้รู้จักและใช้ งานคอมพิวเตอร์ตั้งแต่เด็ก และ ในปัจจุบันผมมีความใส่ใจด้านสุขภาพและสนใจในการสร้าง AI หรือแอพพลิเคชั่นในการคัดเลือกอาหารที่มีประโยชน์ทางโภชนาการที่อยู่ในเกณฑ์ราคาที่เหมาะสมและคุ้มค่ากับคุณค่าทางโภชนาการที่ได้รับ  มีความสนใจในการศึกษาต่อใน สาขาวิศวกรรมซอฟต์แวร์ และวิทยาการคอมพิวเตอร์ ทำให้จําเป็นที่จะต้องพัฒนาทักษะความสามารถและความรู้ในการเขียนโปรแกรม ซึ่งในฐานะผู้เริ่มต้นเขียน Python โครงการนี้เป็นโครงการที่มีความท้าทายและ น่าสนใจเลยทีเดียวตั้งแต่การ ทำแบบฝึกหัดได้เรียนรู้การใช้ฟังชั่นใหม่ ๆ ที่ไม่รู้จักหรือเคยได้ใช้ในภาษา Python และยังมี Numpy Pandas ที่ผมพึ่งได้เริ่มศึกษาเพราะสองอย่างนี้มีความเกี่ยวข้องกับ Data Science ที่ผมสนใจ\n",
      "เมื่อปีที่แล้วพี่ชายของผมได้เข้าร่วมโครงการนี้ จากคนที่แทบจะไม่สนใจภาษาpyton กลับกลายเป็นผู้ที่ชื่นชอบAI และเขามักtrain AIอย่างต่อเนื่อง ผมเคยเข้าร่วมโครงการ ที่เกี่ยวข้องกับ health care data science โดยใช้ภาษาpyton 2 ครั้ง และเคยมีโอกาสศึกษาภาษาpytonด้วยตนเองในเว็บไซต์ต่างๆ เช่น datacamp  AI เป็นสิ่งที่ล้ำสมัยในสายตาของผมและของโลก นอกจากจะมีศักยภาพในการประมวลผลที่สูงกว่ามนุษย์เช่น ในด้านของความเร็ว กระบวนการคิด ฐานข้อมูลอัยมหาศาล และอื่นๆ มันยังวิเคราะห์ผลลัพธ์ออกมาได้หลากหลายประเภท ไม่ว่าจะเป็น ภาพ เสียง ความน่าจะเป็น นอกจากนี้ AI/data scienceยังเป็นสายงานอาชีพที่เป็นที่ต้องการของตลาดในอนาคต ตอนแรกผมคิดว่าการสร้าง ai เป็นเรื่องเพ้อฝัน แต่โครงการนี้ทำให้ฝันที่จะที่จะลองทำสิ่งแปลกใหม่ได้อยู่ต่อหน้าผมแล้ว ผมจะทำมันให้เป็นจริง\n",
      "ส่วนตัวผมเป็นคนที่ชื่นชอบและสนุกไปกับการเรียนรู้และพัฒนาผลงานในด้านคอมพิวเตอร์มากเพราะมันมีความท้าทายแฝงอยู่ไม่น้อย ในปัจจุบันคิดว่าได้ทำผลงานด้านการเขียนเว็บแอพพลิเคชั่นและการเขียนโปรแกรมเบื้องต้นมามากพอแล้ว จึงต้องการศึกษาและพัฒนาผลงานในระดับที่สูงกว่าเดิมและท้าทายมากยิ่งขึ้น  เหตุผลที่อยากเข้าโครงการเพราะว่าต้องการใช้เวลาว่างในช่วงปิดเทอมนี้ในการพัฒนาความรู้และเก็บเกี่ยวประสบการณ์ในด้านคอมพิวเตอร์ให้มากขึ้นและส่วนตัวสนใจในด้าน AI มากพออยู่แล้ว ผมมีความต้องการที่จะพัฒนานวัตกรรมที่เปลี่ยนแปลงหรือยกระดับการใช้ชีวิตในประจำวันให้มีความสะดวกสบายมากยิ่งขึ้น ยกตัวอย่างดังเช่น Facebook ในปัจจุบัน ซึ่งในปีที่แล้วมีพี่ที่สนิทมาชวนเข้าร่วมโครงการนี้ด้วยกัน แต่ผมดันสมัครไม่ทัน ถึงอย่างนั้นผมก็ติดตามบรรยากาศการเรียนการสอนและชื่นชอบผลงานที่มีความโดดเด่นของพี่ ๆ เมื่อปีที่แล้วมาก ก็คิดว่าโครงการนี้ให้ความสนใจและดูแลผู้เข้าร่วมเป็นอย่างดีและน่าสนใจมากเหมือนที่คิดไว้ไม่มีผิดและจะต้องได้ความรู้ในด้านปัญญาประดิษฐ์ที่สอดคล้องกับเป้าหมายของตัวเอง จึงรู้สึกดีใจและตื่นเต้นไม่น้อยที่จะได้เป็นส่วนหนึ่งในโครงการนี้บ้าง ฉะนั้นปีนี้ผมจะต้องไม่พลาดโอกาสอีก ถ้าหากได้เข้าร่วมโครงการนี้ผมจะนำความรู้ไปต่อยอดในการพัฒนาผลงานต่อไป รวมถึงการเข้ามหาลัยและการประกอบอาชีพในอนาคตด้วย\n",
      "ผมได้เข้าร่วมเเข่งขันโครงงานวิทยาศาสตร์สาขาวิทยาการข้อมูลเเละได้ทำโครงงานเกี่ยวกับการใช้เขียนโปรแกรมเเจ้งเตือนอัตโนมัติผ่าน line โดยใช้ข้อมูลจากกรมอุตินิยมวิทยา4ปีย้อนหลังในการคาดคะเนการเกิดอุทุกภัย เเละโครงงานนี้เองที่เป็นเเรงบันดาลใจในการศึกษาด้านต่อในเรื่อง ai เพื่อนำไปประยุต์ใช้กับปัญหาต่างๆในอนาคตเเละผมมั่นใจว่าถ้าหากผมได้รับเข้าโครง AI Builders 2022 จะให้ความร่วมมือเเละตั้งใจอย่างถึงที่สุดครับ  มีความสนใจในเรื่อง ai เพราะในปัจจุบัน ai เป็นที่พูดถึงอย่างมากเเละในอนาคตอันใกล้นี้ ai อาจมีบทบาทมากขึ้นกว่าปัจจุบันผมจึงอยากพัฒนาฝีมือของตัวเองพร้อมทั้งหาเรื่องที่ท้าทายมากขึ้นเละเล็งเห็นว่าโครงการ AI Buildersนี้สามารถให้ความรู้กับผมเพื่อไปพัฒนาเเละต่อยอดได้เห็นได้จากผลงานของพี่ๆที่เคยเข้าร่วมโครงการนี้ ทุกผลงานมีการประยุตก์ใช้ในการแก้ปัญหาต่างๆได้อย่างเหมาะสมผมจึงอยากที่จะเข้าร่วมโครงการ AI Builders 2022 เพื่อสามารถพัฒนาเเละแก้ปัญหาต่างได้อย่างกับพี่ๆที่เคยเข้าร่วมโครงการนี้ครับ\n",
      "ผมมีความสนใจในการ coding มาเป็นเวลาสักพักใหญ่แล้วครับ ผมได้ลองพยายามศึกษาจากการนั่งฟังบรรยายมาเยอะพอสมควร ได้ลองเสียเงินฟังบรรยาย ก็ได้ความรู้พื้นฐานมาบ้างแต่ผมก็ไม่ได้รู้สึกว่าตัวเองเขียน code เป็นเลย จนผมลองมาเจอกับโครงการ AI builder ของปีที่แล้ว ผมรู้สึกชอบวิธีการที่สอนแล้วตั้งคำถามไปด้วยมากๆ และได้ลองแก้โจทย์ที่ทีมงานได้ให้มา ถึงตอนนั้นผมจะยังไม่ได้ได้ผ่านเข้ารอบมาทำ Project ต่อ แต่ผมก็ได้รู้ว่าการทำ coding นั้นไม่ใช่แค่ฟังแล้วจะเขียน code เป็น ต้องอาศัยการฟัง การทำความเข้าใจ และ ลงมือปฏิบัติจริง ถึงจะทำให้เราสามารถแก้ไขปัญหาได้ นั้นจึงเป็นเหตุผลว่าทำไมผลถึงอยากเข้าร่วมโครงการนี้ ผมอยากได้ความรู้ที่จะนำไปต่อยอดสู่อนาคตได้ อยากลองทำ Project เกี่ยวกับ coding ให้มันสำเร็จสักอันหนึ่ง อยากมีประสบการณ์การต่างๆที่ผมจะสามารถเรียนรู้จากมันได้ อยากจะทำให้ตัวเองกล้าพูดได้อย่างเต็มปากหลังจบ Project นี้ไปว่า “ผมเขียน Code เป็น”\n",
      "I have been coding since I was young, so I would understand the concept faster. I have experience in coding microcontrollers using C language and competing in several robotic competitions, but I have never made any project about AI. This is a very great opportunity for me to start learning and using AI. If I were able to make AI, I could also use it to develop other projects and skills, like applying AI into robots. I believe that understanding AI would help in my later studies and jobs as AI are becoming more desired in companies over the years. I would also give my best and as much time as needed to finish the project. I have high stamina and diligence. I would never give up solving what I had started.  I really want to join the course as I want to be able to make AI project and code Python. Nowadays, AI is founded almost everywhere, but I still don’t understand what it is and how it works. Or even how good it is that it is so widely founded and common. I think these questions will be all clear to me if I join this course. I know that everything is going into the digital world, and AI & coding skills are greatly appreciated. Therefore, knowing how to use Python and make AI would really make me accomplished more in future. Making an AI project would also be really fun as I would have to embrace harder challenges and coding bugs. I have never used Python before, so when I watched your videos about Python, NumPy, and Pandas, it was really fascinating to me. I always enjoy the feeling when I finally solve each of the questions in this Python Exam.\n",
      "มีความสนใจในภาษา Python แต่ยังใช้งานได้ในระดับ Basic จึงอยากเรียนรู้เพื่อให้สามารถนำไปประยุกต์ใช้งานในระดับสูงต่อได้ในอนาคต และมีความชอบในศาสตร์ของ AI ต้องการประสบการณ์การในการพัฒนา AI เพื่อแก้ไขปัญหาในหัวข้อที่สนใจ และประสบการณ์ในการแก้ไขปัญหาเพื่อให้เป้าหมายสำเร็จลุล่วง  ต่อยอดระบบส่งเสริมการทำปฎิบัติการเนื้อเยื่อพืชด้วยปัญญาประดิษฐ์ การเข้าใจเนื้อเยื่อพืชนำไปสู่ความเข้าใจเกี่ยวกับกลไกการดำรงชีวิตของพืชที่แตกต่างกันไป การศึกษาเนื้อเยื่อพืชทำได้โดยเทคนิคการตัดตามขวาง เป็นการตัดโครงสร้างของพืชให้มีความบางสม่ำเสมอแล้วนำไปส่องใต้กล้องกล้องจุลทรรศน์ โดยเทคนิคการตัดด้วยมือเปล่าเป็นที่นิยมเนื่องจากทำได้โดยใช้อุปกรณ์ไม่มาก แต่อาศัยความชำนาญ มีการจัดสอนอยู่ในระดับชั้นมัธยมศึกษาปีที่ 5  ปัญหาที่เกิดขึ้นคือ นักเรียนขาดทักษะในการทำปฎิบัติการ ทำให้บางชิ้นงานไม่เหมาะสมจะนำไปใช้งานต่อ จึงต้องสอบถามครูผู้สอนเพื่อให้แน่ใจว่าชิ้นงานของตนเองเหมาะสมจะนำไปใช้งานต่อในกิจกรรมได้ รวมถึงข้อจำกัดด้านเวลาทำให้กิจกรรมในห้องดำเนินไปไม่ได้เร็วมากนัก จึงต้องจำกัดการเรียนรู้ลงเหลือเพียงพืชไม่กี่ชนิดเท่านั้น ทำให้ไม่สามารถศึกษาเนื้อเยื่อพืชที่สนใจได้  การพัฒนา AI เพื่อช่วยส่งเสริมการสอนของครู โดยการระบุชนิดของเนื้อเยื่อพืชว่าเป็นโครงสร้างส่วนใด และมีความเหมาะสมที่จะไปใช้งานต่อหรือไม่ จะช่วยให้การดำเนินไปของปฏิบัติการรวดเร็วขึ้น เพราะตรวจสอบชิ้นงานได้ตลอดเวลา และสามารถศึกษาหัวข้อเนื่อเยื่อพืชที่ตนเองสนใจได้ ทำให้นักเรียนได้เห็นเนื้อเยื่อของพืชหลากหลายชนิดจากนักเรียน คนอื่น ๆ จากการสังเกตและเชื่อมโยงภาพเหล่านั้นจะทำให้นักเรียนสามารถสร้างข้อสรุปและสร้างองค์ความรู้ได้ด้วยตนเอง (constructivisim) นอกจากนี้ยังเป็นเครื่องมือที่อำนวยความสะดวกให้ครูจัดการเรียนรู้ด้วยวิธีปฏิบัติจริง (active learning) อีกด้วย  Dataset สามารถหาได้จากการทำปฏิบัติการเนื้อเยื่อพืชของนักเรียนหรือสร้างขึ้นเอง\n",
      "จากประสบการณ์ที่หนูเคยได้เข้าร่วมกิจกรรม และเข้าร่วมการแข่งขันทางด้าน AI มา มันทำให้หนูค้นพบว่าตนเองสนใจอะไร ค้นพบเส้นทางที่อยากเดินต่อ แต่ตอนนี้ยังขาดความรู้ ยังอ่อนประสบการณ์ ถ้าทางโครงการอยากได้คนที่พร้อมที่จะรับความรู้ คนที่มีความมุ่งมั่นและความตั้งใจ หนูขอให้ทางโครงการลองเปิดโอกาสให้หนูได้แสดงให้เห็น หนูรับรองว่าจะไม่ทำให้ทางโครงการผิดหวังแน่นอนค่ะ  ตัวหนูมีความสนใจทางด้าน AI ค่ะ เลยอยากที่จะเข้าร่วมโครงการนี้ เนื่องจากหนูมีเป้าหมายที่อยากจะนำความรู้ที่ได้จากโครงการไปพัฒนาศักยภาพของตนเอง จนสามารถนำความรู้ที่ได้ไปเป็นส่วนหนึ่งในการสร้างสรรค์นวัตกรรมใหม่ๆ และพัฒนาเทคโนโลยีทางด้าน AI เพื่อเข้ามาช่วยเหลือสังคม และตอบสนองความต้องการของผู้คนทั่วโลกค่ะ  อยากทำแอปพลิเคชันสำหรับคนพิการทั้งที่เป็นใบ้ และหูหนวกค่ะ โดยโครงงานนี้จะเข้ามาช่วยแก้ปัญหาในเรื่องการสื่อสารระหว่างคนปกติและคนพิการ หลักการทำงานจะใช้กล้องถ่ายเก็บข้อมูลภาษามือ แล้วให้ AI ประมวลผล พร้อมแปลความหมายให้กับคนที่จะสื่อสารด้วย โดยหาชุดข้อมูลจากคนที่หูหนวกและเป็นใบ้ และบุคคลที่เชี่ยวชาญเรื่องการแปลภาษามือ\n",
      "เพราะผมรู้ตัวว่าผมชอบด้านนี้แน่ๆ ผมอยากเรียนรู้เพิ่มเติมในด้านการเขียนโปรแกรมภาษาไพทอน ถึงแม้โครงการนี้จะไม่รับผมเข้าผมก็ยังจะศึกษาคนคว้าแลอบด้านนี้ต่อไป และผมทุ่มเทเวลาและตั้งใจ ศึกษาหาคอร์สสอนพวกนี้อยู่ตลอด และถ้าเข้าโครงการนี้ได้ผมจะตั้งใจจริงๆ  ผมสนใจในการโค้ดภาษา python มากๆ หาเรียนฟรีใน YouTube มาตลอดและมีเรียนจากที่โรงเรียนเล็กน้อย ผมเห็นว่า python สามารถทำอะไรได้มากมายจึงอยากเรียนรู้เพิ่มเติมในด้านนี้ ผมไม่ค่อยมีความรู้ด้าน library numpy หรือ pandas (อาจจะทำผิดในข้อสอบข้อต่างๆที่ใช้ module พวกนี้ แต่เรียนคอร์สปรับพื้นฐานที่โครงการจัดให้แล้ว) แต่ผมพอมีพื้นฐาน python เคยทำเกมจาก pygame หรือ lib ต่างๆ ผมจึงอยากเข้าร่วมโครงการนี้เพื่อเรียนรู้การทำ AI ด้วย python และการใช้ library ต่างๆเช่น numpy หรือ pandas ผมเพิ่งมาเห็นโพสต์นี้เอาวันสุดท้ายก็อาจจะมีมีโค้ดผิดอยู่สองข้อ แต่ผมตั้งใจทำในระยะเวลาที่เหลืออยู่มากที่สุดแล้วครับ อยากเข้ามากๆครับ\n",
      "ผมมีความใฝ่รู้สิ่งใหม่ๆ มีไฟในการเรียนรู้ศึกษาสิ่งใหม่ๆอย่างมาก ผมพร้อมที่จะเรียนรู้สิ่งที่โครงการนี้พร้อมที่จะมอบให้และผมจะนำไปพัฒนาให้ดีมากยิ่งขึ้น ผมยังมีประสบการณ์เข้าร่วมโครงการ Young Computer Scientist Camp #2 มหาวิทยาลัยเชียงใหม่ที่เรียนรู้เกี่ยวกับการเขียน Bot Python เบื้องต้น และมีประสบการณ์การเขียนภาษา Python มีประสบการณ์เป็นเจ้าของและผู้พัฒนาเซิร์ฟเวอร์ Minecraft และมีความเข้าใจภาษาอังกฤษได้เป็นอย่างดี ผมมั่นใจว่าถ้าผมได้เข้าร่วมโครงการนี้จะสร้างผลงานดีๆและนำไปสานต่อในอนาคตให้เกิดประโยชน์ต่อส่วนรวม  ผมมีความสนใจด้าน AI และวิทยาศาสตร์ข้อมูล และกำลังเริ่มศึกษาหาความรู้ พี่ๆของผมจึงแนะนำค่ายนี้ หลังจากที่ผมเข้าไปศึกษาดูโครงการนี้แล้วเห็นว่า โอ้โห เด็กนักเรียนระดับมัธยมก็สามารถสร้าง AI ดีๆขึ้นมาได้ ผมจึงทำการศึกษาข้อมูลเพิ่มเติมและตั้งเป้าหมายให้ได้เข้าร่วมโครงการนี้ และในที่สุดผมจะนำความรู้ที่ได้จากโครงการไปพัฒนาปัญญาประดิษฐ์ที่ใช้งานได้จริง และมีประโยชน์ต่อผู้อื่น นั่นจะเป็นหนึ่งในความภาคภูมิใจของผม  ผมอยากทำโครงงานแก้ไขปัญหาให้กับผู้พิการทางสายตา ที่เดินทาง Indoor ได้ลำบาก โดยใช้ Image Processing ร่วมกับโมเดล Text to Speech ของผู้ศึกษาโครงการ AI Builders รุ่นแรกโดยภาพที่ได้จากกล้องที่ติดบนหมวกของผู้พิการทางสายตานำไปประมวลผลกับโมเดลที่เทรนโดย https://www.kaggle.com/datasets/hamzafar/look4me จะได้ทิศทางการเดินที่เป็นไปได้แล้วตอบกลับด้วยเสียง โดยใช้ Thai TTS Tacotron (สามารถเดินตรงไป เลี้ยวซ้ายและเลี้ยวขวาได้) หรืออาจจะรับข้อมูลจากไม้เท้าของผู้พิการทางสายตาว่าชี้ไปทิศทางไหน แล้วให้ตอบกลับว่าทิศทางนั้นเป็นไปได้หรือไม่ และในอนาคตอาจนำไปสานต่อกับการเดิน Outdoor ของผู้พิการทางสายตาบอกถึง ทางม้าลาย ทางเดินเท้าที่เป็นไปได้ หรือยานพาหนะต่างๆ ให้มีความปลอดภัยมากขึ้น\n",
      "แรงบันดาลใจมาจาก ตอนที่ผมได้เข้าร่วมกิจกรรมในงานของ Kidbright AI Bot ครับ ตอนนั้นเป็นครั้งแรกที่ผมได้รู้จักและเข้าใจภาพรวมในเรื่องของ AI และกระบวนการโดยรวมครับ จากพี่ๆที่โครงการมาอบรมให้ครับ ผมเลยได้ลองสร้าง, เทรน model และ เขียนโค้ดที่เป็น AI โดยใช้ Kidbright AI Platform ครั้งแรกโดยการสั่งการให้หุ่นยนต์เดินด้วยเสียงได้ครับ หลังจากนั้นผมจึงมีความคิดที่อยากทำโครงการที่ใช้ AI ในการประมวลผลขึ้นมาจริงๆครับ ผมเคยเข้าร่วมโครงการ Super AI Engineer เมื่อ 2 ปีที่แล้วครับแต่ตอนนั้นผมยังไม่มีพื้นฐานในเรื่องของ Coding กับ Math เลยไม่ผ่านรอบต่อไปที่ทำ AI ครับ หลังจากนั้นผมจึงกลับไปฝึกพื้นฐาน Coding ที่เป็น Python, Pandas, Numpy มาเลยพอมีพื้นฐานระดับนึงแล้วครับ แล้วก็คิดจะลองทำโปรเจคที่เป็น AI ดูแต่ผมก็ไม่ค่อยเข้าใจเลยไม่กล้าทำขึ้นมาทีครับ หลังจากที่ผมรู้ว่ามีโครงการ AI Builder ผมเลยสนใจที่อยากเข้าร่วมโครงการเพราะผมว่าตอนนี้ผมมีความพร้อมมากกว่ารอบที่แล้ว และ ผมมีความมั่นใจมากกว่าที่แล้ว และ ก็ผมคิดว่าถ้าผมได้เข้าทำโครงการนี้จริงๆแล้ว ผมจะได้มีเพื่อนๆ และ พี่ๆที่มีประสบการณ์ในการปรึกษา และ เรียนรู้ได้ครับ  เนื่องจากผมเคยทำ project ที่เขียน coding มาบ้างครับเลยได้รู้จักในเรื่องของ AI ครับแต่ยังไม่เคยทำแบบจริงๆจังๆด้วยตัวเองมาก่อนครับ เพราะ ไม่เข้าใจเรื่องหลักการแบบจริงๆจังๆรู้แต่คร่าวๆครับเคยแต่ใช้ในรูปของ platform ครับ เลยสนใจที่อยากจะเข้าโครงการนี้เพราะจากที่ผมศึกษามามีการสอนพื้นฐานต่างๆ ในการสร้าง AI มี Workshop ต่างๆ ได้ทำและพัฒนาผลงานจริงๆ ผมจึงอยากที่จะเข้าร่วมโครงการครับ  โครงงานที่ผมอยากทำเป็น การตรวจเอกสารยืนยันผลเชื้อของไวรัส Covid 19 ครับ โดยเป็นการ detection จากเอกสารว่า คนๆนี้ ชื่อ นามสกุล ผลตรวจติดเชื้อหรือไม่ ตรวจจากสถานที่ใด โดยสามารถทำได้ 2 แบบ 1. ส่งไฟล์ รูปภาพเข้ามาในระบบ กับ 2.ในสถานที่จริงให้เอาเอกสารยื่นเข้ากล้องให้ตรวจจับ หรือ เป็นตัวที่ตรวจสีขาวที่เป็นขีด โดยแนบคู่กับบัตรประชาชนครับ โดยจะแสดงผลว่าติดเชื้อหรือไม่ และก็จะเข้าระบบใน google sheet เป็น .csv เพื่อใช้ pandas ในการจัดการข้อมูลต่างๆได้ครับ เนื่องจากล่าสุดผมได้คุมสอบของนักศึกษาแพทย์ กสพท โดยที่คนที่จะเข้าสอบมีจำนวนเกือบถึง 5000 คนครับ โดยต้องตรวจสอบเอกสารการตรวจเชื้อของทุกๆคนด้วยตวเอง ทำให้เกิดโอกาสผิดพลาด และ คลาดเคลื่อนสูงครับ ถ้ามีระบบที่เป็น AI วิเคราะห์ได้ก็จะแก้ปัญหาในเรื่องของระยะเวลาในการตรวจเอกสาร, จำนวนของเจ้าหน้าที่คุมสอบ และ สถานการแออัดในสถานที่นั้นๆได้ครับ และ สามารถใช้ได้ทุกสถานที่ เช่น สนามสอบ, สถานศึกษาที่ต้องใช้ตรวจเอกสารผลเชื้อ covid 19 ครับ โดยชุดข้อมูลที่ใช้ในการเทรน หาได้จากใน internet (keyword == เอกสารตรวจโควิด, รูปแบบเอกสาร ผลการตรวจ covid) ส่วนถ้าเป็นเครื่องตรวจก็จะเทรนขีด (keyword == covid antigen test results, ) แสดงผลครับรูปแบบของเครื่องตรวจแบบต่างๆ โดยจะเอารูปแบบของเอกสาร และ เครื่องตรวจให้มีความหลากหลายเพื่อไม่ให้เกิดความผิดพลาดครับ\n",
      "\"เนื่องจากผมเป็นคนที่สนใจและถนัดในชีววิทยา ที่ผ่านมาจึงเข้าร่วมการแข่งขันทางวิชาการหลายๆอย่างทั้งโอลิมปิกวิชาการ ตอบปัญหาชีววิทยา/การแพทย์ และได้ทำโครงงานที่เกี่ยวกับการตรวจคัดกรองทางการแพทย์ จึงยังไม่ได้มีโอกาสทำโครงงาน ML หรือโคดดิ้ง แต่จากประสบการณ์ในการเรียนวิชานี้ ทำให้ผมมีความเข้าใจในระบบต่างๆทางชีววิทยา และพบว่ากลไก ปฏิกิริยาทางเคมีต่างๆ ล้วนสามารถศึกษาได้โดยใช้การวิเคราะห์ ข้อมูล เชิงชีววิทยา หรือที่เรียกว่า Bioinformatics เมื่อไม่นานมานี้ผมจึงได้เริ่มศึกษาการสร้างโมเดล QSAR เพื่อหาความสัมพันธ์ของโครงสร้างทางเคมีของโมเลกุลกับ bioactivity โดยใช้ ML เข้ามาทำนายข้อมูล ซึ่งถือว่าเป็นการที่ผมได้ self-study เกี่ยวกับ ML ด้วยตัวเองครั้งแรก ถึงแม้จะเป็นการหยิบยืมโค้ดเพื่อให้เข้าใจการใช้ ML ในเบื้องต้น แต่อย่างไรก็ตาม ผมคิดว่า ยังมีส่วน algorithm ของ model ที่ยังไม่เข้าใจมากนัก และไม่รู้จะนำไป apply ต่ออย่างไร .. ดังนั้นผมจึงต้องการที่จะหาโอกาสที่จะเรียนรู้ในเรื่องนี้อย่างลึกซึ้ง และมั่นใจว่าเราจะได้ประโยชน์จากจุดนี้ และสามารถทำให้เกิดประโยชน์ต่อไปได้ เช่น project ที่ช่วยพัฒนายา หรือ วิเคราะห์ข้อมูลทางชีวภาพต่างๆ\",  นอกจากนี้คือ ผมกำลังทำงานวิจัยเกี่ยวกับ Molecular Dynamics Simulation โดยมีอาจารย์จาก KMUTT เป็นที่ปรึกษา ซึ่งการทำงานนี้เป็นส่วนของ Computational Biophysics ที่ต้องอาศัยการเขียนโปรแกรมเข้ามาช่วยวิเคราะห์โครงสร้าง DNA ผมจึงจะได้มีโอกาสทำงานใช้ ภาษา python และคิดว่า ML อาจสามารถนำมาประยุกต์ใช้ในงานได้ไม่มากก็น้อย  สาเหตุที่ผมอยากเข้าโครงการ คือ การที่ AI และ Machine Learning จะเข้ามามีบทบาทความสำคัญในอนาคตเป็นอย่างมาก ไม่ว่าจะเป็นในเชิงการแพทย์ วิศวกรรม การทำธุรกิจ ฉะนั้น การเรียนรู้ทักษะการเขียนโปรแกรมเพื่อพัฒนา AI เบื้องต้นจึงจะเป็นทักษะที่จำเป็น ยิ่งไปกว่านั้นคือ การหาประสบการณ์ในการทำ AI เพื่อนำมาใช้แก้ปัญหาจริง จะช่วยให้เห็นแนวทางที่จะนำไปต่อยอดเพื่อให้เกิดประโยชน์ในอนาคตมากยิ่งขึ้นไป โดยผมเห็นว่าโครงการนี้สามารถตอบโจทย์ เพราะถ้าได้เข้าร่วมผมจะได้ผู้เชี่ยวชาญคอยชี้แนะและสอนการทำงานในสายนี้จริงๆ ซึ่งอาจทำให้เราได้เรียนรู้ในสิ่งที่ลึกกว่าการเรียนจากแหล่งข้อมูลทั่วไปในอินเตอร์เน็ต นอกจากนี้ ผมยังเห็นว่า การเข้าโครงการจะช่วยให้เรามี connection กับเพื่อนที่สนใจใน AI เหมือนกัน และรู้จักกับอาจารย์ต่างๆ ซึ่งจะเป็นประโยชน์มาก เพราะอาจช่วยให้ผมมีโอกาสได้ partner ทำงานวิจัย หรือทำธุรกิจเทคโนโลยีที่ได้สร้างจากประสบการณ์การเข้าร่วมโครงการและการศึกษาต่อเพิ่มเติม\n",
      "ผมสนใจแพทยศาสตร์เป็นหลัก และตอนนี้ AI ก็มีความน่าสนใจเท่ากัน ผมเคยศึกษางานวิจัยจากรามาธิบดีเวชสารมาพอสมควร และพบว่า ยังมีสิ่งที่ผมสามารถต่อยอดจากการเอาทั้ง 2 แขนงมารวมกันได้อีกมาก ผมได้กล่าวไปในจดหมายที่ส่งให้คณะแพทยศาสตร์โรงพยาบาลรามาธิบดี และผมจะกล่าวไว้ที่นี่เช่นกัน ว่าผมมีจุดมุ่งหมายจะนำทั้ง 2 แขนงนี้มาสร้างประโยชน์ให้สังคม นี่เป็นเหตุที่ผมตัดสินใจสมัคร AI Builders และเป็นเหุผลที่ท่านควรรับผมเข้าโครงการครับ  เมื่อช่วง lockdown ปี 2564 ผมมาเริ่มสนใจการเขียนโปรแกรม เริ่มเรียน python ด้วยตัวเองประมาณ 2 เดือน ต่อมาเห็นเพื่อนที่เรียนมาด้วยกันทำโครงงาน CNN พยากรณ์อาการลมชักจากสัญญาณ EEG ผมก็เลยเข้ามาสนใจในงาน AI มากขึ้น ใช้เวลาอีก 2 เดือนเรียน Tensorflow จนพอมีพื้นฐานบ้าง แต่ผมเรียนทุกอย่างด้วยตัวเอง ไม่เคยได้มีโอกาสที่ได้รับหลักสูตรในสายนี้จาก Lectures เลย ผมเห็นว่า AI Builders เป็นโอกาสให้ผมได้มีประสบการณ์ในด้าน AI อย่างเป็นทางการ ให้ผมได้เรียนรู้และพบปะคนอื่นที่มีความสนใจตรงกับผม และทำ projects เพื่อเพิ่มประสบการณ์ที่จะกลับมาพัฒนาในสิ่งที่เป็นประโยชน์สูงสุดครับ\n",
      "ผมมีประสบการณ์ทำ Project ต่างๆ ไม่ว่าจะเป็น Web App,Desktop/Mobile App,IoT,Game Dev,Networking,Image/Signal Processing ผมจึงมีทักษะในการเขียนโปรแกรมด้วยหลายภาษารวมถึง Python ทำให้ผมสามารถเรียนรู้การสร้าง AI ได้เร็ว สามารถนำไปปรับใช้กับความรู้ที่มี และพัฒนาออกมาเป็น product ที่ใช้งานได้จริง  ในโลกของเทคโนโลยีจะมีการเปลี่ยนแปลงเกิดขึ้นตลอดเวลา ซึ่งตอนนี้ AI เป็นเทคโนโลยีใหม่ที่มีศัยภาพที่น่าสนใจเป็นอย่างมาก ผมที่ชื่นชอบการแข่งขันและทำงานวิจัยเพื่อพัฒนาศักยภาพของตนเอง อยากที่จะเข้าร่วมโครงการ AI Builder เพื่อที่จะศึกษาขอบเขตความสามารถ และการพัฒนา AI เพื่อใช้ในงานวิจัยของผมต่อไปในอนาคต  ผมชอบการเป็น Content Creator และ Game Dev แต่ดนตรีประกอบมีผลสำคัญอย่างมากกับสื่อทั้งสองประเภท และการแต่งเพลงขึ้นใหม่จะใช้เวลาและเงินทุนมาก ทำให้ผู้พัฒนาทุนน้อยไม่สามารถทำได้ ทำให้ผมอยากพัฒนา AI ที่สามารถ Generate ดนตรีประกอบคลิปวีดีโอหรือเกมออกมาได้ โดยใช้ Dataset เป็นจาก Github และ Kaggle\n",
      "ผมไม่ค่อยเข้าร่วมกิจกรรมมากนัก เพราะพวกกิจกรรมที่มีมาบ่อยๆ ไม่ค่อยน่าสนใจ เช่นพวก open house หรือ แคมป์เสียเงินต่างๆ ผมชอบนั่งเรียนไปเรื่อยๆมากกว่า ดู Tutorials นั่นนี่แล้วก็ลองทำอะไรไปเรื่อยๆ ถ้าเวลาว่างๆ ผมก็จะไปตอบคำถามให้คำปรึกษาที่กลุ่มเฟสบุ๊ค/ดิสคอร์ด programming ครับ ได้ทบทวนความรู้ด้วย ได้ช่วยคนอื่นด้วย ผมว่าแบบนี้มันดีกว่าเยอะ ไม่ว่าใครจะว่ายังไง อันนี้ถือเป็นกิจกรรมที่ผมดีใจที่ได้ทำครับ  เพราะผมสนุกครับ สนุกกับการเรียนอะไรใหม่ๆ เรียนเรื่องที่ยังไม่เข้าใจ ได้แบ่งปันงานของตัวเองให้คนอื่นเอาไปพัฒนาต่อ หลักๆคือ เพราะว่ามันน่าสนุกผมเลยสมัครเข้ามา พอได้รู้อะไรมากขึ้นก็สอนคนอื่นได้มากขึ้นด้วย อีกอย่างคือผมอยากออกจากโลกแคบๆ อยากไปเจอคนใหม่ๆ ผมกังวลนความสามารถตัวเองมาตลอด ผมเลยอยากสร้างอะไรเจ๋งๆ ผมอยากพิสูจน์ตัวเอง ให้ตัวเองเห็นครับ\n",
      "ผลงานเกี๋ยวกับ AI 1. Model ทำนายการเสื่อมสภาพของดินเป็นผลให้ได้เป็นตัวแทนเข้าร่วมนำเสนอผลงานที่จัดโดยประเทศเกาหลี 2. Machine Learning ตรวจจับรูปร่างวัตถุโดยใช้กล้องตรวจจับในการแข่งขันหุ่นยนต์ ได้รับรางวัล Control Award และ Winner Award แรงบันดาลใจคือโครงงานที่อยากทำค่ะเป็นผลให้เข้าร่วมกิจกรรมอบรม AI ของ Microsoft และ AWS  ชื่นชอบและสนใจปัยญษประดิษฐ์มากยิ่งเหตุมีข่าวเกี่ยวกับค่าย AI ตั้งแต่ต้นปีก็ตั้งหน้าตั้งตารอวันที่ค่ายเปิดรับสมัครเลยค่ะ หนูเคยเข้าร่วมค่ายวิทยาศาตร์และมีโอกาสได้ทำงานเกี่ยวกับการทำนายของ Model แต่หนูไม่ได้เข้าใจมันทั้งหมดตอนนั้นที่ทำได้เพราะนำโค้ดที่มีอยู่แล้วมาเปลี่ยน dataset แล้วก็แก้นิดหน่อย สิ่งที่หนูจะบอกก็คือหนูอยากเข้าใจกระบวนการ algorithm ของ AI จริงๆค่ะ ถ้าหนูได้เข้าใจ algorithmของAI จริงๆแล้วหนูจะสามารถต่อยอดโครงงานให้เป็นจริงได้ค่ะ  การสร้าง Model วิเคราะห์และบอกประเภทของโรคหัวใจจากเสียงของจังหวะการเต้นและกราฟคลื่นไฟฟ้าของหัวใจโดยใช้การวิเคราะห์เชิงลึก (Big data) ประยุกต์ร่วมกับปัญญาประดิษฐ์ (AI)\n",
      "ผมเคยมีประสบการณ์ในด้านนี้ตอนแข่ง TMLCC ครับ แต่ว่าก็ยังเป็นแค่สร้างโมเดลเพื่อใช้ในการแข่ง ซึ่งตอนนั้นผมรู้สึกว่ามันเพลินมากตอนสร้างโมเดล อาจจะมีเหนื่อยบ้างนิดหน่อยตอนที่ต้องอ่าน papers ยาว ๆ หลายสิบหน้าที่เกี่ยวกับเคมี แต่เราก็ต้องสู้ครับ! ฮ่าๆ แม้ว่าตอนแก้และรันแต่ละครั้ง accuracy จะขึ้นหรือลง แต่ผมก็รู้สึกสนุกและลุ้นไปกับมันทุกครั้งเลยครับ ถ้าจะให้บอกว่าแรงบันดาลใจในเรื่อง AI ของผมมาจากไหน ก็คงต้องบอกว่ามาจากตัวเองที่มึความสุขกับมันนี่แหละครับ  ตั้งแต่ประถม ผมเริ่มรู้สึกกับตัวเองว่าเรามีความสุขเวลาที่เราสามารถแก้ปัญหาต่าง ๆ ได้ (แน่นอนว่าใครก็ต้องมีความสุขแหละครับที่คิดหาทางแก้ปัญหาออกได้) นั่นจึงทำให้วิชาที่โดดเด่นในเรื่องของการแก้ปัญหาอย่างคณิตศาสตร์เป็นวิชาที่ผมชอบได้อย่างไม่ยากเลยครับ ผมรู้สึกมีความสุขและสนุกที่หาวิธีคิดออกโดยเฉพาะวิธีแปลก ๆ ที่คนอื่นเขาไม่คิดกัน จนม.ต้น ผมได้รู้จักกับการ coding ตั้งแต่ครั้งแรกที่ผมเริ่มโค้ดก็รู้เลยครับว่านี่แหละสิ่งที่เหมาะกับเรา จนมาตอนม.ปลาย ผมก็เริ่มมองตัวเองในอนาคตว่าเราจะทำอะไร ก็หาข้อมูลกับลองเขียนนู่นนี่นั่นเล่นๆ จนผมได้มาเจอกับ AI ความรู้สึกตอนเจอคือแบบเดียวกับตอนม.ต้นเลยครับ ก็รู้เลยว่านี่คือสิ่งที่เรากำลังตามหาอยู่ แต่ตั้งแต่ตอนนั้นผมก็ยังไม่ได้สัมผัสเลยว่า โปรเจค AI จริง ๆ เป็นแบบไหน กระบวนการในการทำโปรเจคที่แท้จริงเป็นอย่างไร จึงอยากเข้าร่วมโครงการนี้เพื่อที่จะได้รับประสบการณ์ในการทำโปรเจคที่เป็นชิ้นเป็นอันและได้รับความรู้ในด้านที่เกี่ยวข้องเพื่อที่จะไปเรียนรู้ต่อและนำมาพัฒนาตนเองขึ้นไปอีกครับ และผมยังอยากหาเพื่อนหรือกลุ่มคนที่สนใจในด้านเดียวกัน จะได้มีคนที่คุยเรื่องพวกนี้ด้วยได้ครับ\n",
      "I firmly stand by the fact that I have a passion for always seeking to learn and research new things and technologies to improve myself and the world around me.  \"One example of this was when I took the Harvard University CS50x course last year in grade 8. This programming course was extremely challenging. But with my passion and determination, I pressed on, excelled, and earned my certificate shown in the attached portfolio. Furthermore, I went on to completely self-study the AP Computer Science Principles course and was the only person who ever scored a perfect 5 out of 5 for my school. Currently, Im studying another Harvard course that focuses on artificial intelligence: CS50AI.\",  Another achievement was the application that I wrote for my school, which is being used by over 200 people. For context, I am the youngest Student Council member in the history of my school, and I wanted to help the community by combining all the news into one place. Please see the portfolio for links to the app. During this time, I also joined the AWS Builders program to learn about the platform and all the marvelous tools that it offers.  Additionally, I am also very familiar with Linux. Throughout the last 3 to 4 years, I have researched on my own about it and have learned enough about it to post an install guide on Youtube and help countless people. To make the installation straightforward, I created various packages to add support for the Microsoft Surface devices (https://github.com/parinzee/linux-surface-overlay).  Finally, I believe that I am a compelling candidate because of my experience, ability to self-study, and extreme perseverance. These are qualities that innovators and leaders need to have. Accepting me into this program would allow me to help Thailand effectively in the future.\n",
      "What inspires me to create AI is how I discovered NLP by accident while I was looking to create spoonerism for Thai words. Back then I really wonder how a library like PyThaiNLP can split syllables nearly perfectly without me having to tell the users to split on my own, and that really get me obsessed.\n",
      "หนูมีความแน่วแน่และสนใจด้านนี้จริงๆ หลังจากที่ได้รู้ว่า AI builders ได้เปิดรับสมัครอีกครั้ง ก็ได้ติดตามข่าวสาร และ ศึกษาจากไลฟ์สดที่พี่ๆได้สอนในวันที่ 21 และ 28 มีนาคมที่ผ่านมา เพื่อใช้ในการทำแบบทดสอบของทางโครงการ ยอมรับค่ะว่าตอนทำข้อสอบช่วงแรกๆอาจจะมีนบ้างรันได้ error บ้างแต่หลังจากที่ได้ดูไลฟ์ของทางเพจ AI builders ทำให้หนูสามารถทำข้อสอบได้หมดทุกข้อเลยค่ะถึงแม้อาจจะใช้เวลาเยอะกว่าคนอื่นไปบ้าง หนูอาจจะไม่ใช่คนที่เก่งที่สุด อาจจะไม่ใช่อัจฉริยะที่เรียนรู้ได้รวดเร็ว แต่หนูเชื่อมั่นค่ะว่าหนูมีความสามารถไม่ต่างจากคนอื่น และสามารถประสบความสำเร็จได้เหมือนกันกับ เพื่อนๆAI builders ปีที่ผ่านมา หนูมีประสบการณ์ด้าน AI และ coding จากเวที Space Fight , YSLC ,The 2nd Kibo- RPC จากปีที่ผ่านมาค่ะ และหนูอยากจะให้ โครงการ AI builders เป็นหนึ่งในประสบการณ์ด้าน AI ของหนูต่อไปในอนาคตค่ะ  ส่วนตัวหนูเป็นคนชอบเขียนโปรแกรมมิ่งมากๆค่ะ หลังจากที่ได้รู้ในสิ่งที่ตัวเองชอบได้ไม่นาน หนูก็ได้พยายามฝึกฝนและขวนขวายเกี่ยวกับภาษาpythonมากยิ่งขึ้น ในช่วงที่ผ่านมาหนูได้มีโอกาสเข้าร่วมเวทีSPACE FIGHT ,The 2nd Kibo- RPC ยิ่งทำให้หนูสนใจด้าน AI มากยิ่งขึ้นและได้นำความรู้จากค่ายต่างๆมาประยุกต์ใช้ในโปรเจกต์ที่โรงเรียนและอื่นๆ เมื่อไม่นานมานี้ หนูพึ่งได้เรียนรู้เกี่ยวกับ Machine Learning ไม่ว่าจะเป็น การจัดการข้อมูล โดยใช้ Numpy , pandas และอยากจะนำความรู้เหล่านี้มาลองทำเป็นโปรเจกต์ของตัวเองดูบ้าง  จนมาเจอ AI Builder จากผลงานของเพื่อนๆในปีที่ผ่านมา ทุกคนสุดยอดมากๆเลยค่ะ น่าประทับใจมาก มีตั้งแต่รุ่นน้องๆ ไปจนถึงเพื่อนๆพี่ๆ ทำให้เห็นได้เลยค่ะว่าถ้าจบจากโครงการ AI builders ไปจะต้องได้คุณภาพทางด้าน Data Science และ AI แน่ๆ และ หนูอยากจะมีโอกาสเหมือนเพื่อนๆเหล่านั้น จนกระทั่งได้รับข่าวสารไม่นานมานี้ว่าโครงการนี้เปิดรับสมัครอีกครั้ง หนูเลยอยากลองทำโปรเจกต์ Machine learning ดูบ้าง หนูได้ตั้งเป้าหมายแน่วแน่เลยค่ะ ว่าต้องสมัครโครงการนี้และเป็นส่วนหนึ่งของโครงการนี้ให้ได้ ถ้าหนูได้รับโอกาสนี้หนูจะตั้งใจและหมั่นศึกษาหาความรู้จากโครงการนี้ ให้เกิดประโยชน์ต่อหนูเองในอนาคตและช่วยพัฒนาสังคมประเทศของเราให้ดียิ่งขึ้นค่ะ\n",
      "เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "for project_index in tqdm(range(data.shape[0])):\n",
    "    root = './images/2022/'\n",
    "\n",
    "    info_dict = {'date': \"\",  \"title\": \"\", \"builder\": \"\", \"builder_info\": \"\", \"thumbnail\": \"\", \"links\": {\"github\": \"\", \"facebook\": \"\", \"blog\": \"\"}, \"summary\": \"\", \"reason\": \"\"}\n",
    "    info_dict['date'] = data.iloc[project_index]['date']\n",
    "    info_dict['title'] = data.iloc[project_index]['title']\n",
    "    info_dict['builder'], data.iloc[project_index]['builder_info'] = process_author(data.iloc[project_index]['author'])\n",
    "    # info_dict['thumbnail'] = data.iloc[project_index]['title_image']\n",
    "    project_id = data.iloc[project_index]['ID'].astype(str)\n",
    "    info_dict['thumbnail'] = root + project_id + '/' + '01' + '.jpg' # save to static/images/2022/21/01.jpg\n",
    "    \n",
    "    info_dict['links']['blog'], info_dict['links']['github'] = process_link(data.iloc[project_index]['links'])\n",
    "    info_dict['links']['facebook'] = data.iloc[project_index]['post_url']\n",
    "    info_dict['summary'] = process_summary(data.iloc[project_index]['summary'])\n",
    "    info_dict['summary'] = new_summary = ['- ' + x.replace(\"'\", '') for x in info_dict['summary'] if x != '']\n",
    "    info_dict['reason'] = data.iloc[project_index]['reason'].split('แล้ว):')[-1].replace(\"',\", '').replace(\"'\", '').strip()\n",
    "    print(info_dict['reason'])\n",
    "    # strip everyshit\n",
    "    for key in info_dict.keys():\n",
    "        if type(info_dict[key]) == str:\n",
    "            info_dict[key] = info_dict[key].strip()\n",
    "        elif type(info_dict[key]) == list:\n",
    "            info_dict[key] = [x.strip() for x in info_dict[key]]\n",
    "        elif type(info_dict[key]) == dict:\n",
    "            for key2 in info_dict[key].keys():\n",
    "                info_dict[key][key2] = info_dict[key][key2].strip()\n",
    "    \n",
    "    posts.append(info_dict)\n",
    "\n",
    "    # download image and save to static/images in format \"/images/2022/21/01.jpg\"\n",
    "    # make folder according to ['ID']\n",
    "    if os.path.exists(root) == False:\n",
    "        os.mkdir(root)\n",
    "\n",
    "    if os.path.exists(root + data.iloc[project_index]['ID'].astype(str)) == False:\n",
    "        os.mkdir(root + data.iloc[project_index]['ID'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_md(data_dict):\n",
    "    md_format ='''---\n",
    "date: \"{}\"\n",
    "title: \"{}\"\n",
    "builder: \"{}\"\n",
    "builder_info: \"{}\"\n",
    "thumbnail: \"{}\"\n",
    "links:\n",
    "    github: \"{}\"\n",
    "    facebook: \"{}\"\n",
    "    blog: \"{}\"\n",
    "---\n",
    "\n",
    "![image]({})\n",
    "\n",
    "{}\n",
    "\n",
    "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
    "\n",
    "> \"{}\"'''\n",
    "\n",
    "    return md_format.format(data_dict['date'], data_dict['title'], data_dict['builder'], data_dict['builder_info'], data_dict['thumbnail'][1:], data_dict['links']['github'], data_dict['links']['facebook'], data_dict['links']['blog'], data_dict['thumbnail'][1:], '\\n'.join(data_dict['summary']), data_dict['reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ID</th>\n",
       "      <th>summary</th>\n",
       "      <th>title_image</th>\n",
       "      <th>images</th>\n",
       "      <th>links</th>\n",
       "      <th>reason</th>\n",
       "      <th>author</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>post_url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, ID, summary, title_image, images, links, reason, author, fulltext, post_url, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['title'] == 'MyLittleHR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "date: \"1-7-22\"\n",
      "title: \"BACK (Blind All Can Know) - Action Captioning for Blinds\"\n",
      "builder: \"โชติวัฒน์ ตั้งสถาพร (ไนน์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/21/01.jpg\"\n",
      "links:\n",
      "    github: \"https://colab.research.google.com/github/cninet/BACK/blob/main/BACK.ipynb\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/405337768301335\"\n",
      "    blog: \"https://medium.com/@cninet.std/back-blind-all-can-know-action-captioning-a10a3fa85695\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/21/01.jpg)\n",
      "\n",
      "- โมเดลอธิบายรูปภาพ (image captioning) เพื่ออธิบายภาพตรงหน้าให้กับผู้พิการทางสายตา,\n",
      "- CLIPCap นำ pretrained CLIP เพื่อสร้าง image embeddings เป็น input ให้กับ pretrained GPT2 สร้างข้อความที่ตรงกับภาพ,\n",
      "- เทรนโมเดลด้วย Flickr30k (รูป-คำบรรยายภาษาอังกฤษ) เป็นเวลา 17 ชั่วโมง (10 epochs),\n",
      "- ตัดสินใจใช้ Flickr30k ทั้งที่จำนวนข้อมูลน้อยกว่า COCO เพราะทำแบบสอบถามแล้วพบว่าข้อมูลคำบรรยายของ Flickr30k มีคุณภาพมากกว่า,\n",
      "- ใช้ PyThaiNLP Translate ในการแปลภาษาคำบรรยายเป็นภาษาไทย เนื่องจากแบบสอบถามพบว่าเป็นธรรมชาติกว่า Google Translate API ในบริบทนี้,\n",
      "- ใช้ Google TTS ในการเปลี่ยนคำบรรยายที่ถูกแปลเป็นเสียงพูด,\n",
      "- นอกจากการเทรนโมเดล CLIPCap ตรง ๆ แล้วยังมีการนำมาประกอบการใช้งานกับ pretrained models อื่น ๆ เช่น PyThaiNLP Translate และ Google TTS อีกทั้งการต่อสู้กับคุณภาพข้อมูลอย่างสมศักดิ์ศรี เช่น ลบรูปซ้ำ, แก้ข้อมูลตาราง, แก้คำบรรยายที่มีมากกว่าหนึ่งประโยคต่อกัน ฯลฯ\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เคยเข้าร่วมโครงการ Samsung Innovation Campus มาแล้ว (ได้เรียนพื้นฐานของ Python และ AI มาบ้างเล็กน้อย) และอยากเรียนรู้เรื่องการทำ AI ที่มากขึ้นเพื่อสามารถนำไปต่อยอดในการทำโปรแกรมที่อยากทำ  อนาคตใฝ่ฝันอยากเป็นโปรแกรมเมอร์ ตอนนี้เลยเริ่มศึกษาหาความรู้เกี่ยวกับการเขียนโค้ด และเก็บเกี่ยวประสบการณ์ให้ได้มากที่สุดเท่าที่จะทำได้ และอยากมีโปรแกรมเป็นของตัวเองที่สามารถใช้แก้ปัญหาได้จริง และอยากนำความรู้ที่ได้ไปต่อยอดทำแอปฯ ที่ช่วยเหลือสังคมในอนาคต (BACK)  สิ่งที่อยากทำคือ Blind All Can Know (BACK) เป็นแอปพลิเคชันที่ช่วยบรรยายการกระทำต่าง ๆ ออกมาเป็นเสียง ที่สามารถทำได้แบบ real-time เพื่อช่วยเหลือผู้พิการทางการมองเห็น จะได้สามารถรับรู้ว่าเกิดอะไรขึ้นบ้าง ช่วยให้การใช้ชีวิตสะดวกสบายมากขึ้น (https://news.samsung.com/th/sic-coding-for-students ป.ล. Can Know ไม่ใช่ Can See ;-;;)\"\n",
      "---\n",
      "date: \"2-7-22\"\n",
      "title: \"Violence Detection\"\n",
      "builder: \"ชินวัตร นาไชยธง (ม่อน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/22/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/monshinawatra/ViolenceDetection\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/405998371568608\"\n",
      "    blog: \"https://medium.com/@monchinawat/%E0%B8%95%E0%B8%A3%E0%B8%A7%E0%B8%88%E0%B8%88%E0%B8%B1%E0%B8%9A%E0%B8%84%E0%B8%A7%E0%B8%B2%E0%B8%A1%E0%B8%A3%E0%B8%B8%E0%B8%99%E0%B9%81%E0%B8%A3%E0%B8%87%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2-video-classification-%E0%B8%89%E0%B8%9A%E0%B8%B1%E0%B8%9A%E0%B8%87%E0%B9%88%E0%B8%B2%E0%B8%A2-d2bbf894149f\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/22/01.jpg)\n",
      "\n",
      "- โมเดลตรวจจับการใช้ความรุนแรงจากกล้องวงจรปิดด้วย action recognition ในแต่ละเฟรม,\n",
      "- เทรนบนชุดข้อมูลที่รวบรวมจาก UCF101 (แยกวิดีโอ เช่น boxing, sumo เป็น violence), Real Life Violence Situations Dataset (1,000 violence, 1,000 non-violence), sparshdrolia/violence, Hockey Fight Videos,\n",
      "- คัดเลือกเฟรมที่จะใช้เทรนด้วย feature engineering แบบเฉพาะที่ทำให้โมเดลทำงานได้ดีกว่าใช้ทุกเฟรม โดยแบ่งวิดีโอเป็นช่วงๆ s ช่วง โดยมากสุด m ช่วง แล้วในแต่ละช่วงเราจะดึง features ออกมาโดย และเราจะข้ามเฟรมทุกๆ k เฟรมในช่วงที่ s นั้น,\n",
      "- เปลี่ยนรูปภาพในแต่ละเฟรมให้เป็น features ด้วย pretrained VGG16; เรียงตามลำดับเวลาในวิดีโอ,\n",
      "- นำ features เหล่านั้นมาเป็น input ให้กับ LSTM โดยใช้ 20 เฟรมก่อนหน้าจนถึงเฟรมปัจจุบัน มาทายว่าเฟรมปัจจุบันมีการใช้ความรุนแรงหรือไม่,\n",
      "- ความแม่นยำ (accuracy) ในระดับเฟรมอยู่ที่ 74.8% ใน test set\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ถ้ามีโอกาสได้เข้ามาศึกษาหาความรู้ ผมจะเอาความรู้ที่ได้ไปลงแข่งขันในรายการ TH National Software Contest อย่างแน่นอน ซึ่งจะทำอย่างสุดความสามารถเพื่อเป็นเกียรติแก่ความรู้ทั้งหมดที่จะได้รับมากจากโครงการนี้ ผมจะไม่หยุดแค่ได้เข้ามาเรียนรู้แล้วรู้สึกว่ามันเปิดโลกมากมายแล้วจบไปแค่นั้น แต่หลังจากนั้นผมจะทำโครงการให้สำเร็จและ จะสร้างสรรค์ไอเดียใหม่ๆออกมาเรื่อยๆอย่างต่อเนื่องครับ  ตั้งใจไว้ว่าจะลงแข่งขัน NSC ในปีหน้า จึงต้องการความรู้เรื่อง Machine learning อย่างมาก เพื่อไปทำโปรเจคส่งเข้าประกวดการแข่งขัน NSC ซึ่งผ่านมาเห็นโครงการ AI Builder พอดี และส่วนตัวเองก็มีความรู้เรื่อง Python มาพอสมควรแล้ว แต่ยังไม่แน่นเรื่อง Machine learning จึงเป็นโอกาสดีที่จะส่งเข้ามาคัดเลือกในโครงการนี้  อยากทำ Action Recognition ประมวลผลท่าทางภาษามือแล้วแปลงเป็นข้อความ เพื่อเอาไว้เข้าใจผู้ที่ใช้ภาษามือในการสื่อสาร เพื่อให้สามารถเข้าใจภาษามือได้ง่ายและสามารถสื่อสารกับผู้ที่บกพร่องการสื่อสารได้ง่ายมากขึ้น โดยจะอิงข้อมูลจาก กองทุนส่งเสริมและพัฒนาคุณภาพชีวิตคนพิการ\"\n",
      "---\n",
      "date: \"3-7-22\"\n",
      "title: \"Fake Product Detection on Online Retail\"\n",
      "builder: \"เจษฎา ปราณี (แจ็ค)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/23/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/JackJessada/fake_product_detect\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/406851801483265\"\n",
      "    blog: \"https://medium.com/@jessadajackpranee/%E0%B8%82%E0%B8%AD%E0%B8%87%E0%B8%9B%E0%B8%A5%E0%B8%AD%E0%B8%A1%E0%B8%81%E0%B8%B1%E0%B8%9A-e-commerce-c2d1bb142e2e\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/23/01.jpg)\n",
      "\n",
      "- โมเดลประเมินว่าสินค้าที่ขายออนไลน์ในเว็บไซต์เป็นของแท้, ของปลอม หรือของไม่มีแบรนด์โดยใช้ข้อมูลจากหน้า product detail page,\n",
      "- แรงบันดาลใจจากการสำรวจของ intelligencenode ที่ว่าช่วงโรคระบาด COVID-19 มีผู้ใช้พบของปลอมระหว่างเลือกซื้อสินค้าออนไลน์ถึง 38% จากผู้ตอบแบบสอบถามทั้งหมด,\n",
      "- เก็บข้อมูลโดยการใช้ selenium ดึงข้อมูลจากหมวดหมู่เครื่องใช้ไฟฟ้าของ Shopee.co.th จำนวนเกือบ 5,000 รายการ แล้วจำแนกเป็นของแท้ (79%), ของปลอม (9%) และของไม่มีแบรนด์ (12%) **ด้วยมือเองทั้งหมด**,\n",
      "- ทำการ rebalance training set ด้วย SMOTE เป็นของแท้ 55%, ของปลอม 20% และของไม่มีแบรนด์ 25% เพื่อให้โมเดลเรียนรู้ได้ดีขึ้น,\n",
      "- ไม่ลืมที่จะแบ่ง test set ออกมาก่อน เพื่อไม่ให้มีการทดสอบหา metric ด้วยข้อมูลสังเคราะห์ จะทำให้โมเดลดูดีเกินจริง,\n",
      "- ใช้ feature จากหน้า product detail page โดยอ้างอิงสิ่งที่มนุษย์ใช้จำแนกของแท้-ของปลอม เช่น ราคา (ไม่ถูกหรือแพงเกินไป), จำนวนสินค้าที่ถูกขาย (ยอดขายไม่เวอร์จนเกินไป), จำนวนรีวิวสินค้า (รีวิวไม่เยอะหรือน้อยจนผิดสังเกต), จำสินค้าที่ร้านค้าขายทั้งหมด (ยิ่งขายเยอะยิ่งน่าเชื่อถือ), อัตราการตอบกลับของร้านค้า (ยิ่งตอบเร็วยิ่งใส่ใจลูกค้า), จำนวนผู้ติดตามร้านค้า (ไม่ได้มีผู้ติดตามปลอมเยอะจนผิดสัดส่วน), ระยะเวลาที่เปิดร้านค้ามา (ยิ่งยาวนานยิ่งน่าเชื่อถือ), เรตติ้งของสินค้า (ไม่ถูกปลอมขึ้นมา) ฯลฯ,\n",
      "- เลือกโมเดลที่ดีที่สุดด้วย cross-validation จาก KNN, Random Forest, และ XGBoost; เลือกใช้ Random Forest เนื่องจากผลงานดีพอๆกับ XGBoost แต่ใช้งานได้เร็วกว่า,\n",
      "- ลองนำคอมเม้นท์ในหน้า product detail page มาเป็น feature เพิ่มแล้ว แต่ผลไม่ดีขึ้น สันนิษฐานว่าเกิดจากโมเดลไม่สามารถแบ่งคุณภาพคอมเม้นท์ได้ เช่น คอมเม้นท์ปลอม มีคอมเม้นท์ประเภทร้านค้าขอให้พิมพ์ และคอมเม้นท์ที่ไม่เกี่ยวกับเนื้อหาเลย เป็นต้น,\n",
      "- ได้ผลดีถึง F1 score ที่ 0.9x ใน test set ทั้ง micro/macro average และในแต่ละประเภทสินค้าที่ทำนาย,\n",
      "- แต่เมื่อไปทดสอบกับประเภทสินค้าที่ไม่คุ้นเคย, product detail page จากเว็บไซต์อื่นที่ไม่ใช่ Shopee.co.th, หรือสินค้าที่ไม่ครอบคลุมจาก training set ยังพบเห็นความผิดพลาด; ต้องการข้อมูลเพิ่มเพื่อทำให้สมบูรณ์แบบ,\n",
      "- ทำการวิเคราะห์ข้อผิดพลาดอย่างเข้มข้นด้วย SHAP; หนึ่งในข้อสรุปที่น่าสนใจคือต้นไม้บางต้นตัดสินว่า \"ยิ่งยอดขายมาก ยิ่งมีโอกาสเป็นของปลอม\" ทั้งนี้เนื่องจากพฤติกรรมการปั๊มยอดขายของสินค้าปลอมนั่นเอง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมชอบและถนัดทางคณิตศาสตร์ครับ การแก้ปัญหาต่าง ๆ และชอบลองอะไรใหม่ ๆ ผมมีประสบการณ์ภาษา python มาบ้างรวมทั้งการใช้ libraries อื่น ๆ เช่น numpy pandas matplotlib  ผมอยากใช้เวลาว่างในช่วงปิดเทอมนี้เรียนรู้ในสิ่งที่ผมสนใจ ส่วนตัวผมรู้ตัวช้าไปว่าสนใจในด้านนี้ จึงอยากจะหาความรู้ให้ทันคนอื่น และนำความรู้ที่ได้ตรงนี้ไปต่อยอดในโครงงานต่อ ๆ ไป อีกอย่างผมเองก็สนใจทางด้าน AI มาสักพักหนึ่งแล้วเลยอยากใช้โอกาสที่ทาง AI Builders จัดโครงการดี ๆ แบบนี้ศึกษาเรื่องนี้ไปพร้อมกับโครงการเลย  โมเดลเช็คว่าสินค้ามีโอกาสเป็นของปลอมหรือไม่ ช่วยในการแก้ปัญหาสินค้าปลอมที่เห็นตามแพลตฟอร์มออนไลน์ต่าง ๆ โดยหาชุดข้อมูลจากการทำ web scraping ในหมวด เรตติ้ง ความคิดเห็น คะแนนร้านค้า รูปภาพ ราคา และนำมาเปรียบเทียบข้อมูลกับสินค้าประเภทเดียวกันอื่น ๆ\"\n",
      "---\n",
      "date: \"4-7-22\"\n",
      "title: \"Cactus Classification with Fastai\"\n",
      "builder: \"ปัณณธร กรุดทอง (โฟกัส)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/24/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Fosacius/cactus_pred\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/407556248079487\"\n",
      "    blog: \"https://medium.com/@neko2nego/cactus-classification-with-fast-ai-393f8a64cadc\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/24/01.jpg)\n",
      "\n",
      "- โมเดลแยกประเภทแคคตัสที่มีหลากหลายสายพันธุ์ ทั้งต้นกระบองเพชรที่มีหนามที่เราคุ้นเคย ไปจนถึงแก้วมังกรก็เป็นแคคตัสประเภทหนึ่ง,\n",
      "- แรงบันดาลใจเกิดจากงานอดิเรกในการปลูกแคคตัส และต้องการดูแลให้ถูกต้องตามสายพันธุ์ โดยเฉพาะมือใหม่ที่อาจจะแยกสายพันธุ์ไม่ออก,\n",
      "- แยกแคคตัสเป็น 5 สกุลได้แก่ Ariocarpus, Astrophytum, Echinopsis, Gymnocalycium, และ Ophuntia,\n",
      "- สร้างชุดข้อมูลจาก DuckDuckGo image search โดยอ้างอิงหนังสือแคคตัส Cactus (ใหม่) ของภวพล ศุภนันทนานนท์รวมทั้งหมด 1,500 รูป แบ่งเป็น validation set สกุลละ 60 รูป,\n",
      "- ทำการปรับจูน pretrained resnet-50 เพื่อจำแนกสกุลแคคตัสได้ความแม่นยำที่ 87%,\n",
      "- มีแผนการเพิ่มสกุลแคคตัสไปถึง 20++,\n",
      "- สุขสันต์วันเกิดโฟกัสเมื่อ 7 กรกฎาคมที่ผ่านมา\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมมีความรู้ python ประมาณนึง และยังสามารถเขียนภาษา html css javascriptได้ครับ ผมคิดว่าจะนำเอาความรู้จากโครงการนี้ไปพัฒนาตัวเองต่อไปครับ  ได้มีเพื่อนของผมคนนึงได้สอนผมเขียน html css และ javascript และเขาได้แนะนำผมมาว่า\"ลองมาศึกษาเรื่อง ai ดูมั้ย\" ผมก็มีความคิดว่าเอ้อน่าสนใจดี ผมก็เลยคิดว่าจะได้รับประสบการณ์ใหม่ๆในโครงการครั้งนี้ครับ  ผมมีงานอดิเรกในการปลูกแคคตัสและบางทีผมก็เลี้ยงแคคตัสและผมต้องการจะรู้สายพันธุ์ของแคคตัสเพื่อที่จะได้ไปศึกษาวิธีดูแลต่อไป ผมจึงสนใจในการทำ ai ที่สามารถระบุสายพันธ์ของแคคตัสได้ครับ ชุดข้อมูลสามารถหาได้จาก internet หรือไปศึกษาและเก็บข้อมูลจากสวนแคคตัส\"\n",
      "---\n",
      "date: \"5-7-22\"\n",
      "title: \"Food Ingredients Label Reader for Food Allergy\"\n",
      "builder: \"พีรณัฐ เมฆวิศิษฏ์ (ปอนด์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/25/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/ponmak/Food-ingredients-label-reader\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/408346911333754\"\n",
      "    blog: \"https://medium.com/@peeranut.4498/food-ingredients-label-reader-for-food-allergy-6dea1de06d2\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/25/01.jpg)\n",
      "\n",
      "- โปรแกรมอ่านฉลากสินค้าด้วย pretrained OCR และค้นหาวัตถุดิบที่ผู้ใช้แพ้ด้วย pretrained word vector,\n",
      "- แรงบันดาลใจจากครอบครัวที่สายตาสั้นกันทั้งบ้านทำให้เวลาจะอ่านอะไรที่อยู่บนฉลากนั้นเป็นเรื่องยากพอสมควรโดนเฉพาะส่วนประกอบในอาหาร; หลายสินค้าไม่มีการเน้นชื่อวัตถุดิบที่คนแพ้ง่ายให้เห็นชัดเจน,\n",
      "- เลือกใช้ pretrained OCR ระหว่าง Google Vision, EasyOCR และ Tesseract; เลือกใช้ Google Vision เนื่องจากเหตุผลความเร็วในการทำนาย,\n",
      "- เปลี่ยนคำให้เป็น word vector ด้วย pretrained thai2fit แล้วหาความคล้ายกันด้วย cosine similarity ระหว่างคำในฉลากและชื่อวัตถุดิบ; ตัดคำด้วย dictionary-based newmm (PyThaiNLP default)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ต้องยอมรับ ณ ตรงนี่เลยนะครับว่าผมไม่ได้มีผลงานี่โดดเน้น แต่จะบอกว่าผมเป็นเป็ดที่พอจะสามารถเรียนรู้หลายๆอยากได้แต่ไปไม่สุดสักทาง ผมจึงมีความสนใจนี่อยากจะเอาAIมาประยุกต์ใช้กับการทำงานแขนงอื่นๆให้เกิดความสะดวกสะบาย  ผมอยากเข้าไปเรียนรู้การสร้างAIเพื่อในอนาตค อาจทำAIมาใช้ในการผลิตสื่อต่างๆเพื่อให้ความบันเทิง เข่น การตัดต่อภาพอัตโนมัดิ การปรับเพิ่มลดเสียงเพลงเองตามเสียงระดับเสียงคนร้อง เป็นต้น  ผมอยากทำAI motion capture ที่ให้ตรวจจับมือแล้วใช้ร่างการนั้นในการควบคุมระดับเสียงเพลงและความเร็วของเพลง ตาม กราฟ2มิติ ให้ระดับเสียงเป็น Y ให้ความเร็วเป็น X อาจมีการใส่เอฟเฟคที่เกิดจากmotionต่างๆเช่นหากมือมาโดนกันจะเกิดเสียงตบมือ โดนจะต้องหาชุดข้อมูลคือการข้อมูลรูปภาพมือเพื่อการให้AIรู้จักมือแล้วใช้มือในการควบคุมคล้าย/เหมือนกับ เมาส์ที่ใช้กัน โครงงานสามารถเอาไปต่อยอดในการทำสื่อหรือการแสดงได้และยังสามารถนำไปดักแปรงใช้กับควบคุมสำหรับผู้พิการอีกด้วย\"\n",
      "---\n",
      "date: \"6-7-22\"\n",
      "title: \"Edge-to-Face: Drawing Realistic Faces from Canny Edges\"\n",
      "builder: \"นิธิศรัฎฐ์ พุฒิภาพงศ์ (พลัส)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/26/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/PluzNtp/Edge-to-Face\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/409045037930608\"\n",
      "    blog: \"https://medium.com/@nitisarath/edge-to-face-683005cdbbb6\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/26/01.jpg)\n",
      "\n",
      "- โมเดล pix2pix GAN ที่เปลี่ยนรูปร่างหน้าคน (Edges) เป็นรูปภาพหน้าคน,\n",
      "- เทรนด้วยชุดข้อมูลหน้าดารา (ส่วนใหญ่จากสหรัฐอเมริกา) รวม 8,760 รูป,\n",
      "- ใช้ haarcascade จับหน้าจากรูป แล้วเปลี่ยนเป็นภาพร่างด้วย canny edge detection เพื่อใช้เป็น input สำหรับโมเดล (รูปจริงเป็น output),\n",
      "- ใช้สถาปัตยกรรม pix2pix GAN โดยใช้ L1 loss สำหรับ generator (U-Net; สร้างภาพปลอมโดยการเติมสีลงใน pixel) และ BCE loss สำหรับ discriminator (Patch GAN; ทำนายแต่ละ patch ในรูปว่าจริงหรือปลอม),\n",
      "- ในการใช้งานจริงเติมรูปจากภาพร่างที่คล้ายกับ training set ได้ดี (canny edges) แต่ยังมีปัญหากับภาพร่างแบบอื่น เช่น ภาพร่างที่หาจากอินเตอร์เน็ต\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมมีแรงบันดาลใจมาจากวีดีโอใน youtube ที่สอนให้ AI เดินได้ใน engine unity ผมคิดว่ามันเท่ดีผมเลยอยากเรียนรู้เรื่องเกี่ยวกับ ML และ AI เพิ่มขึ้นครับ  ผมอยากทำ AI ที่ช่วยเกี่ยวกับการคนตาบอดในการเดินทางดวย object detection ปกติพอเวลาคนตาบอดจะเดินทางแลวจะใช้ไม้เท้าในการเดิน AI ของผมจะบอกคนตาบอกวาข้างหน้ามีอะไรด้วยเสียงและเตือนคนตาบอดเวลาจะขามถนนพร้อมกับช่วยนำไปถงทางมาลายและตรวจจบไฟจราจรหาชดขอมลจาก pov ของนักเดินทางใน google และนำมาแมสสิ่งของเองหรือหาจากเว็ปที่ทำ preset video มาให้แล้วครับผมยังไม่แน่ใจนะครับว่าจะเปลี่ยนหรือเปล่า  สัปดาห์แรกที่ผมเข้าค่ายนี้ผมแทบไม่รู้อะไรเกี่ยวกับ ML เลยครับ 5555 ผมคิดว่าตัวเองได้เรียนรู้เยอะมากๆใน 10 สัปดาห์ที่ได้เข้าร่วมโครงการนี้ตั้งแต่ไม่รู้จักคำว่า GAN จนได้มาลองทำเองผมรู้สึกโชคดีมากครับที่ได้มาเป็นส่วนหนึ่งในโครงการนี้ขอขอบคุณพี่ๆเพื่อนๆในค่ายที่ค่อยช่วยเหลือผมตลอดและทำให้ผมรอดมาได้นะครับ\"\n",
      "---\n",
      "date: \"7-7-22\"\n",
      "title: \"TextDoe: โมเดลจำแนกแวดวงบทความสิ่งพิมพ์\"\n",
      "builder: \"โชติอนันต์ทรัพย์ โสภาเคน (โชกุน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/27/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/ChotanansubSoph/TextDoe\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/409755317859580\"\n",
      "    blog: \"https://medium.com/@chotanansub.s/text-classification-%E0%B8%88%E0%B8%B3%E0%B9%81%E0%B8%99%E0%B8%81%E0%B9%81%E0%B8%A7%E0%B8%94%E0%B8%A7%E0%B8%87%E0%B8%9A%E0%B8%97%E0%B8%84%E0%B8%A7%E0%B8%B2%E0%B8%A1%E0%B8%AA%E0%B8%B4%E0%B9%88%E0%B8%87%E0%B8%9E%E0%B8%B4%E0%B8%A1%E0%B8%9E%E0%B9%8C-db0ef5abc676\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/27/01.jpg)\n",
      "\n",
      "- โมเดลจำแนกประเภทเอกสารเพื่อลดระยะเวลาในการคัดแยกเอกสารและสามารถทำงานได้แบบอัตโนมัติ ประเภทได้แก่ Applied Science, Arts, Belief & Thought, Commerce & Finance, History, Imaginative, Natural & Pure Science, Social Science,\n",
      "- เทรนบน TNC ด้วยข้อมูลจากหนังสือ (60%), วารสาร (25), หนังสือพิมพ์ (5-10%), สิ่งพิมพ์อื่น (เช่น แผ่นพับโฆษณา; 5-10%) และงานเขียนเผยแพร่บนอินเตอร์เน็ต (<5%),\n",
      "- แบ่งข้อมูลตามเลข Serial Number ของ TNC โดยใช้ฟังชั่นเฉพาะทำให้จำนวนเอกสารแต่ละแหล่งออกมาสมดุลใน train, validation และ test set,\n",
      "- ใช้ WangchanBERTa เป็นโมเดลพื้นฐาน; ปรับจูนให้ทำการจำแนกประเภทเอกสาร,\n",
      "- WangchanBERTa (F1 0.71) ทำได้ดีกว่า baseline ที่ใช้ bag-of-words (F1 0.64) และ LSTM (F1 0.61),\n",
      "- วิเคราะห์ความผิดพลาดพบว่าบางครั้งประเภทของเอกสารมีความกำกวม เช่น เอกสาร \"ความร่วมมือของประเทศในภูมิภาคเอเชียตะวันออกเฉียงใต้ ในการก่อตั้งองค์การส่วนภูมิภาค 1945–1985\" เป็น History แต่โมเดลทายว่า Social Science\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เพราะผมมีความชื่นชอบในแวดวง คอมพิวเตอร์และเทคโนโลยีเป็นอย่างมาก ทำให้ผมคอยที่จะมองหาโอกาสที่จะพัฒนาทักษะความรู้ความสามารถที่เกี่ยวข้องกับสาขา คอมพิวเตอร์อยู่ตลอดเวลา อาทิเช่น การฝึกฝนเขียนโปรแกรม และ การศึกษาความรู้ที่เกี่ยวข้องกับคณิตศาสตร์ประยุกต์ เป็นต้น ปัจจุบันผมมีความสนใจที่จะศึกษา และ เพิ่มพูนประสบการณ์ที่เกี่ยวข้องกับสาขาปัญญาประดิษฐ์ ผมจึงหวังเป็นอย่างยิ่งว่า โครงการที่จัดขึ้นในครั้งนี้ จะช่วยทำให้ผมสามารถพัฒนาทักษะต่างๆทีเกี่ยวข้อง เพื่อนำไปสู่การสร้างสรรค์โครงงานปัญญาประดิษฐ์ ที่ก่อให้เกิดประโยชน์ต่อสังคมส่วนร่วมต่อไป\"\n",
      "---\n",
      "date: \"8-7-22\"\n",
      "title: \"Auto Lyric Recognizer\"\n",
      "builder: \"กิตติพงศ์ เทพอยู่ (ปืน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/28/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/KittpongT/auto_lyric_recognize\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/410400524461726\"\n",
      "    blog: \"https://medium.com/@puenkittipongtapyou/ai-%E0%B8%96%E0%B8%AD%E0%B8%94%E0%B9%80%E0%B8%AA%E0%B8%B5%E0%B8%A2%E0%B8%87%E0%B8%A3%E0%B9%89%E0%B8%AD%E0%B8%87%E0%B8%A0%E0%B8%B2%E0%B8%A9%E0%B8%B2%E0%B9%84%E0%B8%97%E0%B8%A2-speech-to-text-%E0%B8%89%E0%B8%9A%E0%B8%B1%E0%B8%9A%E0%B8%A1%E0%B8%B7%E0%B8%AD%E0%B9%83%E0%B8%AB%E0%B8%A1%E0%B9%88-fcca46eeb3df\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/28/01.jpg)\n",
      "\n",
      "- โมเดลถอดคำร้องเพลงไทยจากไฟล์เสียงหรือลิ้งค์ YouTube โดยตรง ด้วย Wav2Vec2 ที่ถูกปรับจูน,\n",
      "- ใช้ข้อมูล 50 เพลงยอดฮิตบน YouTube ตามยอดคนฟังเป็นความยาว 150 นาที,\n",
      "- แยกเสียงเพลงออกจากเนื้อร้องด้วย Spleeter; ตัดเป็นคลิปละ 2-6 วินาทีเพื่อให้เหมาะกับการเทรนโมเดล,\n",
      "- พบปัญหาเนื้อเพลงที่เป็นข้อความไม่ตรงกับเสียง; แก้ปัญหาด้วยการตัดมือแบ่งกับน้องนนนี่ เพื่อนในโครงการ,\n",
      "- ทำความสะอาดเครื่องหมายพิเศษเข้ามาด้วย เช่น . , ที่เกิดจาการเชื่อมต่อประโยคต่างๆในเนื้อเพลง; เปลี่ยน ๆ เป็นการเพิ่มคำซ้ำในประโยคเช่น สิ่งต่างๆ เป็น สิ่งต่างต่าง; เปลี่ยน สระ แ ที่มักถูกเขียนในรูปของสระ เ เ เเละสระ ำ เป็น ํ า,\n",
      "- แบ่ง train-valid-test ที่ 50:25:25,\n",
      "- ใช้ airesearch/wav2vec2-large-xlsr-53-th ที่ถูกเทรนบน Common Voice 7 เป็นโมเดลพื้นฐาน,\n",
      "- วัดผลด้วย WER (ตัดคำด้วย newmm ของ PyThaiNLP) และ CER; ทำได้ดีกว่า airesearch/wav2vec2-large-xlsr-53-th ประมาณ 3-4 เท่าบน test set\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"อยากเรียนรู้การทำAIในรูปแบบต่างๆ เพราะผมเคยทำโครงงานด้านนี้และรู้สึกสนใจอยากศึกษาจริงจัง และคิดว่าค่ายนี้จะสามารถเพิ่มความรู้และความเข้าใจเกี่ยวกับAIเพิ่มขึ้นนำความรู้ไปพัฒนางานหรือโครงงานที่ทำให้มีประสิทธิภาพและความถูกต้องที่เพิ่มขึ้น หรือได้เรียนรู้หลักการ เทคนิคต่างๆในการเทรนด์โมเดลที่ใช้ในการประมวลผล และสามารถนำความรู้นี้ไปต่อยอดงานด้าน AI ในอนาคตของผมได้\"\n",
      "---\n",
      "date: \"9-7-22\"\n",
      "title: \"Image Transfer Day-to-Night and Night-to-Day\"\n",
      "builder: \"ณฐกร คเชนทร (เท็น)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/29/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/TENet1010/cycleGAN_Night2day\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/411124194389359\"\n",
      "    blog: \"https://medium.com/@nattakorn2713/image-transfer-night-to-day-and-day-to-night-2086edc6b298\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/29/01.jpg)\n",
      "\n",
      "- เริ่มด้วยปัญหาเวลาเล่น social media ต่างๆแล้วเจอคลิปที่ถ่ายสิ่งลี้ลับ, อะไรที่ดูน่ากลัว หรือพลังงานบางอย่าง เมื่อถูกจับภาพไว้ได้ก็มักจะเป็นภาพที่ไม่ชัดและส่วนใหญ่เป็นตอนกลางคืน บางทีสิ่งเหล่านี้อาจเกินจากการตีความที่ผิดพลาดเนื่องจากละเอียดหายไปกับความมืดจึงอยากที่จะเปลี่ยนภาพพวกนี้ให้เป็นตอนกลางวันสดใส เพื่อดึงรายละเอียดที่หายได้กับความมืดกลับมา,\n",
      "- สาเหตุของความไม่ชัดคาดว่าเกิดจาก ความไวแสง (ISO; ยิ่งเพิ่มยิ่งสว่างแต่อยากทำให้เกิด noise), F-stop (เมื่อค่า F-stop ต่ำรูปจะชัดเพียงที่โฟกัสและสว่าง แต่ถ้าค่า F-stop มากก็จะทำให้ชัดทั้งภาพ แต่ภาพก็จะมืด), รวมถึงคุณภาพของกล้องและเลนส์,\n",
      "- วิธีแก้โดยไม่ใช้ ML เช่น ใช้ Adobe Lightroom ปรับค่า exposure แต่ก็จะทำให้เสียคุณภาพของรูปไป,\n",
      "- ใช้ CycleGAN ในการทำ image-to-image translation; ข้อดีคือไม่จำเป็นต้องใช้คู่รูปกลางวัน-กลางคืนของรูปเดียวกันเพราะ CycleGAN ใช้วิธี optimize ค่า cycle-consistency loss จากรูปภาพเดียวกันที่ถูกแปลงจากกลางวันเป็นกลางคืน หรือกลับกัน,\n",
      "- ใช้ PatchGAN เป็น discriminator และ generator เป็น autoencoder ที่มี residual block 9 ชั้น,\n",
      "- ทดลองรูปภาพจาก Aachen Day-Night dataset, Day-night Dataset จาก Kaggle, Mapillary Vistas Dataset, Day time and Night time road Images, Dataset Night city image; สุดท้ายใช้ภาพกลางวันจาก Mapillary Vistas Dataset และกลางคืนจาก Dataset Night city image อย่างละ 2,500 ภาพเป็น training set และอย่างละ 600 ภาพเป็น test set,\n",
      "- แปลงรูปภาพได้ค่อนข้างน่าพอใจหลังเทรนไป 55 epochs; หลัง error analysis พบภาพที่ผิด เช่น การเติมแสงไฟในรูปที่ไม่ควรเติมเมื่อแปลงรูปจากกลางวันเป็นกลางคืน คาดว่าอาจเกิดจากการที่ใน Dataset มี ภาพที่เป็นแสงไฟจากเมืองรถค่อนข้างมาก, ภาพจริงมีสะพานอยู่ แต่ภาพที่โมเดลสร้างขึ้นได้ลบสะพานให้กลายเป็นท้องฟ้า คาดว่าน่าจะเกิดจากการที่สะพานอยู่ซ้อนทับกับท้องฟ้าเลยอาจทำให้โมเดลคิดว่าสะพานเป็นส่วนหนึ่งของท้องฟ้า,\n",
      "- ใช้ FID score (Fréchet inception distance) ในการวัดคุณภาพ ในการ generate ภาพ FID score วัดได้โดยการนำรูปที่ generate หลายๆรูปกับภาพจริงจำนวนเท่ามาโยนเข้า inception v3 แล้วนำ distribution ของภาพจริงและภาพที่ generate มาเทียบกัน โดย FID ยิ่งน้อยเท่าไรก็นิ่งดีเท่านั้น; night-to-day FID = 75.68 vs day-to-night FID = 57.80 คาดว่าการเปลี่ยนภาพกลางวันเป็นกลางคืนนั้นเป็นการลดรายละเอียดของภาพซึ่งทำได้ง่ายกว่า night to day ที่เป็นการเพิ่มรายละเอียดของภาพ\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เพราะโครงการ AI Builders และ อาจารย์หรือนักวิจัยหลายๆที่ได้รับเชิญเป็นหนึ่งในแรงบันดาลใจ ทำให้เริ่มต้นเส้นทางสาย AI ด้วยการศึกษาจากในอินเตอร์และเน็ตจึงทำให้มีพื้นฐาน ภาษาpython การใช้ numpy pandas ในการจัดการข้อมูล แล้วนำมาทำ Data visualization สามารถทำ web scraping ได้ รู้จักโมเดล machine learning ต่างๆ มีพื้นฐาน deep learning เล็กน้อย  เหตุผลที่ทำให้อยากเข้าร่วมโครงการเริ่มจากในปีที่แล้วได้เห็นโครงการที่มีชื่อว่า AI Builders และเกิดความสนใจเป็นอย่างมากแต่เนื่องจากปิดรับสมัคร จึงตัดสินใจติดตามกิจกรรมที่ได้ลงย้อนหลังใน facebook เป็นจุดเริ่มต้นที่จุดประกายความชอบด้าน AI จึงได้เริ่มศึกษาการเขียนโปรแกรมภาษา python และ library ต่างๆที่ใช้การจัดข้อมูลทำให้รู้สึกสนุกกับคณิตศาสตร์มากขึ้นเพราะไม่ได้ใช้คิดคำนวนเพียงในห้องเรียน แต่สามารถนำมาประยุกต์ตอบปัญหาต่างๆได้ ต่อมาค่อยศึกษาด้าน AI มากขึ้นพบว่าศาสตร์นี้มีความน่าหลงใหล ทั้งในเรื่องของการใช้แก้ปัญหา และ ในด้านแนวคิดเชิงปรัชญาในกระบวนการทำงานของ AI เมื่อโอกาศที่ดีอย่างโครงการนี้กลับมาอีกครั้งผมเลยคิดว่าต้องลงให้ได้ ถ้าได้รับคัดเลือกผมจะนำความรู้ด้านต่างๆ เช่น NLP image pocessing ฯลฯ และ ประสบการณ์ที่ได้ถ่ายถอด เหล่าพี่ๆ mentor ไปทำ project ที่ก่อให้เกิดประโยชน์ต่อสังคมไม่มากก็น้อย ขอบคุณครับ  ปัญหาเมื่อมีการบึกทึกภาพในที่มืดแล้วนั้นทำให้รายละละเอียดภายในภาพไม่ชัดเจนและคลุมเครือ และ อาจนําไปสู่การตีความสิ่งอยู่ในภาพผิดไปจากความเป็นจริง ซึ่งการเพิ่มแสงด้วยโปรแกรมแต่งภาพจะทำให้รายละละเอียดไปได้หากไฟล์คุณภาพต่ำ ผมจึงอยากจะทำAI ที่สามารถ generate ภาพจากภาพที่มืดและมีรายละเอียดไม่ชัดเจนให้มีความสว่างให้สามารถมองเห็นสีและรายละเอียดวัตถุภายในภาพได้ชัดเจนเหมือนตอนกลางวัน ในส่วนของ Data set จะเป็นถ่ายภาพในสถาที่และมุมกล้องเดี่ยวกันแต่แบ่งออกเป็น ภาพที่สว่าง และ ภาพที่มืด\"\n",
      "---\n",
      "date: \"10-7-22\"\n",
      "title: \"Music Recognition\"\n",
      "builder: \"นนทพรรษ วงษ์กัณหา (นน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/30/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Nonnyss/Ms-Wav2Vec2-Finetune\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/411804267654685\"\n",
      "    blog: \"https://medium.com/@nonthapan.wong/music-recognition-a6c9acea23e1\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/30/01.jpg)\n",
      "\n",
      "- โมเดลถอดเสียงเนื้อเพลงภาษาไทย แรงบันดาลใจการเป็นคนที่ชอบฟังเพลง 🎶 แต่บางทีนึกชื่อเพลงไม่ออก จำได้แต่เนื้อเพลงบางท่อน หรือแม้กระทั่งเวลาไปคาเฟ่ ☕ ที่เปิดเพลงเพราะๆ ก็มักจะไม่รู้ว่าเพลงนั้นเป็นเพลงอะไร (ขี้อายไม่กล้าถามพนักงาน🥲),\n",
      "- เริ่มจากใช้ Wav2Vec2 ภาษาไทยเป็น baseline; โมเดลอาจทำได้ดีในบทสนทนาทั่วไป (speech-to-text) แต่ผลงานในการถอดเสียงเพลงไม่ดีนัก (sing-to-text) ทั้งจากการร้องสดและคลิปเพลง,\n",
      "- ใช้ข้อมูล 40 เพลงบน YouTube ตามยอดคนฟังเป็นความยาว 2.5 ชั่วโมง,\n",
      "- ทำความสะอาดด้วยการแยกเสียงเครื่องดนตรีจากเนื้อร้อง, ตัดเป็นคลิปเสียงคลิปละ 2-6 วินาทีด้วย Adobe Audition, คัดเนื้อร้องที่เป็นภาษาอังกฤษออก, และทำความสะอาดเครื่องหมายต่างๆ เช่น `จนผ่านวันร้ายๆ` ➜ `จนผ่านวันร้ายร้าย`; พบปัญหา เช่น เสียงร้องกลืนเข้าไปกับ BGM, เสียงคอรัสร้องหลายเนื้อร้องในเวลาเดียวกัน เป็นต้น ทำการคัดเลือกออก**ด้วยมือ**,\n",
      "- พบปัญหาเนื้อเพลงที่เป็นข้อความไม่ตรงกับเสียง; แก้ปัญหาด้วยการตัดมือแบ่งกับปืน เพื่อนในโครงการ,\n",
      "- เสียงมาจากนักร้องชาย 28 คน นักร้องหญิง 12 คน; แบ่ง train-validation-test เป็น 80:10:10,\n",
      "- มีข้อสังเกตว่าโมเดลที่ถูกเทรนบนเสียงนักร้องมืออาชีพจะสามารถถอดความเสียงมือสมัครเล่นที่ร้องเพี้ยนได้หรือเปล่า อาจจะพัฒนาเป็นโมเดลจับคนร้องเพี้ยนต่อไป,\n",
      "- ใช้ airesearch/wav2vec2-large-xlsr-53-th ที่ถูกเทรนบน Common Voice 7 เป็นโมเดลพื้นฐาน,\n",
      "- วัดผลด้วย WER (ตัดคำด้วย newmm ของ PyThaiNLP) และ CER; ทำได้ดีกว่า airesearch/wav2vec2-large-xlsr-53-th ประมาณ 3-4 เท่าบน test set\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เป็นคนที่มีความรู้ความชื่นชอบทางด้านคณิตศาสตร์เป็นอย่างมาก คณิตศาสตร์ถือเป็นวิชาที่ถนัดที่สุดสำหรับผม เป็นคนที่ถ้าได้ตั้งใจทำอะไรบางอย่างแล้วก็จะทุ่มเทให้กับสิ่งนั้น แบบ มี 100 ให้ 100 ไปเลย, มีผลงานที่เป็นผลจากความทุ่มเทอยู่บ้างเช่น การแข่งหุ่นยนตร์ รายการ wrg , สพฐ 9ล9 และกิจกรรมการเข้าร่วมกับค่าย ที่เกี่ยวกับคอมพิวเตอร์และเทคโนโลยีต่างๆ, มีเวลา พร้อมที่จะสละให้กับโครงการนี้อย่างเต็มที่, มีความสามารถเข้ากับคนอื่นได้ง่าย, และมีความสนใจในปัญญาปัญญาประดิษฐ์!  อยากเข้าเพราะ ตั้งแต่ที่ได้เห็นพัฒนาการของเทคโนโลยีตั้งแต่เด็ก จนถึงปัจุบันที่สิ่งต่างๆเติบโตขึ้นเร็วมาก มีสิ่งใหม่ๆออกมาให้เราเห็นทุกวัน ทุกอย่างทั้งน่าตื่นเต้น และน่าสนใจ จนเราเอง ก็อยากเป็นคนที่ได้ร่วมพัฒนาสิ่งเหล่านั้นแหละเติบโตไปพร้อมกับมัน แต่เนื่องจากผมไม่ได้มีประสบการณ์ในด้านนี้มาก มีแต่ความตั้งใจและความรู้ทางด้านคณิตศาสตร์ โครงการนี้จึง \"สำคัญกับผม\" ที่จะทำให้ผมได้เริ่มต้นเส้นทางนี้อย่างจริงจัง! และจะเป็นอีกหนึ่งประสบการณ์ที่จะช่วยต่อยอดการทำโครงงานจบ และการเรียนต่อมหาลัยในอาคต  อีกทั้ง เรื่องความดูแลเอาใจใส่ที่มีมาให้ตั้งแต่ยังไม่ได้ร่วมโครงการเลยด้วยซ้ำ เช่นเรื่อง Pre-course Workhop เพื่อปรับพื้นฐาน, ตารางการเรียนที่ชัดเจนจริงจัง, แบบทดสอบที่มีมาให้ม รุ่นพี่ที่ผ่านโครงการนี้มาปีที่แล้ว ก็มีแต่ผลงานเจ๋งๆ มีคุณภาพ ออกมา แบบนี้ใครจะไม่อยากเข้าร่วมโครงการนี้ครับ!! ผลงานแบบนี้ต้องมี mentor และ TA เก่งๆคอยให้คำแนะนำแน่นอน! :) ขอบคุณครับ  อยากทำ ai ที่ ช่วยเราหา \"เพลง\" เพื่อแก้ปัญหา => เวลาที่จำได้แค่ทำนองเพลง หรือถึงจำเนื้อร้องได้ แต่เนื้อร้องดันเป็นภาษาอะไรก็ไม่รู้ ทำให้เรารู้สึกหงุดหงิด คิดไม่ออกสักทีว่า เพลงที่ร้องแบบนี้มันชื่อเพลงอะไรนะ!?? มีรูปแบบการทำงานคร่าวๆ เริ่มต้นที่ รับข้อมูลเสียง(เสียงทำนอง,เสียงร้อง) > ai ประมวลผล > แสดงเพลงที่ประมวลผลได้ออกมาให้ผู้ใช้ ใช้ชุดข้อมูล จำพวก เนื้อเพลง และ เสียงเพลง มาจาก kaggle\"\n",
      "---\n",
      "date: \"11-7-22\"\n",
      "title: \"vTranslator: Transcribe and Translate VTuber using Wav2Vec2\"\n",
      "builder: \"ธนภณ ทองจำนงค์ (ธันย์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/31/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/thunni-noi/vTranslator-prototype\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/412504900917955\"\n",
      "    blog: \"https://medium.com/@thunninoi/vtranslator-vtuber-speech-recognition-with-wav2vec2-cba2e2c4a6df\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/31/01.jpg)\n",
      "\n",
      "- vTranslator คือสคริปต์ที่จะ generate ซับไตเติลของคลิปนั้นๆออกมาเป็นภาษาที่ต้องการ โดยเป็นการรวมกันระหว่างตัว Speech-Recognition Wav2Vec2 และตัว Google Translate เพื่อสร้างไฟล์ซับไตเติล (.srt) ขึ้นมา โดย model Wav2Vec2 ที่นำมาใช้นั้นจะถูก fine-tuned โดยใช้เสียงของ VTuber Hololive เป็นหลัก!,\n",
      "- แรงบันดาลใจจากการชอบดู VTuber แต่ไม่เข้าใจภาษาญี่ปุ่น ส่วนใหญ่ดูผ่านคนแปลตาม YouTube; อยากดูให้เข้าใจแบบถ่ายทอดสด,\n",
      "- ชุดข้อมูลหาจากคลิปสั้นๆของ Hololive ข้อดีคือมี timestamp ชัดเจน-ความยาวเหมาะแก่การเทรนโมเดล; ใช้คลิปจากช่องอื่นบางส่วนโดยการทำ OCR ด้วยมือ, \"\n",
      "- ทำความสะอาดช้อมูล เช่น ตัดการใช้อักษร/สัญลักษณ์เพื่ออธิบายสิ่งที่ตัวละครกำลังทำ-ส่วนใหญ่จะไม่มีเสียงพูด ( (^_^), (O.O), ฯลฯ ), สัญลักษณ์แสดงอารมณ์ ( :(, :D, ฯลฯ ), ลบไฟล์เสียงที่เปิดไม่ได้, เปลี่ยนตัวอักษรเป็น hiragana ทั้งหมดด้วย pykakasi\",\n",
      "- ใช้โมเดลพื้นฐาน ได้แก่ vumichien/wav2vec2-large-xlsr-japanese-hiragana (ปรับจูนบน Common Voice และ Japanese speech corpus of Saruwatari-lab) และ ttop324/wav2vec2-live-japanese (ปรับจูนบน Common Voice, JSUT, CSS10, TEDxJP-10K, JVS และ JSS),\n",
      "- การปรับจูนกับชุดข้อมูล VTuber ทำให้ได้ WER 0.1884\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมเคยเข้าร่วมคอร์สการจัดการข้อมูลโดยใช้ Excel เพื่อหาวิธีการที่มีประสิทธิภาพที่สุด , Data Science เบื้องต้น และการใช้ AI เพื่อสร้างเสียงเสมือน  อยากลองเรียนสายอื่นดูบ้างครับ เพราะตอนนี้เรียนอยู่เป็นเอก DE ที่จะเน้นการจัดการข้อมูลใน Database เป็นหลัก อยากลองทำอย่างอื่นบ้างอะครับ (และก็มาหา Portfolio ไปเผื่อเข้ามหาวิทยาลัยด้วยครับ)  อยากจะทำการประมวลผลภาษาให้ได้ Real-Time เพื่อจะได้ลดช่องว่างระหว่างภาษาและสามารถเข้าใจกันได้ง้ายขึ้น ปัจจุบันก็มีบ้างแล้วแต่ยังไม่แม่นและแพร่หลายขนาดนั้น\"\n",
      "---\n",
      "date: \"12-7-22\"\n",
      "title: \"Text-to-image synthesis with VQGAN-ThCLIP\"\n",
      "builder: \"ภูริช ศิริทิพย์ (มาร์ค)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/32/01.jpg\"\n",
      "links:\n",
      "    github: \"https://colab.research.google.com/github/vikimark/VQGAN-ThCLIP/blob/master/Streamlit_VQGANxThaiCLIP.ipynb\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/413224897512622\"\n",
      "    blog: \"https://medium.com/@phuritsiritip/%E0%B9%82%E0%B8%84%E0%B8%A3%E0%B8%87%E0%B8%81%E0%B8%B2%E0%B8%A3-ai-builders-%E0%B8%81%E0%B8%B1%E0%B8%9A-ai-%E0%B8%AA%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%87%E0%B8%A0%E0%B8%B2%E0%B8%9E%E0%B8%88%E0%B8%B2%E0%B8%81%E0%B8%82%E0%B9%89%E0%B8%AD%E0%B8%84%E0%B8%A7%E0%B8%B2%E0%B8%A1%E0%B8%AA%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%87%E0%B9%82%E0%B8%94%E0%B8%A2%E0%B9%80%E0%B8%94%E0%B9%87%E0%B8%81%E0%B8%A1%E0%B8%B1%E0%B8%98%E0%B8%A2%E0%B8%A1%E0%B8%9B%E0%B8%A5%E0%B8%B2%E0%B8%A2-%E0%B8%97%E0%B8%B5%E0%B9%88%E0%B9%80%E0%B8%81%E0%B8%B7%E0%B8%AD%E0%B8%9A%E0%B8%88%E0%B8%B0%E0%B8%82%E0%B8%B6%E0%B9%89%E0%B8%99%E0%B8%9B%E0%B8%B5-1-ed5878c7a72c\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/32/01.jpg)\n",
      "\n",
      "- โมเดลสร้างรูปภาพจากคำอธิบายภาษาไทยเพื่อสร้างภาพประกอบนิยาย เรื่องสั้น หรือบทความต่าง ๆ; เลือกใช้ VQGAN และ CLIP โดย VQGAN จะทำหน้าที่เป็นเสมือนผู้วาดรูปและ CLIP จะทำหน้าที่เป็นคนที่คอยกำกับรูปที่ VQGAN วาดว่าตรงกับข้อความที่เราวาดไปแค่ไหน,\n",
      "- CLIP เป็นโมเดลที่เป็นสะพานเชื่อมระหว่างรูปภาพกับข้อความโดยจะทำการ Embed ทั้งสองอย่างนี้ให้อยู่ใน latent space ขนาดเท่ากันจึงสามารถนำทั้ง Text embedding และ Image embedding มาเปรียบเทียบความเหมือนความต่างได้โดยใช้วิธีการทางคณิตศาตร์ต่าง ๆ CLIP จะประกอบไปด้วยโมเดลหลัก 2 ส่วนคือ Text encoder และ Image encoder,\n",
      "- VQGAN เป็นโมเดลประเภท Generative โดยจะประกอบไปด้วย Generator และ Discriminator โมเดลสองตัวนี้จะแข่งกันและพัฒนาตัวเองไปพร้อม ๆ กันจนในที่สุด Discriminator ไม่สามารถเอาชนะ Generator ได้ เราจึงจะนำ Generator ไปสร้างภาพต่อ นอกจากนี้ก่อนที่ทั้งสองโมเดลนี้จะแข่งกัน Generator จะได้เรียนรู้โครงสร้างของภาพที่ตัวเองจะสร้างไว้ก่อน เปรียบเสมือนมีสมุดเปล่าที่เอาไว้จดวิธีการสร้างสิ่งต่าง ๆ ลงไป,\n",
      "- เนื่องจากการจะสร้างรูปจาก VQGAN นั้นต้องมี Random input (กลุ่มตัวเลขแบบสุ่ม) ส่งเข้าไปให้ Generator จึงจะสร้างเป็นรูปต่าง ๆ ได้และแน่นอนว่าเราไม่สามารถรู้ได้ว่าการสุ่มแบบไหนจะให้รูปที่เราต้องการได้ จึงต้องใช้ CLIP คอยกำกับและค่อย ๆ เปลี่ยน Random input เหล่านี้ให้เป็นรูปที่เราต้องการ,\n",
      "- วิธี #1: เริ่มจากการเทรน CLIP ขึ้นมาเองใช้ข้อมูลเริ่มจาก flicker8k (8,000 รูป) ไปจนถึง flicker30k (30,000 รูป) แปลข้อมูล caption จากภาษาอังกฤษไปไทยด้วย PyThaiNLP; ใช้ resnet-50 เป็น image encoder และ WangchanBERTa เป็น text encoder (ThCLIP),\n",
      "- วิธีแรกยังไม่ได้ผลเป็นที่น่าพึงพอใจด้วยปัจจัยขนาดชุดข้อมูลและเวลาในการเทรน จึงทดลองวิธี knowledge distillation สำหรับ CLIP แทน,\n",
      "- วิธี #2: เทรนใหม่โดยการสอนให้ ThCLIP สร้าง text embeddings ให้คล้ายกับ OpenAI CLIP มากที่สุดตาม mean-squared error loss; ใช้ปริมาณข้อมูลน้อยกว่าและได้ผลดีกว่ามาก,\n",
      "- เทรนตามวิธี #2 ด้วยข้อมูล 2 ล้านรูป สุ่มจาก GCC, MSCOCO เหมือนของ SwedishCLIP,\n",
      "- จากการ \"ทดลอง ทดลอง ทดลอง\" พบว่า transform ภาพโดยสุ่มเพิ่มระดับ sharpness ให้กับภาพทำให้กราฟ Loss converge เร็วขึ้น, iteration ที่เหมาะที่สุดอยู่ระหว่าง 200–300 รอบ, รวมถึง:,\n",
      "- ใช้ negative prompt เพื่อพัฒนาคุณภาพรูปภาพได้ เช่น เมื่อสร้างภาพ \"เครื่องบิน\" ให้ \"ภาพเบลอ\" เป็น negative prompt (ใส่เข้าไปใน loss function) จะทำให้ได้ภาพเครื่องบินที่ชัดขึ้น,\n",
      "- ใช้ aesthetic-predictor จาก pretrained model ที่ประเมิน \"ความสวย\" ของรูป และให้ความสวยเป็นส่วนหนึ่งของ loss function; ทำให้รูปที่ออกมาสวยขึ้น,\n",
      "- ทดสอบประสิทธิภาพโมเดลด้วยแบบสอบถามจาก 27 คน พบว่า VGQAN-ThCLIP (โมเดลของเรา) ทำได้ดีกว่า VQGAN-CLIP (pretrained จาก OpenAI) เมื่อรูปภาพถูกสร้างจากข้อความสั้นทั้งด้านความสอดคล้องและความหลากหลาย แต่ยิ่งข้อความยาวทำได้ดีกว่าในด้านความสอดคล้องแต่ด้อยกว่าในด้านความหลากหลาย,\n",
      "- โมเดลสามารถทำ prompting ได้เหมือน text-to-image ชั้นนำทั่วไป เช่น \"คฤหาสน์\", \"คฤหาสน์ แฟนตาซี\", \"คฤหาสน์ แฮรี่พอตเตอร์\" ฯลฯ\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผู้เขียนมีความสนใจทางด้าน machine learning เป็นอย่างมากและยังมีความมุ่งมั่นที่จะทำให้สำเร็จ ปัจจุบัน machine learning & AI มีบทบาทกับเราแทบทุกด้าน แต่การจะทำให้ AI ใช้งานได้ในแต่ละด้านนั้นแตกต่างกันอย่างสิ้นเชิง ผู้เขียนจึงอยากเก็บเกี่ยวประสบการณ์ตั้งแต่การสร้างไปจนถึงการนำไปใช้ของ Machine learning & AI ในแต่ละด้านเพื่อขยายขอบเขตไอเดียของตัวเองและเมื่อไอเดียที่เข้าท่ามาถึง ผู้เขียนก็สามารถลงมือทำได้เลย โดยรู้ว่าด้านที่จะทำนั้นต้องใช้ model ประมาณนี้ รู้แหล่งชุดข้อมูลและรู้คีย์เวิร์ดที่จะศึกษาเพิ่มเติม นอกจากนั้นการเข้าโครงการนี้จะทำให้เราได้เจอกับเมนเทอร์และเพื่อนร่วมโครงการที่มีความชอบ เหมือนๆ กัน เมื่อเค้ามีความถนัดในด้าน machine learing ที่เราจะทำเราก็สามารถขอคำแนะนำจากเค้าได้และในทางกลับกันเราก็สามารถให้คำแนะนำในด้านที่เราถนัดแก่เพื่อนร่วมโครงการได้เช่นกัน เป้าหมายของผู้เขียนคือการสร้างนวัตกรรมหรือสิ่งประดิษฐ์ที่ทุกคนสามารถใช้ได้อย่างแพร่หลายและเกิดประโยชน์จากการใช้งานนั้น ซึ่งปัจจุบันผู้เขียนอยากศึกษาเพิ่มเติมทางด้าน Machine learning & AI อยากลองศึกษาศาสตร์แขนงใหม่ๆของ machine learing อาทิเข่น NLP, time series, GAN และอยากศึกษาวิธีการนำไปปรับใช้กับปัญหาในชีวิตจริง  อยากทำการสร้างรูปสังเคราะห์จากข้อความภาษาไทย (text to image genarator) เพื่อจำลองการออกแบบผลิตภัณฑ์เบื้องต้นจากไอเดียแล้วนำไปประเมิณว่าสามารถนำไปต่อยอดได้มากเพียงใดหรือเพื่อค้นพบไอเดียใหม่จากรูปที่สังเคราะห์ขึ้นมา เช่น อยากออกแบบดีไซน์เก้าอี้จึงพิมพ์ไปว่าเก้าอี้ทรงทุเรียน ตัวโมเดลอาจจะให้ผลลัพธ์เป็นเก้าอี้ที่มีหนามทุเรียนเป็นขาหรือเก้าอี้ที่ใช้หนามมนเป็นที่นั่ง และอื่นๆที่ผู้เขียนคาดไม่ถึง ชุดข้อมูลรูป ใช้จาก COCO โดยส่วนมากจะเป็นรูปสิ่งของต่างๆ, ชุดข้อมูลคำ ใช้คำที่ผ่านการ embedded มาแล้วโดยใช้ thai2vec ด้วย PyThaiNLP, นอกจากนี้ถ้าเปลี่ยนชุดข้อมูลใหม่โดยใช้รูปหน้าคนแล้วเทรนให้โมเดลสร้างหน้าคนจากคำบอกเล่าของพยานก็จะสามารถสร้างรูปคนร้ายเพื่อใช้ในการตามหาตัวหรือทำรูปติดประกาศจับ การทำแบบนี้จะสามารถลดระยะเวลาการสเก็ตช์ภาพขั้นต้นและสามารถโฟกัสกับการปรับแต่งขั้นสุดท้ายให้ภาพตรงกับคนร้ายที่พยานเห็นมากที่สุด ก็เป็นอีกโครงงานหนึ่งที่น่าทำเช่นกัน\"\n",
      "---\n",
      "date: \"13-7-22\"\n",
      "title: \"Game Recommendation by using Neural Network Embeddings\"\n",
      "builder: \"มาวิน ศรีชาติ (วิน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/33/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/kyou7797/Game-Recommendation\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/413880357447076\"\n",
      "    blog: \"https://medium.com/@meow7747/%E0%B9%80%E0%B8%A1%E0%B8%B7%E0%B9%88%E0%B8%AD%E0%B9%80%E0%B8%81%E0%B8%A1%E0%B8%A1%E0%B8%B5%E0%B8%A1%E0%B8%B2%E0%B8%81%E0%B8%A1%E0%B8%B2%E0%B8%A2-%E0%B9%81%E0%B8%95%E0%B9%88%E0%B9%80%E0%B8%A3%E0%B8%B2%E0%B9%84%E0%B8%A1%E0%B9%88%E0%B8%A1%E0%B8%B5%E0%B9%80%E0%B8%A7%E0%B8%A5%E0%B8%B2%E0%B9%80%E0%B8%A5%E0%B9%88%E0%B8%99%E0%B9%80%E0%B8%81%E0%B8%A1-t-t-game-recommendation-a1598c50553f\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/33/01.jpg)\n",
      "\n",
      "- โมเดลแนะนำเกมด้วย neural collaborative filtering,\n",
      "- ใช้ชุดข้อมูลเกมใน Steam จาก 70,912 ผู้ใช้และ 10,947 เกมส์; ข้อมูลที่บ่งบอกความชอบคือเวลาที่ใช้ในการเล่น,\n",
      "- ทำการ normalize เวลาเล่นด้วย min-max scaling เนื่องจากบางเกมมีคอนเท้นท์ให้เล่นน้อย-เยอะ จึงใช้เวลาน้อย-เยอะกว่าเกมอื่นๆ,\n",
      "- ทำโมเดลด้วยเกมส์ที่มีคนเล่นอย่างน้อย 15 คนและผู้เล่นที่เล่นมาแล้วอย่างน้อย 10 เกมส์,\n",
      "- ปัญหาที่ผมเมื่อประเมินผลคือชุดข้อมูลไม่มี timestamp ทำให้ไม่สามารถประเมินด้วยการทำนายเกมส์สุดท้ายที่เล่นของแต่ละผู้ใช้เหมือน recommendation ทั่วไปได้; เลือกใช้วิธีสุ่มเกมส์มาหนึ่งเกมส์จากผู้ใช้ทุกคน แล้วทาย top-k accuracy (แนะนำ k เกมสำหรับผู้เล่นแต่ละคนใน validation set แล้วดูว่าเกมส์ที่สุ่มมาอยู่ใน k เกมส์นั้นหรือไม่),\n",
      "- โมเดลทำได้ดีกว่า rule-based baseline ที่ทายว่าทุกคนจะเล่นเกมค่าเฉลี่ยเวลาเล่น-เวลาเล่นรวมมากที่สุด k ลำดับ แต่แพ้ให้กับการทายว่าทุกคนจะเล่นเกมที่มีคนเล่นมากที่สุด k ลำดับ; จะเห็นได้ว่าอุตสากรรมเกมส์ค่อนข้างเป็น winners take all มีเพียงไม่กี่เกมเท่านั้นที่ผู้เล่นแทบทุกคนจะเล่น,\n",
      "- ทำ error analysis ด้วยการลองสมมุติว่าเกม top 1-10, 11-20, 21-30, ... ไม่มีอยู่จริง พบว่าโมเดลทำได้ใกล้เคียง rule-based baseline เกมที่คนเล่นมากที่สุดขึ้นเรื่อยๆ; คาดว่าโมเดลน่าจะมีประโยชน์ในการแนะนำเกมที่ไม่ค่อยเป็นที่นิยมมากนัก\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมได้เข้าค่าย สอวน. ค่าย 1 และ 2 วิชาคอมพิวเตอร์ ที่มหาวิทยาลัยนเรศวร ทำให้ผมได้รู้จักกระบวนการคิดต่างๆ ตั้งแต่ เบสิกของการเขียนโปรแกรม ตั้งแต่ การปริ้น, อินพุต, if-else, loop ไปจนถึงการสร้าง Function, Data Structure และ การทำงานของ Algorithm ต่างๆ นี่เป็นจุดเริ่มต้นที่ทำให้ผมสนใจ ในการเขียนโค้ดตั้งแต่นั้นมา  ผมมีประสบการณ์ การทำ data analytic จากโครงงานเรื่อง การวิเคราะห์อารมณ์ของคอมเมนต์เกี่ยวกับสมาร์ทวอทช์ผมได้ท ากระบวนการของ data science ตั้งแต่การเก็บข้อมูล, การหาแหล่งข้อมูลจากที่ต่างๆ การทำ data cleansing เพื่อเช็คว่า คอมเมนต์นั้นใช้ได้ไหม เช่น การตัดข้อความที่เป็นอิโมจิออก, การวิเคราะห์ข้อมูล และการทำให้ข้อมูลสามารถเข้าใจได้ง่าย จากการทำ data visualization  ผมอยากทำความเข้าใจเกี่ยวกับ ปัญญาประดิษฐ์ มากยิ่งขึ้น รวมถึงกระบวนการทาง data science ตั้งแต่การเก็บข้อมูล, การทำ data cleansing วิเคราะห์ข้อมูล จนไปถึง การทำ data visualization เพื่อที่จะ สามารถทำการวิเคราะห์ข้อมูลได้อย่างมีประสิทธิภาพ ผมอยากเห็นแรงบันดาลใจ จากกลุ่มคนที่สนใจ ในเรื่องเดียวกับผม มาพยายามทำความเข้าใจศึกษา และพัฒนาความรู้ เพื่อที่จะสามารถนำไปพัฒนาต่อยอดในอนาคต เพื่อสรรสร้างปัญญาประดิษฐ์เป็นฉบับของตนเอง\"\n",
      "---\n",
      "date: \"14-7-22\"\n",
      "title: \"Chaos EDM: Generating EDM Song with VAE (Variational Autoencoder) Spectrogram\"\n",
      "builder: \"ณยศ สุวัฒโน (ไมค์กี้)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/34/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Mikey8943/EDM-spectrogram-vae\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/414621047373007\"\n",
      "    blog: \"https://medium.com/@nayos.su/generating-edm-song-with-vae-variational-autoencoder-spectrogram-eb6dcd5fc4b8\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/34/01.jpg)\n",
      "\n",
      "- โมเดลแต่งเพลง EDM ด้วย Variational Autoencoder (VAE),\n",
      "- แรงบันดาลใจการความชื่นชอบเพลง EDM และโครงการที่ใช้ deep learning เข้ามาช่วยแต่งเพลงอย่าง Magenta Tensorflow,\n",
      "- สร้างชุดข้อมูลจาก EDM ประเภท (genre) Hardcore (ดูประเภทของ EDM ทั้งหมดที่ https://music.ishkur.com/) เนื่องจากได้รับความนิยมสูง โดยใช้คลิปจาก YouTube,\n",
      "- เลือกเพลงที่มีเสียงคนร้องเพลงไม่เกินร้อยละ 60 ของความยาวเพลง, หากมี voice sample แต่ยังมีช่วงที่มี beat หรือ melody เล่นอยู่ด้วยก็พอปล่อยผ่านได้, ทั้งเพลงควรมีความคงที่ของ BPM(Beat per minute) และ Time Signature หรือไม่ได้มีการเปลี่ยนแปลงที่ไม่บ่อยจนเกินไป; ได้เพลงที่ผ่านการทำความสะอาด 1,090 เพลงรวมเวลา 71.8 ชั่วโมง,\n",
      "- ใช้สถาปัตยกรรม Variational Autoencoder (VAE) เพื่อเรียนรู้การสร้าง spectogram ของเพลง EDM,\n",
      "- ประเมินคุณภาพด้วย mean opinion score (MOS) จากแบบสอบถาม คน ด้านความชัดเจนของ beat โดยรวม (2.67/5), ความชัดเจนของ melody โดยรวม (2.69/5) และความพึงพอใจโดยรวม (2.77/5),\n",
      "- มองแนวทางพัฒนาด้วยการเทรนให้นานขึ้น-ข้อมูลมากขึ้น, ใช้ช่วง climax ที่เมโลดี้ชัดเจนเทรน และลองสถาปัตยกรรมใหม่ๆ,\n",
      "- อัลบั้ม The Final of Chaos? (น่าจะ) เป็นอัลบั้ม EDM ที่สร้างโดยปัญญาประดิษฐ์แรกของไทย ลองฟังกันได้ที่: https://soundcloud.app.goo.gl/17SThr5PisKCFaZC6\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"กระผมเคยได้มีโอกาสในการร่วมเข้าการแข่งขันในงาน TMLCC เมื่อปี 2021 โดยที่ผมได้ช่วยเหลือในการนำ dataset มา clean และ select data ที่น่าสนใจนำไปใช้ใน algorithm มีแรงบันดาลใจที่จะเขียนโค้ดจากเพื่อนของผมที่แสดงให้เห็นถึงความสำคัญและศักยภาพของ AI ทำให้ผมได้ศึกษาและเรียนรู้การเขียนโค้ดมาเรื่อยๆในระยะเวลา 1 ปีที่ผ่านมานี้แต่ยังไม่ได้เริ่มเขียนโปรเจคแบบจริงๆจังๆสักครั้งเลยอยากจะลองทำดูในโครงการนี้ครับ  เหตุผลที่ผมอยากเข้าร่วมโครงการนี้เริ่มต้นมาจากการได้เห็นเพื่อนของผมคนหนึ่งที่ได้มีความสนใจในด้าน AI ได้ชวนผมมาทำโครงงานแข่งด้าน AI แล้วและยังเคยเข้าร่วมโครงการนี้ได้มาชวนผมให้มาลองศึกษาและเข้าใจการทำงานและการสร้าง AI อีกทั้งผมยังเคยได้เข้าค่ายแพทย์ของมหาลัยวิทยาลัยธรรมศาสตร์ โดยในค่ายนั้นได้มีการบรรยายเกี่ยวกับ Digital Hospital ในหัวข้อของ AI ทำให้ผมมีความสนใจในด้านนี้อยู่แล้วได้ตัดสินใจที่จะเข้าร่วมโครงการนี้ ทั้งนี้ผมเลยเห็นโครงการนี้เป็นโอกาสอันดีที่ควรจะคว้าไว้เพื่อต่อยอดในการศึกษาและการงานของผมในอาชีพแพทย์ได้ครับ  เพลงในโลกนี้มีมากกว่าที่จะนับได้ทั้งหมด ทั้งเป็นเพลงที่เป็นที่รู้จักกันอย่างดีหรือมีคนรู้จักเพียงหยิบมือ แต่ทั้งนี้เพลงก็จะถูกแบ่งประเภทด้วยสิ่งที่เรียกว่า Genre หากแต่เป็นเพียงสมัยก่อนยุคเพลง Digital การใช้หูฟังเพื่อแบ่งแยกนั้นอาจไม่ต้องการประสบการณ์ในการฟังเพลงที่มากนัก แต่กระนั้นเองยุคสมัยในการผสมผสานการทำเพลงแบบดิจิตอลก็เข้ามาถึงทำให้เกิดเพลงประเภทหนึ่งขึ้นมานั้นคือ Electronic Music แต่ส่วนมากเราจะได้ยินกันทั่วไปคือ EDM หรือ Electronic Dance Music อย่างไรก็ตาม electronic music นั้นเป็นเพลงที่เกิดขึ้นจากเสียงสังเคราะห์ทำให้เกิดความหลากหลายที่มากกว่าเดิมจากเพลงที่เกิดจากเครื่องดนตรีตามปกติทำให้เกิด genre และ subgenre ขึ้นมากมายและมีจำนวนเพิ่มขึ้นอย่างไม่หยุดอันเป็นเหตุทำให้ทำให้หลายบุคคลเกิดความสับสนและโต้แย้งกันถึง genre ของเพลงบางเพลงจนถึงวันนี้ ตัวอย่าง genre สามารถหาดูได้ทางนี้ https://www.reddit.com/r/electronicmusic/comments/dbxf5x/extremely_genre_specific_relectronicmusic/ ผมจึงมีความคิดที่จะทำ AI ที่สามารถรับไฟล์เพลง หรือถ้าเป็นไปได้ก็รับค่า input จากเพลงที่เล่นอยู่และบอก Genre ใหญ่ๆให้คนทั่วไปเข้าถึง Genre ของ EDM ได้มากขึ้น ส่วนชุดข้อมูลนั้นเราสามารถหาโหลดได้จาก Youtube, Spotify, Soundcloud, Mixcloud เป็นต้น\"\n",
      "---\n",
      "date: \"15-7-22\"\n",
      "title: \"WanchanBERTa Thai Grammarly\"\n",
      "builder: \"อิทธิพัฒน์ ปานขำ (มาร์จิ้น)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/35/01.jpg\"\n",
      "links:\n",
      "    github: \"https://colab.research.google.com/github/bookpanda/WanchanBERTa-Thai-Grammarly/blob/main/demo.ipynb\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/415235220644923\"\n",
      "    blog: \"https://medium.com/@marginpankam/wanchanberta-thai-grammarly-5010671797c7\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/35/01.jpg)\n",
      "\n",
      "- โมเดลแก้การสะกดคำภาษาไทยด้วยเทคนิค tagging and masking โดยอาศัย WangchanBERTa เป็นโมเดลพื้นฐาน,\n",
      "- ปรับจูบนชุดข้อมูล VISTEC-TP-TH-2021 (https://github.com/mrpeerat/OSKut/blob/main/VISTEC-TP-TH-2021) ประกอบด้วยการสะกดคำผิด เช่น ตัวอักษรซ้ำ; มากกกกกก (มาก), รักๆๆๆๆ (รัก ๆ), ไม้ยมกโดยไม่เว้นช่องว่า; ขอบคุณๆ (ขอบคุณ ๆ), คำย่อโดยไม่มีจุด; มิย (มิ.ย.), วรรณยุกต์หาย; แป๊ป (แปป), พิมพ์ตก; อุหนุน (อุดหนุน), จงใจพิมพ์ผิด; นะ (น้า), ณ๊อง (น้อง), พิมพ์ไม่ครบ; อลัง (อลังการ), แบต (แบตเตอรี) เป็นต้น รวม 42,893 ประโยคที่มีการสะกดผิด,\n",
      "- ทำความสะอาดข้อมูลโดย เปลี่ยนรูปแบบประโยคจาก \"สวัสดี|<msp value=”ครับ”>ค้าบ</msp>|พี่|<ne>จอม</ne>\" เป็น \"สวัสดี^ครับ$พี่จอม\", เพิ่ม token สำหรับคำที่สะกดถูกเพื่อให้สามารถเติมคำได้ใน token เดียว, หาก token ที่สะกดผิดมีมากกว่าที่สะกดถูก ให้เติม _ ไปให้ครบเท่ากัน,\n",
      "- ทดลองใช้ hunspell, seq2seq และ tagging and masking,\n",
      "- tagging and masking ทำได้ดีที่สุด; โมเดลทำงานด้วยการชี้เป้า token ที่สะกดผิด (tagging; token classification) แล้วแทนที่ด้วย mask token จากนั้นให้โมเดลเดาว่า mask นั้นควรจะเป็นอะไร (masking),\n",
      "- ได้ accuracy 28.1% / F1 score 0.256 เทียบกับ hunspell และ seq2seq ที่แทบทายไม่ถูกเลย; ถ้าดูจาก BLEU รายประโยค จาก 1,000 ประโยคใน test set โมเดล tagging and masking แก้ถูก 386 ประโยค\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมมีความพร้อมและความปรารถนาในการเรียนรู้และประยุกต์ AI ผมมีพื้นฐานการเขียนโปรแกรม และผมยังมีความเข้าใจใน computer science ระดับหนึ่งจากโครงการคอมพิวเตอร์โอลิมปิกวิชาการ ในระดับค่ายสสวท. 1 นอกจากนี้ผมเคยเข้าโครงการ FIBO-School Consortium รุ่นที่ 5 ในสาขา deep learning ที่ผมได้เรียนรู้ intuition ของ neural network, CNN, fine-tuning และผมมีประสบการณ์ใน web development โดยผมมีโครงงานคอมพิวเตอร์ที่ใช้ Google Geolocation API ในการกำหนดพื้นที่แชร์ไฟล์ ส่วนตอนนี้ผมกำลังสร้างโปรเจคโดยใช้ MERN stack (MongoDB, Express, React, Node)  เมื่อก่อนนั้น AI เป็นสิ่งที่ค่อนข้างจะไกลตัว ไม่ว่าจะเป็นในด้านการใช้ประโยชน์หรือการหา resource เรียน แต่ในตอนนี้ AI กลายเป็นสิ่งที่มันเริ่มคืบคลานเข้ามาในชีวิตเรามากขึ้นและทุกคนก็สามารถเริ่มได้ แต่ด้วยประสบการณ์ของผมที่เคยเรียนสาย web development ผมบอกได้เลยว่า resource ของการเรียนเช่น MERN stack มันหาง่ายและ intuition ง่ายกว่าการเรียน AI ด้วยตัวเอง ผมเลยอยากจะใช้โอกาสนี้เพื่อศึกษา ทำความเข้าใจ และนำ AI มาปฏิบัติจริงในโครงการ AI Builder 2022 ที่มี mentor ผู้สามารถทำให้ผมกระจ่างในข้อสงสัยต่าง ๆ และเพื่อน ๆ ในโครงการที่จะคอยเรียนและผลักดันไปด้วยกัน ตอนนี้ผมพร้อมแล้วที่จะเข้าสู่ discipline แขนงนี้ไม่เหมือนเมื่อก่อนที่ผมยังขาด intuition บางส่วน เช่นการเขียนโปรแกรมเบื้องต้น หรือคณิตศาสตร์บางบท นอกจากนี้แล้วผมยังอยากจะมาสร้าง connection กับคนในโครงการนี้ไม่ว่าจะเป็น mentor หรือผู้สมัครโครงการ เพราะผมเชื่อว่าเป็นการเก็บจุดที่จะได้ใช้ในอนาคตแน่นอน เช่นผมอาจจะมีการทำงานร่วมกับคนในโครงการนี้ในอนาคต และผมรู้สึกว่า community ที่เกี่ยวกับคอมพิวเตอร์ในไทยนั้นมีความเกี่ยวพันกันมาก ผมก็พอจะสังเกตเห็นหลายคนที่มีส่วนร่วมในโอลิมปิกวิชาการมาทำ AI ฉะนั้นการทำความรู้จักคนมากก็ไม่ใช่สิ่งที่เสียหาย และยังอาจจะเปิดโอกาสให้ผมได้เรียนรู้จากคนอื่น ๆ อีกมากมาย\"\n",
      "---\n",
      "date: \"16-7-22\"\n",
      "title: \"Garbage Detection with Tensorflow Lite\"\n",
      "builder: \"กันต์พัจน์ วิเศษสุข (กัน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/36/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/24GUNV/aibuilders/tree/main/object_detection/images\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/415865783915200\"\n",
      "    blog: \"https://medium.com/@24progun/object-detection-using-tensorflow-lite-80da8d75c03b\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/36/01.jpg)\n",
      "\n",
      "- โมเดลคัดแยกประเภทขยะจากรูปภาพแบบ real-time ด้วย Tensorflow Lite; แยกลัง, แก้ว, โลหะ, กระดาษ และพลาสติก,\n",
      "- เลือกใช้ Tensorflow Lite เนื่องจากต้องการ deploy ลง OrangePi; ต้องการความแม่นยำประมาณ 70-80% เพื่อให้ใช้งานได้จริง,\n",
      "- ใช้ข้อมูลจาก asdasdasasdas/garbage-classification, mostafaabla/garbage-classification แล้วนำมา annotate เองเพื่อทำ object detection ได้เป็น training set (1,554 รูป), validation set (170 รูป) และ test set (170 รูป),\n",
      "- ชุดข้อมูลที่ annotate เองเปิดให้ใช้เป็นสาธารณะที่ https://github.com/24GUNV/aibuilders/tree/main/object_detection/images ; แบ่งเป็นลัง (325 รูป), แก้ว (406 รูป), โลหะ (433 รูป), กระดาษ (199 รูป) และพลาสติก (191 รูป),\n",
      "- เลือกใช้สถาปัตยกรรม EfficientDet-Lite0 เพื่อ latency ที่ดีที่สุด; ได้ AP 76.6% บน test set,\n",
      "- สามารถทดลองใช้แบบ real-time ได้บน streamlit cloud; ใช้ OpenRelay เพื่อเชื่อม streamlit กับ webcam ของผู้ใช้\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"I wish to join the organization AI Builders because of my interest within the AI field. I had first been introduced to this field from a background of playing video games. I played these video games and gained an interest in what ran in the background of video games. I wanted to know how these games worked and soon began pursuing a way in which to learn how to code. I started of attempting to learn how to code in a language called LUA. It wasn\\t easy nor very successful but it opened my eyes to what was possible with the lines of code that you could write. Wanting to know more about this, I soon ventured into a course known as CS50 (https://cs50.harvard.edu/x/2021/). I learned the basics about coding such as python, c, sql, html, etc. during this course. Wanting to know more, I continued learning after finishing this course. As someone recommended to me that there was a CS50Ai course (https://cs50.harvard.edu/ai/2020/) after that I continued to expand my knowledge and finished the course. At the same time I took \"Take The World Forward Fellowship\" (https://learnwithleaders.com/taketheworldforwardfellowship/) in order to attempt to apply my knowledge to make something that could be applicable in the real world. Now I believe that the next step for me is to join \"AI Builders\" in order for my next step to apply my knowledge into something in the real world.  I wish to be a part of AI Builders because I have an interest in the AI field. I believe that AI, in the future, will be a major part of our lives. I think that by joining with this organization, I build upon and learn new concepts and lessons and apply them to the projects that I can make in the real world. I think that this organization is greater than doing it individually since we can ask the mentors from the organizations and our peers for advice on for our specific project. These mentors have experience in doing this type of stuff so it would be greatly beneficial to have them guide us through this experience. Another benefit of this organization is that they have prepared us lessons which can also guide us when creating this project. We can learn new concepts in which we can immediately use them in the real world by incorporating them into the projects that we are making.  During my time at the \"AI builders\" program, I plan to construct garbage classification machine. It should be able to the differentiate the different types of materials. An image from a camera set up inside the machine take a picture of the garbage that the user puts in. Then, based on the image, an AI will classify the type of garbage that it is. It can classify the items by the material of the item. Lastly, there will be a mechanism in the machine that can push the garbage into its specific garbage chute. This machine will help group the same types of material together, hopefully making recycling easier since the garbage is classified into different materials.\"\n",
      "---\n",
      "date: \"17-7-22\"\n",
      "title: \"Sick Pig Classifier\"\n",
      "builder: \"ภวัต ลีชาแสน (บีม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/37/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Igonazio/Sick-Pig-Classifier\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/416533550515090\"\n",
      "    blog: \"https://medium.com/@beamsisb/sick-pig-classifier-394db89c3c5d\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/37/01.jpg)\n",
      "\n",
      "- โมเดลแยกแยะรูปหมูป่วยด้วย ResNet-18; แรงบันดาลใจจากข่าวโรคอหิวาต์แอฟริกาในสุกร (African swine fever : ASF) ระบาดช่วงต้นปี 2022,\n",
      "- ต้องการโมเดลที่ขนาดเล็กสามารถใช้งานได้ง่าย และมีความแม่นยำเพียงพอในการทุ่นแรงมนุษย์ โดยอาจไม่แม่นยำเท่ามนุษย์เนื่องจากการวินิฉัยโรคใช้มากกว่าการมองเห็น,\n",
      "- สร้างชุดข้อมูลจากการ scrape รูปจากอินเตอร์เน็ต; พบปัญหารูปหมูป่วยหาได้ยาก และรูปหมูไม่ป่วยบางครั้งมีรูปที่ไม่เกี่ยวข้อง เช่น การ์ตูน Peppa Pig ติดมาด้วย; ได้รูปหมูป่วยทั้งหมด 141 รูป หมูไม่ป่วย 370 รูป,\n",
      "- ResNet-18 ได้ผลดีที่สุดบน test set จำนวน 154 รูป ได้ micro-averaged F1 ที่ 0.84; เทียบกับ baseline การทายว่าทุกตัวไม่ป่วยที่ 0.82 (แน่นอนว่าในกรณีนี้ recall ของหมูป่วยเป็น 0) และ CNN ที่ 0.63,\n",
      "- โมเดลที่ดีที่สุดมี recall (จำนวนหมูป่วยที่ทายถูก / จำนวนหมูป่วยทั้งหมด) สูงถึง 0.88 ซึ่งน่าจะเพียงพอสำหรับการช่วยคนเฝ้าระวังในฟาร์ม,\n",
      "- จำเป็นต้องทดลองกับภาพจริงในฟาร์ม เพื่อพัฒนาสู่ระบบใช้งานจริง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"I am a highly-motivated person who strives to make a difference in Thai society. I have a habit of observing the problems that various groups of people around me have been facing and thinking about the solutions to their problems. For instance, as flooding becomes a frequent natural disaster that affects people in Lopburi, my friends and I have helped plant trees at Pasak Chonlasit Dam to alleviate the problem for the past few years. More recently, I was selected to participate in the Young Changemakers Program organized by the School of Changemakers organization. There, I teamed up with my peers to raise awareness about cybercrimes in Thailand. Also, I realized that I’m passionate about applying technologies, including AI, to address social issues. Though I still lack the advanced math and computing background that I believe is a prerequisite for being a great AI developer, I have the willingness to learn and the motivation to excel in whatever I do, as well as my love of helping others.  \"With my limited experience in the field of AI, I had a major preconception of what an AI was. I always thought that anything related to AI was daunting and complex. To me, it wasn’t something that a high-schooler would be able to comprehend. However, when I got a chance to work with a professor at KMITL on an image processing project to closely observe a cricket population, my perception of AI has been shifted. In the beginning, I didnt know anything about image processing, so I started studying computer programming and image processing algorithms. Looking back, I was elated that I took on this research journey. I was fortunate that I had a KMITL student and my professor to help me navigate the enormous world of AI. It has been challenging, but rewarding, and I started to believe that I, as a high-schooler, can appreciate the versatility of AI as well. Also, I realized that there is so much more to see in this particular field. So, I decided to apply to this AI Builders program, with a strong determination to learn as much as I can about AI and explore the many ways to use its capability to build something to impact our society. With the guidance from AI experts in this program, I believe I will get to where I set to achieve.\",  My inspiration for this project derives from my ongoing work on cricket population surveys using image processing to help farmers keep track of their cricket farms. It led me to wonder about how to assist other farmers in taking care of their livestock. Population counting is just one of the measures of animal well-being, sanitation, and farm productivity. For other animals, there are other measures. For example, recently, there has been a national-level incident involving African Swine Fever, causing deaths in pigs throughout the country and the prices of pork to skyrocket. With early intervention using AI, it may be possible for farms to prevent such catastrophes from happening again. Data for this project can come from live video footage from cameras installed on the farm and sensors that attach to animals to detect anomalies, as well as “cleanliness” sensors at all the gates to assess the farm sanitation.\"\n",
      "---\n",
      "date: \"18-7-22\"\n",
      "title: \"NLP for genre predictions on FFnet: an antithesis to utilitarianism\"\n",
      "builder: \"zeiosis@\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/38/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/zeiosis/ffnet-summary-prediction\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/417209980447447\"\n",
      "    blog: \"https://medium.com/@cryingptosis/nlp-for-genre-predictions-on-ffnet-an-antithesis-to-utilitarianism-4380524ca1fc\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/38/01.jpg)\n",
      "\n",
      "- โมเดลจำแนก genre ของ fan fiction จากบทคัดย่อด้วย BERT; แรงบันดาลใจคืออยากสร้างระบบแท้กอัตโนมัติให้ AO3 (ao3.org) เพราะแท้กปัจจุบันสร้างโดยผู้ใช้และคุณภาพไม่ค่อยดี,\n",
      "- เลือก scrape ข้อมูลจาก FFNet (fanfiction.net) เพื่อเป็นชุดข้อมูล เนื่องจากแท้กใน FFNet นั้นคุณภาพเสมอต้นเสมอปลายกว่าและอนุญาตให้ใส่เพียง 2 แท้กต่อเรื่อง,\n",
      "- เนื่องจากหนึ่ง fan fiction โดยทั่วไปแล้วมีมากกว่าหนึ่งแท้กจึงเลือกทำการวัดผลด้วย accuracy metric ที่ิคิดขึ้นเองคือ (% เรื่องที่มี 2 แท้กและทายถูกทั้ง 2 แท้ก) + 1/2 * (% เรื่องที่มี 1 แท้กและทายถูก) + 1/2 * (% เรื่องที่มี 2 แท้กแต่ทายถูกแค่ 1 แท้ก),\n",
      "- เขียนสคริปท์สำหรับ scrape FFNet ขึ้นมาเองเนื่องจากไม่มี API อย่างเป็นทางการโดยเลือกเฉพาะเรื่องที่เป็นภาษาอังกฤษ, K->T-rated, เรื่องที่จบแล้ว และมาจากต้นฉบับที่มีงาน fan fiction อย่างน้อย 50k เรื่อง,\n",
      "- พบว่ามีเพียง 8 genre หลักที่มีคนใช้เป็นแท้กคือ Romance, Humor, Drama, Hurt_Comfort, Adventure, Family, Angst, Friendship; แท้กมีความไม่สมดุลโดยเฉพาะ Romance ที่มีเยอะกว่าแท้กอื่นมาก,\n",
      "- เทรนโมเดลเปรียบเทียบกับ pretrained หลาย iteration เช่น bart-large-mnli, distilbert-base-uncased-mnli และ distilbart-mnli-12-1; โมเดลที่ดีที่สุดได้ค่า accuracy ตามวิธีคิดด้านบนที่ 0.437 เทียบกับ baseline ที่ 0.269\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"Although I do not have much in the way of experience in actual coding or machine learning (my projects mostly being minuscule in scope and being limited to some facet of regex or language learning with Python serving as the consistent backdrop), I believe I do have a general background in the mathematical (though not so much the statistical) foundations of the course; I am comfortable with most of the basic knowledge required to do derivative and integral calculus, having learned and relearned them previously many times; however, I unfortunately do not believe I have covered the necessary background required for vector calculus, by extension from the requirement given for understanding of partial derivatives. I have in the past attempted to teach myself linear algebra as well, although I have retained little from that. I do believe, however, that my ability to focus and diligently persevere, while keeping an eye out for more efficient methods, as alluded to in the examples in regards to my mathematical education, will be a boon, should I be able to take part in the project.  I also, of course, believe in the spirit of open-source; the ability to open doors for those less fortunate than oneself should be a motivating factor for anyone, especially in a country so rife with inequality as ours. Ultimately, I wish to assist in addition to myself the general public, in order to better the opportunities afforded to anyone and everyone, regardless of social standing, geographical isolation, or otherwise.\"\n",
      "---\n",
      "date: \"19-7-22\"\n",
      "title: \"AI แยกแยะแมงดาจาน กับ แมงดาถ้วย\"\n",
      "builder: \"ภัคพล อาจบุราย (หลุยส์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/39/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/alicelouis47/maengda-classification-detection\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/417931133708665\"\n",
      "    blog: \"https://medium.com/@phakkhaphonartburai/ai-%E0%B9%81%E0%B8%A2%E0%B8%81%E0%B9%81%E0%B8%A2%E0%B8%B0%E0%B9%81%E0%B8%A1%E0%B8%87%E0%B8%94%E0%B8%B2%E0%B8%88%E0%B8%B2%E0%B8%99-%E0%B8%81%E0%B8%B1%E0%B8%9A-%E0%B9%81%E0%B8%A1%E0%B8%87%E0%B8%94%E0%B8%B2%E0%B8%9E%E0%B8%B4%E0%B8%A9-784bf470c592\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/39/01.jpg)\n",
      "\n",
      "- ในปัจจุบันการรับประทานยำไข่แมงดาได้รับความนิยมมากขึ้น จึงทำให้เกิดปัญหาที่ว่าร้านนำแมงดาที่มีพิษ(แมงดาถ้วย หรือแมงดาเหรา)นำมาปรุงอาหาร และขาย ซึ่งเกิดจากการเข้าใจผิด อาจทำให้ส่งผลต่อชีวิตได้ ผมจึงได้มีความสนใจที่จะสร้าง Application ในการแยกแยะประเภทของแมงดาจาน(กินได้) กับ แมงดาถ้วย(มีพิษ กินไม่ได้) เพื่อช่วยการตัดสินใจก่อนทำอาหาร เพื่อความปลอดภัยในการรับประทาน,\n",
      "- เก็บชุดข้อมูลจาก DuckDuckGo Image Search API; เริ่มแรก scrape ได้กว่า 1,000 รูปแต่คุณภาพไม่ดีจึงคัดเลือกด้วยมือและหาเพิ่มจนได้ชุดข้อมูลสุดท้ายที่แมงดาถ้วย 224 รูปและแมงดาจาน 226 รูป แบ่ง train-test split ที่ 85:15,\n",
      "- สร้าง annotation สำหรับ object detection ด้วยมือผ่านโปรแกรม LabelImg,\n",
      "- ปรับจูนโมเดลจากสถาปัตยกรรม VGG16, VGG19, AlexNet, ResNeXt50, DenseNet201 ครั้งแรกพบว่าผลบน test set ค่อนข้างแย่,\n",
      "- พบว่าโมเดลมีความสับสนระหว่างด้านหน้าและด้านหลังของแมงดา จึงทำโมเดลแยกสำหรับหน้า-หลัง; ได้ความแม่นยำสูงในการทายด้านหน้า-หลัง (F1 ~0.9),\n",
      "- หลังจากแยกแยะด้านหน้า-หลังแล้ว ใช้อีกโมเดลแยกประเภทซ้ำ (multi-model approach) ได้ผลดีขึ้น ด้านหน้า (F1 ~0.83) และ ด้านหลัง (F1 ~0.70); โมเดลที่ทำได้ดีที่สุดได้ผลในการจำแนกชนิดแมงดาโดยรวมสูงถึง F1 0.92,\n",
      "- โมเดลสุดท้ายคือ 1) object detection ทำนายว่าแมงดาอยู่ไหน 2) โมเดลทำนายว่าด้านหน้า-ด้านหลัง 3) ทำนายชนิดแมงดา,\n",
      "- ทดสอบเทียบกับมนุษย์ด้วยแบบสอบถามและรูป 16 รูป พบว่าโมเดลทำได้ดีกว่า (F1 0.89 vs 0.74); จำนวนตัวอย่างเล็กมาก ตีความอย่างระมัดระวัง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เนื่องจากโรงเรียนของผมเป็นโรงเรียนวิทยาศาสตร์ทำให้ผมได้ทำโครงงานวิทยาศาสตร์ที่ต้องศึกษาหาความรู้ด้วยตนเองแล้วก็มีอาจารย์ครูที่ปรึกษามาแนะนำเกี่ยวกับโปรเจคการปรับปรุงน้ำดิบเพื่อนำมาผลิตน้ำประปา ที่ได้ผลิตน้ำประปาเองเป็นส่วนใหญ่เนื่องจากน้ำประปาที่ส่งมาจากการประปาไหลมาไม่เพียงพอต่อบุคคลในโรงเรียน โดยโรงเรียนได้มีการผลิตน้ำเองมาก่อนหน้านี้แล้ว แต่ยังพบว่าน้ำไม่ค่อยได้มาตราฐาน จึงทำให้ผมและคุณครูได้คิดที่จะทำเครื่อง Jartest (สามารถดูเพิ่มเติมได้ในผลงานครับ) ที่ใช้ในทดลองเพื่อหาปริมาณของสารเคมีที่เหมาะสมต่อการผลิตน้ำประปา และเมื่อทำเครื่องเสร็จผมพบกับปัญหาที่ว่า น้ำดิบมีคุณสมบัติไม่เหมือนกันตลอดทั้งวัน ทำให้ต้องมีการทำ Jartest 3 ครั้งต่อวันเพื่อปรับเปลี่ยนอัตราส่วนของสารเคมีให้เหมาะสมต่อการปรับปรุงน้ำดิบ ผมจึงได้หาข้อมูลต่อที่จะช่วยทำให้การปรับปรุงน้ำดิบได้รวดเร็วมากขึ้น ซึ่งเป็นการนำ deep learning มาประมวลผลข้อมูลทางสถิตจากข้อมูลก่อน-หลังการทดลองและปริมาณสารที่เติม และประมวลผลภาพของขนาดตะกอน แล้วผมก็มาพบกับโครงการ AI Builders ที่มีการอบรมเกี่ยวกับ Data Sci และ AI ซึ่งตอบโจทย์ต่อโปรเจคที่ผมสนใจเป็นอย่างมาก แล้วมีการประยุกต์องค์ความรู้ที่เรียนมาใช้ในการแก้ไขปัญหาในชีวิตประจำวันได้อีกด้วย ดูได้จากการนำเสนอผลงานของรุ่นที่แล้วมีความน่าสนใจมากครับ แล้วผมมั่นใจว่าโครงการจะมอบประสบการณ์และเทคนิคในการทำงานเกี่ยวกับAi ให้ผมอย่างมากครับากครับ จึงทำให้กระผมอยากเก็บเกี่ยวประสบการณ์เกี่ยว AI จากโครงการนี้ครับ\"\n",
      "---\n",
      "date: \"20-7-22\"\n",
      "title: \"Is that a Supra?!\"\n",
      "builder: \"จิตรบุณย์ ทรัพย์สินทวีลาภ (กั๊ต)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/40/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/BikiniGordon/Is-that-a-Supra\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/418635413638237\"\n",
      "    blog: \"https://medium.com/@gatchanminecraft/is-that-a-supra-thai-version-405cb2231f2b\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/40/01.jpg)\n",
      "\n",
      "- โมเดลแยกรุ่นรถโตโยต้าจากรูปภาพรวม 36 รุ่นที่เป็นที่นิยมในประเทศไทย; แรงบันดาลใจจากคุณพ่อผู้เป็นอดีตวิศวกรโตโยต้า นั่งรถไปด้วยกันแล้วถามชื่อรุ่น บางครั้งคุณพ่อตอบไม่ได้เนื่องจากเป็นรถรุ่นใหม่หลังจากที่คุณพ่อออกจากบริษัทแล้วจึงมึความคิดว่า “ถ้าเรามีระบบที่เราสามารถโยนรูปไป แล้วระบบตอบกลับมาเป็นชื่อรุ่นเลยก็คงจะดี”,\n",
      "- เริ่มจากการใช้ชุดข้อมูลที่จัดทำโดย Occulta Insights บน Kaggle ประกอบด้วยรถ 38 รุ่น แต่มีรุ่นที่เป็นที่นิยมในประเทศไทยน้อย เช่น Vios มีเพียง 141 รูป และไม่มีการแยกรุ่นย่อย เช่น yaris ativ หรือ corolla altis,\n",
      "- ทำความสะอาดข้อมูล ประเภทรูปที่ไม่ได้ใช้คือ รูปภายในรถ, รูปเครื่องยนต์รถ, รูปที่เจาะจงเฉพาะบางส่วนมากเกินไป และรูปรถคนละรุ่น; มีรูปที่คัดออกทั้งหมด 2,203 จากประมาณ 16,000 รูป หรือประมาณ 13.5% ของจำนวนรูปภาพทั้งหมด,\n",
      "- แบ่งข้อมูลเป็น train-validation-test ที่ 70-15-15; เริ่มเทรนด้วยการปรับจูน resnet34 (freeze 1 epoch; unfreeze 5 epochs) ได้ balanced accuracy 57%; พบว่ารุ่นที่มีรูปน้อย เช่น estima, revo และ rush ทำให้ได้ผลแย่,\n",
      "- แก้ปัญหาด้วยความรู้เกี่ยวกับรถโตโยต้า ได้แก่ 1) ยุบ revo รวมกับ hilux เนื่องจากเป็นรุ่นเดียวกัน 2) ใช้ DuckDuckGo Image Search API หารูปมาเพิ่มสำหรับรุ่นที่มีรูปน้อย 3) ตัด previa ออกเนื่องจากเป็นรุ่นเดียวกับ estima ต่างกันเพียงแค่โซนยุโรปกับเอเชีย 4) ตัด avalon ออก เนื่องจากหน้าตาคล้าย camry และมีขายเพียงแค่ในสหรัฐอเมริกา 5) เพิ่มรูปด้านหลังของ avanza เข้าไปเนื่องจากเดิมมีรูปน้อย 6) เนื่องจาก celica, crown, corona รุ่นเก่าจะมีหน้าตาคล้ายกันมาก จึงเลือกเฉพาะ celica 6-7th generation, crown 12-15th generation ที่ยังมีวิ่งให้เห็นตามท้องถนนเท่านั้น 7) หารูป hilux เพิ่ม 8 ) ตัด vitz ออกเนื่องจากเป็นเพียง yaris ดัดแปลงเล็กน้อย มีขายเฉพาะในญี่ปุ่น 9) เพิ่ม wish ที่มีความนิยมสูงในไทย 10) ตัด vios 3rd generation ออกเนื่องจากโครงเหมือน yaris ativ 10) ตัด verso ออกเนื่องจากไม่มีขายในไทย 11) เพิ่ม c-hr และ sienta ที่เป็นที่นิยมในไทย,\n",
      "- จากการแก้ปัญหาแบบ data centric ทั้งหมดด้านบนทำให้ได้ balanced accuracy เพิ่มเป็น 89% จาก 36 รุ่น\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมมีความรู้ด้านฐานข้อมูลเบื้องต้น พอสมควร จากการเรียนในเอก DE : Digital Engineering ของโรงเรียน เข้าใจหลักการทำงานของฐานข้อมูลเบื้องต้น แต่จุดด้อยของผมคือการเขียนโปรแกรมที่ยังเขียนได้แค่พื้นฐาน แต่ผมก็พร้อมที่จะเรียนรู้ และทำความเข้าใจการเขียนโปรแกรมที่สูงขึ้น ผมพร้อมจะไปหาข้อมูลเพิ่มเกี่ยวกับเรื่องที่ผมยังไม่รู้ และยังไม่เข้าใจ ครับ  ที่ผมอยากเข้าก็เพราะอยากฝึกการเขียนโปรแกรมในระดับที่สูงขึ้นกว่าเดิม อยากจะพบเจอพี่ เพื่อน หรือน้อง ที่มีความรู้และความสนใจในด้านนี้เหมือนกันเพื่อที่จะได้แลกเปลี่ยนข้อมูลกัน อีกอย่างคือผมอยากที่จะลองสร้างระบบที่มีการใช้ฐานข้อมูล และเอไอ มาช่วยคำนวณสิ่งต่างๆ ในชีวิตประจำวันเหมือนกับที่ประเทศญี่ปุ่นที่มีการนำระบบมาใช้ในร้านแห่งหนึ่ง มันเป็นระบบที่จะคำนวณหาจำนวนวัตถุดิบที่ต้องใช้ จากสถิติการสั่งเมนูของลูกค้า ซึ่งผลออกมาเป็นที่น่าพึ่งพอใจอย่างมาก ทางร้านมียอดขายที่เพิ่มขึ้น และวัตถุดิบที่สั้งมาก็เพียงพอกับจำนวนของลูกค้า โดยวัตถุดิบไม่เกินความจำเป็น อยากจะนำความรู้จากการเรียนที่โรงเรียนเกี่ยวกับฐานข้อมูลมาลองปรับใช้ดูในการเขียนโปรแกรมจริงๆ ครับ  หนึ่งโครงงานที่ผมแยกาทำคือการคำนวณการเปิดปิดไฟแดง โดยการใช้ image processing ในการนับจำนวนรถในแต่ละแยกแล้วนำมาคำนวณว่าควรจะปล่อยแยกไหนก่อน เพื่อลดปัญหาการจารจรติดขัดครับ\"\n",
      "---\n",
      "date: \"21-7-22\"\n",
      "title: \"Microplastic detection and collect statistical tebular data.\"\n",
      "builder: \"ภานุวัฒน์ วงศ์พัฒนวุฒิ (ก้อง)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/41/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/kongonggong\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/419222536912858\"\n",
      "    blog: \"https://medium.com/@kongwongpattanawut_61910/microplastic-detection-and-collect-statistical-tebular-data-8d09339e79d\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/41/01.jpg)\n",
      "\n",
      "- โมเดล object detection คัดแยก microplastic ในน้ำ แยกเป็น fragment, pellet, film, foam และ fiber,\n",
      "- เก็บตัวอย่างมาจากแหล่งน้ำต่างๆในจังหวัดมุกดาหาร 6 แหล่ง และนำมาถ่ายในไมโครสโคป ยี่ห้อ Olympus CX23 กำลังขยายเลนส์ใกล้ตา 10x ใกล้วัตถุ 4x; เป็น training set 174 ภาพและ validation set 75 ภาพ,\n",
      "- เพิ่มรูปและแก้ไข class imbalance (pellet และ fiber เยอะกว่าประเภทอื่นมาก) ด้วยการพลิกรูปบน-ล่าง,\n",
      "- ใช้ YOLO v5l (latency น้อยกว่า) และ v5x (ประสิทธิภาพสูงกว่า); ได้ mAP[0.05:0.95] ประมาณ 0.54\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมมีความมุ่งและมีความฝัน ที่จะผลิต คิดค้น นวัตกรรมใหม่เพื่อให้ตอบโจทย์ปัญหาทางสังคมใน ประเทศไทย และ ทั่วโลก เพื่อให้ผู้คนมี การเป็นอยู่ที่ดียิ่งขึ้น โดยการใช้เทคโนโลยี ร่วมกับ สาขาวิชา ต่างๆ อาชีพที่ผมใฝ่ฝันที่จะเป็น คือ วิศวะกรรมคอมพิวเตอร์ เพราะผมต้องการหาความรู้ด้าน คอมพิวเตอร์ เพื่อที่จะนำความรู้ที่มีมากขึ้นมาสร้าง นวัตกรรมใหม่ๆ ให้สังคม และสาขาที่อยากเรียน เสริม คือการบริหารธุรกิจ เพราะการเงินเป็นเรื่องสำคัญสำหรับทุกคน จึงอยากได้ความรู้ด้านการเงิน ควบคู่กับการสร้างนวัตกรรม เพื่อพัฒนา สังคม เเละ เศรฐกิจของไทยอย่างมั่นคงเเละยั่งยืน\"\n",
      "---\n",
      "date: \"22-7-22\"\n",
      "title: \"Debunker: ML ตรวจจับข่าวลวง\"\n",
      "builder: \"นิธิวัฒน์ สิริรัตนชัยกุล (ตง)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/42/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/nitsirs/debunker\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/419846963517082\"\n",
      "    blog: \"https://medium.com/@nitsirs/detecting-thai-fake-news-with-machine-learning-5c1bb3430bf3\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/42/01.jpg)\n",
      "\n",
      "- โมเดลแยกแยะข่าวปลอมประเภทสาธารณสุข,\n",
      "- ใช้ข้อมูลข่าวจริง (2,081 ข่าว) และข่าวเท็จ (2,570 ข่าว) จากชุดข้อมูล LimeSoda (ไม่ใช้ข่าวที่ยังไม่ได้รับการยืนยัน); พยายามหาข้อมูลจากแหล่งอื่นด้วย OCR แล้วแต่ไมไ่ด้ผลดีเท่าที่ควร,\n",
      "- ทดลองกับ WangchanBERTa และ Linear/LSTM head โดยมีและไม่มี backtranslation ได้ผลดีประมาณ F1 0.89-0.91,\n",
      "- พบว่าโมเดลที่ทำได้ดีที่สุดในบริบทการแยะแยะประโยคสั้นๆเช่นกรณีนี้คือ tf-idf + SVM ที่ F1 0.92,\n",
      "- ใช้ LIME เพื่อทำ error analysis ว่าโมเดลใช้อะไรตัดสินว่าเป็นข่าวปลอม ข้อสรุปคือสำหรับโมเดลที่ใช้ keyword ในการแยะแยะเช่น tfidf + SVM นั้นการมี keyword ที่ปรากฎบ่อยในข่าวปลอมอาจจะส่งผลให้โมเดลผิดพลาด เช่น รักษามะเร็ง ลูกหลานของเรา ฯลฯ\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"- ผมมีความสนใจในวิทยาศาสตร์ข้อมูล และกำลังทำโครงงานกลุ่ม เกี่ยวกับ “การใช้ AI ตรวจจับข่าวลวง” - ก่อนหน้านี้ ผมมีความรู้ Machine learning และ NLP เบื้องต้น จึงได้ลองพัฒนาโมเดล AI จัดจำแนกข่าวลวงภาษาอังกฤษ (ใช้ dataset ใน Kaggle.com) แต่ได้ความแม่นยำ ค่า recall และ F1-score ออกมาต่ำ ไม่เพียงพอต่อการใช้จริง (ถ้าหากนำไปใช้จริง อาจเกิดอันตรายต่อผู้ใช้งาน) - จากการค้นคว้าข้อมูลเพิ่มเติม ผมพบว่า ผมยังไม่ได้ลองใช้ deep learning และ transformer อย่างเช่น BERT ที่อาจให้ความแม่นยำสูงกว่า ในการแก้ปัญหานี้ - ** จากหลักสูตรของโครงการ ผมคิดว่าโครงการนี้ จะช่วยเสริมสร้างความรู้และทักษะที่เพียงพอสำหรับการสร้างโมเดล Deep learning ที่มีความแม่นยำสูง รวมทั้งชี้แนะแนวทางในการ Deploy โมเดลให้เป็นเครื่องมือ AI ตรวจจับข่าวลวง (ทั้งภาษาไทย และอังกฤษ) ที่ใช้งานได้จริง และสร้างคุณค่าให้สังคม ** - ป.ล. ผมยังมีความสนใจด้าน Text Generation เนื่องจากผมเป็นคนชอบเขียนบทกวี ผมมีความคิดว่า สักวัน จะสร้าง AI ที่แต่งกลอนได้ไพเราะเท่าท่านสุนทรภู่\"\n",
      "---\n",
      "date: \"23-7-22\"\n",
      "title: \"Brain Tumor Segmentation using SegResNet\"\n",
      "builder: \"ณัฐวดี ลีภัทรกิจ (กิ่งแก้ว)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/43/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Kkingssss/Brain-Tumor-Segmentation/tree/main\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/420395566795555\"\n",
      "    blog: \"https://medium.com/@nattawadee.lee/brain-tumor-segmentation-using-swin-unet-transformers-d003cbe7ba0f\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/43/01.jpg)\n",
      "\n",
      "- โมเดล image segmentation สำหรับเนื้องอกในสมองจากภาพ MRI เพื่อเป็นการช่วยเหลือการทำงานของบุลคลากรทางการแพทย์ทั้งในด้านของเวลาและภาระหน้าที่; การที่จะได้เนื้องอกและปริมาตรของเนื้องอกสมองที่แม่นยำ จะเป็นต้องใช้ผู้เชี่ยวชาญในการระบายสี ภาพสแกนสมอง ซึ่งบางครั้งหากต้องการความแม่นยำสูงอาจต้องใช้มากกว่า 15 นาทีต่อภาพ,\n",
      "- เทรนบนข้อมูล Brain Tumor Segmentation (BraTS) challenge 2021 และใช้ fold 1 สำหรับ validation; ข้อมูลเป็นรูปภาพ 3D ของสมอง (1251 Training / 219 Validation),\n",
      "- ใช้สถาปัตยกรรม SegResNet ที่เป็น encoder-decoder CNN แบบไม่สมมาตร encoder จะเป็นส่วนที่มี ขนาดใหญ่กว่าเพื่อใช้ในการ สกัดฟีเจอร์ของภาพ และ decoder ขนาดเล็กกว่า เพื่อใช้ในการสร้างภาพกลับและตัดชิ้นส่วน,\n",
      "- เปรียบเทียบกับ Swin U-Net Transformers; วัดผลด้วย dice coefficient (พื้นที่ที่ทับซ้อนกันระหว่างจุดที่เป็นเนื้องอกจริงและถูกที่ทำนายว่าเป็นเนื้องอก / พื้นที่ที่เป็นเนื้องอกทั้งหมดทั้งที่เป็นจริงและที่โมเดลทำนาย),\n",
      "- SegResNet ได้ผลดีกว่าที่ 0.8719 แต่มีข้อจำกัดทางทรัพยากรทำให้เทรน Swin U-Net Transformers ได้เพียง 70 epochs (คาดว่าอาจต้องใช้ถึง 600 epochs) ได้ average dice coefficient ที่ 0.7592 (ผู้ชนะการแข่งขันจาก BraTS 2021 ได้ 0.9294)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"หนูเคยเข้าร่วมการาแข่งขันคอมพิวเตอร์โอลิมปิกระดับชาติ ทำให้มีทักษะกระบวนการคิดที่เป็นเหตุเป็นผล เป็นลำดับอยู่พอสมควรและถึงหนูจะไม่ค่อยมีประสบการณ์ด้าน AI แต่หนูมีความเชื่อมั่นและมีความมุ่งมั่นที่จะทำมันให้ได้ค่ะ และเป็นคนที่ชอบค้นคว้าอยู่แล้ว จึงคิดว่าหนูสามารถที่จะเรียนรู้และพัฒนาตัวเองได้ค่ะ ในด้านของการทำงาน หนูเคยได้รับเชิญเป็นผู้ช่วยวิทยากรในการอบรมคอมพิวเตอร์โอลิมปิกค่าย 1 ทำให้มีทักษะการทำงานเป็นทีมร่วมกับทีมวิทยากร  เหตุผลที่อยากเข้าร่วมโครงการนี้เพราะ เป็นคนที่พอมีพื้นฐานการเขียนโปรแกรมอยู่บ้าง เนื่องจากผ่านการเข้าค่ายสอวน.คอมพิวเตอร์ และมีความชื่นชอบในการเขียนโปรแกรม จึงพยายามศึกษาด้วยตนเองในการเขียนภาษา python จึงคิดว่าอยากนำความรู้พื้นฐานที่มีตอนนี้ พัฒนาต่อยอดให้เกิดประโยชน์มากขึ้นได้ก็จะดีมาก โดยได้เล็งเห็นว่า AI เป็นสิ่งที่น่าสนใจมาก สามารถทำหลายอย่าง และแม่นยำได้มากกว่ามนุษย์ และโครงการนี้ก็จะเปิดโอกาสให้หนูได้เรียนรู้และเข้าใจเกี่ยวกับ AI มากขึ้นได้ และอยากได้ลองปฏิบัติจริงเพราะคาดหวังว่าโครงงานของหนูหากได้ทำสำเร็จแล้วจะเป็นประโยชน์กับกลุ่มเป้าหมายค่ะ\"\n",
      "---\n",
      "date: \"24-7-22\"\n",
      "title: \"Classical Music Generator\"\n",
      "builder: \"มณิสรา แซ่จัน (ฟิล์ม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/44/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/ManissaraZ0/AI-Builders-Deploy\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/421598560008589\"\n",
      "    blog: \"https://medium.com/@manissara2548/classical-music-generator-d9fc911abc9c\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/44/01.jpg)\n",
      "\n",
      "- โมเดลแต่งเพลงคลาสสิคด้วย autoregressive LSTM,\n",
      "- แรงบันดาลใจคืออยากมีเพลงที่ทำขึ้นมาไม่ซ้ำใครและเป็นของเราเอง แต่เราไม่จำเป็นต้องเล่นดนตรีด้วยตัวเอง,\n",
      "- เลือกดนตรีคลาสสิคเนื่องจากมีไฟล์ MIDI ที่แสดงข้อมูลทางดนตรี (duration, pitch, step) ไว้เพียงพอแก่การเทรน,\n",
      "- ใช้ข้อมูลทั้งหมดจาก http://www.piano-midi.de/,\n",
      "- ใช้ LSTM 1 layer เพื่อทำนาย pitch (โน้ตมี 128 ชนิด), duration (ระยะเวลาที่กดโน้ต) และ step (ระยะห่างจากโน้ตตัวหน้า)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"หนูสนใจการเขียนโปรแกรมและเอไอจากการเล่นเกมและก็ดูหนังเกี่ยวกับการเขียนโปรแกรมค่ะ หนูรู้สึกว่าการสร้างเกม แอพ เว็บไซต์ สร้างหุ่นยนต์มันเท่มากเลยค่ะ และมันก็น่าหลงไหลมาก หนูชอบที่จะเรียนรู้และก็เขียนโค้ดทำเกมมากเลยค่ะ กิจกรรมที่หนูเคยเข้าร่วมเกี่ยวกับประสบการณ์ทางด้านนี้ก็มีการทำรถหุ่นยนต์ค่ะ หนูอยากเป็นส่วนหนึ่งของค่ายนี้จริงๆค่ะ หนูอยากเรียนรู้และก็พัฒนาทักษะทางด้านนี้และนำไปพัฒนาเทคโนโลยีต่างๆในอนาคตค่ะ ฝากพี่ๆพิจารณาด้วยนะคะ  หนูอยากมีประสบการณ์ทางด้านนี้ให้มากขึ้นค่ะ หลังจากหนูได้เข้าร่วมชมปรับพื้นฐานแล้วหนูรู้สึกว่าหนูมีความชอบและสนใจเรื่องนี้มาก พี่ๆที่สอนปรับพื้นฐานก็สอนเข้าใจง่ายและหนูรู้สึกว่าถ้าหากพลาดค่ายนี้หนูจะต้องเสียดายมากแน่เลยค่ะ หนูอยากเข้าร่วมเป็นส่วนหนึ่งของโครงการและเก็บเกี่ยวความรู้และประสบการณ์ให้ได้มากที่สุดค่ะ\"\n",
      "---\n",
      "date: \"25-7-22\"\n",
      "title: \"Lamiaceae Classification แยกพืชวงศ์กะเพรา 3 ชนิด\"\n",
      "builder: \"วชิรวิทย์ ไชยมาตย์ (เจ้านาย)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/45/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/KaiZer003/LamiaceaeClassify\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/424327439735701\"\n",
      "    blog: \"https://medium.com/@wachirawit003/image-classification-%E0%B9%80%E0%B9%80%E0%B8%A2%E0%B8%81%E0%B8%9E%E0%B8%B7%E0%B8%8A%E0%B8%A7%E0%B8%87%E0%B8%A8%E0%B9%8C%E0%B8%81%E0%B8%B0%E0%B9%80%E0%B8%9E%E0%B8%A3%E0%B8%B2-3-%E0%B8%8A%E0%B8%99%E0%B8%B4%E0%B8%94-480b9b823d85\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/45/01.jpg)\n",
      "\n",
      "-  พืชวงศ์กระเพราหรือ Lamiaceae มีลักษณะคล้ายคลึงกันมากจนบางครั้งมนุษย์แยกไม่ออก นำมาซึ่งแรงบันดาลใจในการทำโมเดลแยกกะเพรา โหระพา และแมงลักจากรูป,\n",
      "- วัดผลเทียบกับมนุษย์ 20 คน (ครู 4 นักเรียน 16) ด้วย mini-validation set 30 รูป (พืชชนิดละ 10 รูป) มี accuracy เฉลี่ยที่ 52.16%; ทำได้ดีที่สุด 76.66% (นักเรียน) และ73.33% (นักเรียน),\n",
      "- รวบรวมข้อมูลด้วยการถ่ายภาพเอง ระหว่างทางพบชุดข้อมูลกะเพรา-โหระพาจาก TAUTOLOGY-EDUCATION Tautology Thailand; แบ่ง test set 20% (177 รูป),\n",
      "- เลือกทำ data augmentation เช่น zoom, lighting, affine transformation ด้วย fastai,\n",
      "- ทดสอบกับสถาปัตยกรรม GoogLeNet, ResNet-152 และ VGG-19 พบว่า GoogLeNet ได้ผลดีที่สุดที่ accuracy 95%; resnet152 และ vgg19 ยังมีความสับสนระหว่างโหระพาและแมงลักอยู่เล็กน้อย,\n",
      "- เทียบกับมนุษย์บน mini-validation set โมเดลทำได้ 86.66% เทียบกับมนุษย์ที่เก่งที่สุดที่ 76.66%,\n",
      "- ข้อจำกัดของโมเดล ด้วยปริมาณข้อมูลเเละวิธีการเก็บ ทำให้เกิดข้อจำกัดหลายส่วน คือ 1.เก่งกับใบมากกว่าต้น 2.ความเเม่นยำต่ำเมื่อนำไปใช้กับภาพที่มีสภาพเเวดล้อมเป็นพื้นหลัง 3.ข้อมูลที่ใช้เทรนได้มาจากผักตามตลาดทำให้โมเดลไม่เก่งกับภาพพืชที่ได้รับความเสียหายจากสภาพเเวดล้อม 4.ต้องโฟกัสภาพเพื่อให้เห็นรายละเอียดของใบชัดเจนก่อน เพื่อให้โมเดลมีประสิทธิภาพสูงสุด,\n",
      "- ลองใช้ชุดข้อมูลได้ที่ https://drive.google.com/drive/folders/1hmc1Io_lg4_Q3fMqsmSPD9XpsBZ93FmJ?usp=sharing\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมมั่นใจว่าผมจะสามารถพัฒนาคนเองและ นำองค์ความรู้ที่ได้รับจากโครงการนี้ไปใช้พัฒนาต่อยอด หรือสร้างสรรค์นวัตกรรมใหม่ ๆ เพื่อสร้างประโยชน์ให้แก่ส่วนรวมได้ โดยแรงบรรดาลใจได้มาจากการที่ตนได้รู้จักและใช้ งานคอมพิวเตอร์ตั้งแต่เด็ก และ ในปัจจุบันผมมีความใส่ใจด้านสุขภาพและสนใจในการสร้าง AI หรือแอพพลิเคชั่นในการคัดเลือกอาหารที่มีประโยชน์ทางโภชนาการที่อยู่ในเกณฑ์ราคาที่เหมาะสมและคุ้มค่ากับคุณค่าทางโภชนาการที่ได้รับ  มีความสนใจในการศึกษาต่อใน สาขาวิศวกรรมซอฟต์แวร์ และวิทยาการคอมพิวเตอร์ ทำให้จําเป็นที่จะต้องพัฒนาทักษะความสามารถและความรู้ในการเขียนโปรแกรม ซึ่งในฐานะผู้เริ่มต้นเขียน Python โครงการนี้เป็นโครงการที่มีความท้าทายและ น่าสนใจเลยทีเดียวตั้งแต่การ ทำแบบฝึกหัดได้เรียนรู้การใช้ฟังชั่นใหม่ ๆ ที่ไม่รู้จักหรือเคยได้ใช้ในภาษา Python และยังมี Numpy Pandas ที่ผมพึ่งได้เริ่มศึกษาเพราะสองอย่างนี้มีความเกี่ยวข้องกับ Data Science ที่ผมสนใจ\"\n",
      "---\n",
      "date: \"26-7-22\"\n",
      "title: \"สร้างสรรบทเพลง Undertale ผ่าน LSTM และ Teacher Forcing RNN\"\n",
      "builder: \"นพวิทย์ ตันติศิริวัฒน์ (ภีม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/46/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Noppawit-Tantisiriwat/AIB2022-Undertale-Music-Generation\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/424934103008368\"\n",
      "    blog: \"https://medium.com/@noppawitpeam/%E0%B8%AA%E0%B8%A3%E0%B9%89%E0%B8%B2%E0%B8%87%E0%B8%AA%E0%B8%A3%E0%B8%A3%E0%B8%9A%E0%B8%97%E0%B9%80%E0%B8%9E%E0%B8%A5%E0%B8%87-undertale-%E0%B8%9C%E0%B9%88%E0%B8%B2%E0%B8%99-lstm-%E0%B9%81%E0%B8%A5%E0%B8%B0-teacher-forcing-6053a939bc62\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/46/01.jpg)\n",
      "\n",
      "- โมเดลแต่งเพลงประกอบเกม Undertale ด้วย RNN ที่ถูกเทรนด้วยเทคนิค Teacher Forcing,\n",
      "- ในวัยเด็กผมเคยมีประสบการณ์เล่มเกมที่มีชื่อว่า Undertale มันเป็นเกมที่มีเนื้อเรื่องแปลกใหม่ ระบบการเล่นที่สนุก และที่สำคัญที่สุด มันมีเพลงประกอบตัวเกมที่ไพเราะเกินบรรยาย เพลงประกอบเกมนี้ได้กวาดรางวัลมาแล้วมากมาย ขายเป็นแผ่นเสียงได้เป็นกอบเป็นกำและได้ถูกจัดแสดงบนเวทีระดับโลกมาแล้ว ตัวผมจึงอยากลองค้นหาความมหัศจรรย์ของบทเพลงเหล่านี้ ทว่าผมขาดความรู้และพรสวรรค์ทางด้านดนตรีจึงไม่สามารถเข้าใจความสัมพันธ์ของบทเพลงเหล่านี้ได้ ผมจึงลองศึกษาศาสตร์AI ในการวิเคราะห์ความสัมพันธ์เหล่านี้ดู,\n",
      "- ใช้ dataset ที่เป็น MIDI ของเพลงเกม Undertale จาก Kaggle,\n",
      "- พบปัญหาว่า 1) มีเครื่องดนตรีเล่นพร้อมกันหลาย track ใน 1 file midi ทำให้ยากต่อการเลือก track ที่มีความสำคัญมากที่สุด 2) resolution (โน้ตถูกแบ่งเป็นกี่ส่วน) ที่กระจายตัวหลากหลาย ค่า resolution ที่มากทำให้สามารถอ่านข้อมูลได้ช้า และสิ้นเปลืองพื้นที่หน่วยความจำ,\n",
      "- แก้ปัญหาโดยการปรับ resolution ให้เป็น 96 ทั้งหมด (เพิ่ม tempo เป็นการทดแทน) และแปลงไฟล์midi ให้เหลือเพียง 1 track และมีเพียง 1 เสียงเครื่องดนตรีด้วย pianoroll (แล้วค่อยเปลี่ยนกลับเป็น MIDI อีกรอบ),\n",
      "- ใช้สถาปัตยกรรม LSTM (1-3 ชั้น), BiLSTM (3 ชั้น) และทดลองเทคนิค warm-start (เทรนต่อจากโมเดลคล้ายคลึงกัน) และ teacher forcing,\n",
      "- teacher forcing เป็นเทคนิคที่ใช้ ground truth เป็น input ให้กับ RNN (ในที่นี้คือ LSTM) ในหน่วยถัดไปแทนที่จะเป็น output จากหน่วยก่อนหน้า,\n",
      "- วัดผลด้วยแบบสอบถามและคำนวณ mean opinion score; พบว่า WarmStart + BiThreeFold (BiLSTM 3 ชั้นและ warm start; 3.68), WarmStart (warmstart + teacher forcing; 3.59), BiThreeFold (BiLSTM 3 ชั้น; 3.34) และ Toby (LSTM 1 ชั้น; 3.30) ทำคะแนนได้ดีกว่าเพลงจริง (2.80) เสียอีก(!!) ทั้งนี้การประเมินผลอาจจะมี bias เนื่องจากความหลากหลายและประสบการณ์ของผู้ทำแบบสอบถาม,\n",
      "- โมเดลไม่สามารถเรียนรู้จังหวะ, ความยาวของโน๊ต และไม่สามารถแต่งเพลงที่มีความหลากหลายของจังหวะได้ อาจจะส่งผลต่อความรู้สึกต่อคุณภาพของเพลงของผู้ตอบแบบสอบถาม เนื่องจากว่าความไพเราะของเพลงมีเรื่องจังหวะและทำนองเข้ามาเกี่ยวข้องด้วย,\n",
      "- โมเดลอาจจะ overfit บทเพลงและยังไม่สามารถแต่งเพลงให้หลากหลายตามอารมณ์ได้; อาจต้องแยกเทรนตามอารมณ์ของเพลง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เมื่อปีที่แล้วพี่ชายของผมได้เข้าร่วมโครงการนี้ จากคนที่แทบจะไม่สนใจภาษาpyton กลับกลายเป็นผู้ที่ชื่นชอบAI และเขามักtrain AIอย่างต่อเนื่อง ผมเคยเข้าร่วมโครงการ ที่เกี่ยวข้องกับ health care data science โดยใช้ภาษาpyton 2 ครั้ง และเคยมีโอกาสศึกษาภาษาpytonด้วยตนเองในเว็บไซต์ต่างๆ เช่น datacamp  AI เป็นสิ่งที่ล้ำสมัยในสายตาของผมและของโลก นอกจากจะมีศักยภาพในการประมวลผลที่สูงกว่ามนุษย์เช่น ในด้านของความเร็ว กระบวนการคิด ฐานข้อมูลอัยมหาศาล และอื่นๆ มันยังวิเคราะห์ผลลัพธ์ออกมาได้หลากหลายประเภท ไม่ว่าจะเป็น ภาพ เสียง ความน่าจะเป็น นอกจากนี้ AI/data scienceยังเป็นสายงานอาชีพที่เป็นที่ต้องการของตลาดในอนาคต ตอนแรกผมคิดว่าการสร้าง ai เป็นเรื่องเพ้อฝัน แต่โครงการนี้ทำให้ฝันที่จะที่จะลองทำสิ่งแปลกใหม่ได้อยู่ต่อหน้าผมแล้ว ผมจะทำมันให้เป็นจริง\"\n",
      "---\n",
      "date: \"27-7-22\"\n",
      "title: \"Plant Disease Classification\"\n",
      "builder: \"รัชชานนท์ มุขแก้ว (นนท์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/47/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/RatchanonMo/plant-diseases-classification\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/425577722944006\"\n",
      "    blog: \"https://medium.com/@49874/plant-diseases-classification-68b103f624d7\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/47/01.jpg)\n",
      "\n",
      "-  โมเดลจำแนกรูปภาพโรคใบพืช 6 ชนิด ได้แก่ เน่าดำ น้ำค้าง ใบจุดดำ ราแป้ง ราดำ ราสนิม,\n",
      "- ใช้ DuckDuckGo Image Search และ Google Image Search ในการรวบรวมชุดข้อมูล; ทำความสะอาด**ด้วยมือ** ทำให้ได้ชุดข้อมูลโรคละ 100-200 รูป และใบพืชไม่เป็นโรคอีก 193 รูป; แบ่ง train-test split ที่ 80/20,\n",
      "- เทรนด้วยสถาปัตยกรรม VGG-16 และเลือก checkpoint ที่ดีที่สุดด้วย validation set ที่สุ่มออกมาจาก training set 17%,\n",
      "- ได้ผลเป็นที่น่าพอใจที่ F1 และ accuracy 0.9 เทียบกับบุคคลทั่วไป (ที่ไม่ได้มีความรู้เรื่องโรคพืช) 30 คนทำแบบสอบถามจะตอบถูกประมาณ 4/10 รูป,\n",
      "- จำเป็นต้องทดสอบกับรูปจากสนามจริงเพื่อปรับปรุงให้พร้อมกับการใช้งานจริงต่อไป\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ส่วนตัวผมเป็นคนที่ชื่นชอบและสนุกไปกับการเรียนรู้และพัฒนาผลงานในด้านคอมพิวเตอร์มากเพราะมันมีความท้าทายแฝงอยู่ไม่น้อย ในปัจจุบันคิดว่าได้ทำผลงานด้านการเขียนเว็บแอพพลิเคชั่นและการเขียนโปรแกรมเบื้องต้นมามากพอแล้ว จึงต้องการศึกษาและพัฒนาผลงานในระดับที่สูงกว่าเดิมและท้าทายมากยิ่งขึ้น  เหตุผลที่อยากเข้าโครงการเพราะว่าต้องการใช้เวลาว่างในช่วงปิดเทอมนี้ในการพัฒนาความรู้และเก็บเกี่ยวประสบการณ์ในด้านคอมพิวเตอร์ให้มากขึ้นและส่วนตัวสนใจในด้าน AI มากพออยู่แล้ว ผมมีความต้องการที่จะพัฒนานวัตกรรมที่เปลี่ยนแปลงหรือยกระดับการใช้ชีวิตในประจำวันให้มีความสะดวกสบายมากยิ่งขึ้น ยกตัวอย่างดังเช่น Facebook ในปัจจุบัน ซึ่งในปีที่แล้วมีพี่ที่สนิทมาชวนเข้าร่วมโครงการนี้ด้วยกัน แต่ผมดันสมัครไม่ทัน ถึงอย่างนั้นผมก็ติดตามบรรยากาศการเรียนการสอนและชื่นชอบผลงานที่มีความโดดเด่นของพี่ ๆ เมื่อปีที่แล้วมาก ก็คิดว่าโครงการนี้ให้ความสนใจและดูแลผู้เข้าร่วมเป็นอย่างดีและน่าสนใจมากเหมือนที่คิดไว้ไม่มีผิดและจะต้องได้ความรู้ในด้านปัญญาประดิษฐ์ที่สอดคล้องกับเป้าหมายของตัวเอง จึงรู้สึกดีใจและตื่นเต้นไม่น้อยที่จะได้เป็นส่วนหนึ่งในโครงการนี้บ้าง ฉะนั้นปีนี้ผมจะต้องไม่พลาดโอกาสอีก ถ้าหากได้เข้าร่วมโครงการนี้ผมจะนำความรู้ไปต่อยอดในการพัฒนาผลงานต่อไป รวมถึงการเข้ามหาลัยและการประกอบอาชีพในอนาคตด้วย\"\n",
      "---\n",
      "date: \"28-7-22\"\n",
      "title: \"TLDR; Terms and Conditions Summarizer\"\n",
      "builder: \"ศุภโชค บุตรดีขันธ์ (บูม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/48/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Mikune00/ai-text-sum\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/427644922737286\"\n",
      "    blog: \"https://medium.com/@kaitosolo18/terms-and-condition-summarization-d7f0680f752b\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/48/01.jpg)\n",
      "\n",
      "- ผลจากการสำรวจประชากร Gen Z 100 คนชาวไทยพบว่าเพียง 92% เห็นว่าข้อกำหนดและเงื่อนไขมีความสำคัญ แต่มีเพียง 1% ที่อ่านเต็มๆทุกครั้ง เนื่องจากมันยาวมาก ข้อมูลเยอะเกินไป ไม่น่าอ่านด้วย เสียเวลา และอื่น ๆ อีกมากมาย, \"\n",
      "- เก็บข้อมูลจากเว็บไซต์ Terms of Service; Didnt Read ที่ประกอบด้วยข้อกำหนดและเงื่อนไขตัวเต็มและคำย่อที่เว็บไซต์ย่อมาให้แล้ว\",\n",
      "- ทำความสะอาดข้อมูลด้วยการลบอักษรพิเศษ ช่องว่างส่วนเกิน และข้อความที่ไม่มีคู่คำย่อ,\n",
      "- ข้อความตัวเต็มส่วนใหญ่มีความยาวราว 100-200 คำและมากที่สุดถึง 1600 คำ ส่วนคำย่อมีความยาวเฉลี่ย 10 คำ,\n",
      "- เทรนด้วยสถาปัตยกรรม T5; แบ่งชุดข้อมูลเป็น train-validation-test ที่ 70-20-10,\n",
      "- ได้ผล ROUGE-1 F1 0.66, ROUGE-2 F1 0.52 และ ROUGE-L F1 0.61; เปรียบเทียบกับ baseline คือการทำ sentence retrieval ด้วย T5 ได้ดีกว่าประมาณ 3-5 เท่า,\n",
      "- Open Source บน HuggingFace Hub\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมได้เข้าร่วมเเข่งขันโครงงานวิทยาศาสตร์สาขาวิทยาการข้อมูลเเละได้ทำโครงงานเกี่ยวกับการใช้เขียนโปรแกรมเเจ้งเตือนอัตโนมัติผ่าน line โดยใช้ข้อมูลจากกรมอุตินิยมวิทยา4ปีย้อนหลังในการคาดคะเนการเกิดอุทุกภัย เเละโครงงานนี้เองที่เป็นเเรงบันดาลใจในการศึกษาด้านต่อในเรื่อง ai เพื่อนำไปประยุต์ใช้กับปัญหาต่างๆในอนาคตเเละผมมั่นใจว่าถ้าหากผมได้รับเข้าโครง AI Builders 2022 จะให้ความร่วมมือเเละตั้งใจอย่างถึงที่สุดครับ  มีความสนใจในเรื่อง ai เพราะในปัจจุบัน ai เป็นที่พูดถึงอย่างมากเเละในอนาคตอันใกล้นี้ ai อาจมีบทบาทมากขึ้นกว่าปัจจุบันผมจึงอยากพัฒนาฝีมือของตัวเองพร้อมทั้งหาเรื่องที่ท้าทายมากขึ้นเละเล็งเห็นว่าโครงการ AI Buildersนี้สามารถให้ความรู้กับผมเพื่อไปพัฒนาเเละต่อยอดได้เห็นได้จากผลงานของพี่ๆที่เคยเข้าร่วมโครงการนี้ ทุกผลงานมีการประยุตก์ใช้ในการแก้ปัญหาต่างๆได้อย่างเหมาะสมผมจึงอยากที่จะเข้าร่วมโครงการ AI Builders 2022 เพื่อสามารถพัฒนาเเละแก้ปัญหาต่างได้อย่างกับพี่ๆที่เคยเข้าร่วมโครงการนี้ครับ\"\n",
      "---\n",
      "date: \"29-7-22\"\n",
      "title: \"RL in Traffic Management\"\n",
      "builder: \"ณดล พิพัฒนติกานันท์ (ไตตั้น)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/49/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/nadoltitan/RL_in_Traffic_Management\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/429097575925354\"\n",
      "    blog: \"https://medium.com/@nadoltitan1/%E0%B8%A5%E0%B8%94%E0%B8%9B%E0%B8%B1%E0%B8%8D%E0%B8%AB%E0%B8%B2%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%88%E0%B8%A3%E0%B8%B2%E0%B8%88%E0%B8%A3%E0%B8%95%E0%B8%B4%E0%B8%94%E0%B8%82%E0%B8%B1%E0%B8%94%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2-reinforcement-learning-d3b9c6014863\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/49/01.jpg)\n",
      "\n",
      "- โมเดล reinforcement learning (advantage actor-critic; A2C) ทำหรับจัดการไฟจาราจรบนแบบจำลอง Simulation of Urban Mobility (SUMO) ที่สร้างขึ้นมาจากแผนที่จริงผ่าน OpenStreetMap,\n",
      "- สร้างแบบจำลองแยกจราจรจากแผนที่ OpenStreetMap บน SUMO ด้วยOSMWebWizard; สร้างไฟล์ .net.xml สำหรับเส้นทางเดินรถ และ .rou.xml สำหรับระบุรถที่เข้ามาในเลน กำหนดให้รถเข้ามาในเลนของแบบจำลองโดยการสุ่ม,\n",
      "- วัดผลโดยการคำนวณความหนาแน่นของรถต่อเลนโดยเฉลี่ย (average lane density),\n",
      "- ทดลองสี่แยกแบบง่ายกับสถาปัตยกรรม A2C, Deep Q-learning (DQN), Proximal Policy Optimization (PPO); พบว่า A2C ทำได้ดีที่สุด,\n",
      "- ปัญหาสำคัญของโครงงานนี้ที่ยังต้องหาทางแก้ไข และปรับปรุงต่อไปก็คือ map จากเส้นทางจริงที่ถูก import มาจาก OSM มีความผิดพลาดของเส้นถนนอยู่มากมาย เช่น สัญญาณไฟจราจรที่มีมากกว่าหนึ่งอันในหนึ่งแยก เส้นทางถนนที่เกิดการทับซ้อนกันของ map ทำให้รถวิ่งขวางเส้นทางกันเอง(ซึ่งไม่ควรเกิดขึ้นกับสถานที่จริง) ปัญหาถนนที่เป็นทางตันทำให้รถบางส่วนวิ่งวนและเกิดการติดขัดไปสู่ทั้งระบบ และทำให้เป็นปัญหาในการ import มาให้ RL เรียนรู้ จากปัญหาดังกล่าวทำให้เราตัดสินใจว่า โครงงานนี้จะใช้ map ที่มีอยู่จาก Library SUMO-RL ที่มีความซับซ้อนมากขึ้นและใกล้เคียงกับ map ในสถานที่จริงมากที่สุด แทนการใช้ map ที่มีในสถานที่จริง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมมีความสนใจในการ coding มาเป็นเวลาสักพักใหญ่แล้วครับ ผมได้ลองพยายามศึกษาจากการนั่งฟังบรรยายมาเยอะพอสมควร ได้ลองเสียเงินฟังบรรยาย ก็ได้ความรู้พื้นฐานมาบ้างแต่ผมก็ไม่ได้รู้สึกว่าตัวเองเขียน code เป็นเลย จนผมลองมาเจอกับโครงการ AI builder ของปีที่แล้ว ผมรู้สึกชอบวิธีการที่สอนแล้วตั้งคำถามไปด้วยมากๆ และได้ลองแก้โจทย์ที่ทีมงานได้ให้มา ถึงตอนนั้นผมจะยังไม่ได้ได้ผ่านเข้ารอบมาทำ Project ต่อ แต่ผมก็ได้รู้ว่าการทำ coding นั้นไม่ใช่แค่ฟังแล้วจะเขียน code เป็น ต้องอาศัยการฟัง การทำความเข้าใจ และ ลงมือปฏิบัติจริง ถึงจะทำให้เราสามารถแก้ไขปัญหาได้ นั้นจึงเป็นเหตุผลว่าทำไมผลถึงอยากเข้าร่วมโครงการนี้ ผมอยากได้ความรู้ที่จะนำไปต่อยอดสู่อนาคตได้ อยากลองทำ Project เกี่ยวกับ coding ให้มันสำเร็จสักอันหนึ่ง อยากมีประสบการณ์การต่างๆที่ผมจะสามารถเรียนรู้จากมันได้ อยากจะทำให้ตัวเองกล้าพูดได้อย่างเต็มปากหลังจบ Project นี้ไปว่า “ผมเขียน Code เป็น”\"\n",
      "---\n",
      "date: \"30-7-22\"\n",
      "title: \"Learn Chinese Faster by Using Handwritten Chinese Character Recognition (HCCR)\"\n",
      "builder: \"ภควุฒิ ธรรมาวุฒิกุล (Army)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/50/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/GithubArmy/Handwritten-Chinese-Character-Recognition\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/429664732535305\"\n",
      "    blog: \"https://medium.com/@army.prakawut/learn-chinese-faster-by-using-handwritten-chinese-character-recognition-hccr-67b23c63fb9\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/50/01.jpg)\n",
      "\n",
      "- โมเดลทำนายตัวอักษรภาษาจีนจากลายมือ 1,059 ตัวใน HSK4 และ 7,330 ตัวที่ใช้บ่อยด้วย resnet34; ใช้ได้ทั้งทาง webapp และบน Raspberry Pi,\n",
      "- ชุดข้อมูลจาก Institute of Automation of Chinese Academy of Sciences; แปลงเป็น png ในชุดข้อมูล pascalbliem/handwritten-chinese-character-hanzi-datasets บน Kaggle,\n",
      "- ข้อมูลแบ่งเป็น train ประมาณ 600 รูปต่อตัวอักษรและ test ประมาณ 140 รูปต่อตัวอักษร,\n",
      "- เทรนโมเดล ResNet18, ResNet34 และ MobileNetV2 ด้วย GPU บนโน้ตบุ๊คของตัวเอง,\n",
      "- ได้ accuracy 97.3% บนชุดข้อมูล HSK4 (1,059 ตัวอักษร) และ 94.4% บนชุดข้อมูล 7,330 ตัวอักษร,\n",
      "- ศึกษาคุณภาพของโมเดลด้วยการให้คน 15 คนลองใช้ webapp บน Huggingface ค้นพบว่าการเขียนผิด เช่น องศาของเส้น มีผลต่อความมั่นใจของโมเดล; โมเดลที่เทรนบนชุดข้อมูล 7,330 ตัวอักษรมีตัวอักษรที่ไม่ใช่อักษรจีน เช่น\\u3000≠ ถูกสับสนกับ\\u3000半,\n",
      "- พบว่าโมเดลทำนาย 一 (เลขหนึ่ง) ได้ยากมาก (ถูกเพียงหนึ่งในสิบครั้งโดยเฉลี่ย); เหตุผลคือภาพที่ถูกเทรนเป็นสี่เหลี่ยมผืนผ้า และเมื่อถูกบีบให้เป็นสี่เหลี่ยมจตุรัสระหว่างเทรนจึงทำให้ได้ผลที่ไม่ดี; แก้ไขด้วยการปรับขนาดให้ถูกต้อง,\n",
      "- โมเดลสามารถใช้ได้ทั้งผ่าน webapp, Raspberry Pi 3b+ และ Raspberry Pi Zero 2w\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"I have been coding since I was young, so I would understand the concept faster. I have experience in coding microcontrollers using C language and competing in several robotic competitions, but I have never made any project about AI. This is a very great opportunity for me to start learning and using AI. If I were able to make AI, I could also use it to develop other projects and skills, like applying AI into robots. I believe that understanding AI would help in my later studies and jobs as AI are becoming more desired in companies over the years. I would also give my best and as much time as needed to finish the project. I have high stamina and diligence. I would never give up solving what I had started.  I really want to join the course as I want to be able to make AI project and code Python. Nowadays, AI is founded almost everywhere, but I still don’t understand what it is and how it works. Or even how good it is that it is so widely founded and common. I think these questions will be all clear to me if I join this course. I know that everything is going into the digital world, and AI & coding skills are greatly appreciated. Therefore, knowing how to use Python and make AI would really make me accomplished more in future. Making an AI project would also be really fun as I would have to embrace harder challenges and coding bugs. I have never used Python before, so when I watched your videos about Python, NumPy, and Pandas, it was really fascinating to me. I always enjoy the feeling when I finally solve each of the questions in this Python Exam.\"\n",
      "---\n",
      "date: \"31-7-22\"\n",
      "title: \"Crossec : ระบบส่งเสริมการทำปฏิบัติการเนื้อเยื่อพืชด้วยปัญญาประดิษฐ์\"\n",
      "builder: \"วิทวัส กิติภัทร์ถาวร (เอิร์ธ)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/51/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/earthwittawat2548/Crossec\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/432856865549425\"\n",
      "    blog: \"https://medium.com/@wittawatkitipatthavorn/crossec-%E0%B8%A3%E0%B8%B0%E0%B8%9A%E0%B8%9A%E0%B8%AA%E0%B9%88%E0%B8%87%E0%B9%80%E0%B8%AA%E0%B8%A3%E0%B8%B4%E0%B8%A1%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%97%E0%B8%B3%E0%B8%9B%E0%B8%8F%E0%B8%B4%E0%B8%9A%E0%B8%B1%E0%B8%95%E0%B8%B4%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B9%80%E0%B8%99%E0%B8%B7%E0%B9%89%E0%B8%AD%E0%B9%80%E0%B8%A2%E0%B8%B7%E0%B9%88%E0%B8%AD%E0%B8%9E%E0%B8%B7%E0%B8%8A%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2%E0%B8%9B%E0%B8%B1%E0%B8%8D%E0%B8%8D%E0%B8%B2%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B8%94%E0%B8%B4%E0%B8%A9%E0%B8%90%E0%B9%8C-77613e88fb0a\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/51/01.jpg)\n",
      "\n",
      "- โมเดลจำแนกภาพตัดขวางเนื้อเยื่อพืช 8 ประเภท (ลำต้น ราก ใบ ประเภทต่างๆ) ด้วย ResNet34,\n",
      "- แรงบันดาลใจจากการสัมภาษณ์ครูสอนเรื่องการทำปฏิบัติการภาพตัดขวางเนื้อเยื่อพืช ครู 1 คนต้องมีหน้าที่ตรวจชิ้นเนื้อที่นักเรียนประมาณ 40 คนทำการตัดขวาง (cross section) ทำให้ต้องใช้เวลานานหรือจำเป็นต้องจำกัดชนิดของพืชที่เลือกมาทำปฏิบัติการลง,\n",
      "- ทำ cross section เพื่อเก็บภาพจากห้องปฏิบัติการด้วยความช่วยเหลือของทีมงาน (ของ builder เอง) จากพืชหลากหลายชนิด เช่น ข้าวโพด หญ้าขน ถั่วเขียว หมอน้อย ผัดเป็ดไทย หญ้าหมู เป็นต้น รวมทั้งสิ้น 1,250 ภาพ,\n",
      "- ชุดข้อมูลที่ใช้งานถูก open source ไว้ที่: https://www.kaggle.com/datasets/earthwttw/plant-tissue-cross-section-dataset/,\n",
      "- วัดผลด้วย 10-fold cross validation เนื่องจากข้อมูลที่ใช้เทรนมีปริมาณน้อย,\n",
      "- ใช้สถาปัตยกรรม ResNet34 ในการปรับจูนกับภาพเนื้อเยื่อพืช เทรนโมเดล 5 ครั้ง ได้ accuracy เฉลี่ยที่ 96.96% เทียบกับนักเรียนมัธยม 6 ภาควิทย์คณิต 37 คนที่ตอบถูกเฉลี่ยเพียง 31% แสดงให้เห็นว่าโมเดลสามารถใช้เพื่อช่วยส่งเสริมการสอนทำปฏิบัติการสำหรับนักเรียนที่ยังไม่มีความชำนาญได้เป็นอย่างดี\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"มีความสนใจในภาษา Python แต่ยังใช้งานได้ในระดับ Basic จึงอยากเรียนรู้เพื่อให้สามารถนำไปประยุกต์ใช้งานในระดับสูงต่อได้ในอนาคต และมีความชอบในศาสตร์ของ AI ต้องการประสบการณ์การในการพัฒนา AI เพื่อแก้ไขปัญหาในหัวข้อที่สนใจ และประสบการณ์ในการแก้ไขปัญหาเพื่อให้เป้าหมายสำเร็จลุล่วง  ต่อยอดระบบส่งเสริมการทำปฎิบัติการเนื้อเยื่อพืชด้วยปัญญาประดิษฐ์ การเข้าใจเนื้อเยื่อพืชนำไปสู่ความเข้าใจเกี่ยวกับกลไกการดำรงชีวิตของพืชที่แตกต่างกันไป การศึกษาเนื้อเยื่อพืชทำได้โดยเทคนิคการตัดตามขวาง เป็นการตัดโครงสร้างของพืชให้มีความบางสม่ำเสมอแล้วนำไปส่องใต้กล้องกล้องจุลทรรศน์ โดยเทคนิคการตัดด้วยมือเปล่าเป็นที่นิยมเนื่องจากทำได้โดยใช้อุปกรณ์ไม่มาก แต่อาศัยความชำนาญ มีการจัดสอนอยู่ในระดับชั้นมัธยมศึกษาปีที่ 5  ปัญหาที่เกิดขึ้นคือ นักเรียนขาดทักษะในการทำปฎิบัติการ ทำให้บางชิ้นงานไม่เหมาะสมจะนำไปใช้งานต่อ จึงต้องสอบถามครูผู้สอนเพื่อให้แน่ใจว่าชิ้นงานของตนเองเหมาะสมจะนำไปใช้งานต่อในกิจกรรมได้ รวมถึงข้อจำกัดด้านเวลาทำให้กิจกรรมในห้องดำเนินไปไม่ได้เร็วมากนัก จึงต้องจำกัดการเรียนรู้ลงเหลือเพียงพืชไม่กี่ชนิดเท่านั้น ทำให้ไม่สามารถศึกษาเนื้อเยื่อพืชที่สนใจได้  การพัฒนา AI เพื่อช่วยส่งเสริมการสอนของครู โดยการระบุชนิดของเนื้อเยื่อพืชว่าเป็นโครงสร้างส่วนใด และมีความเหมาะสมที่จะไปใช้งานต่อหรือไม่ จะช่วยให้การดำเนินไปของปฏิบัติการรวดเร็วขึ้น เพราะตรวจสอบชิ้นงานได้ตลอดเวลา และสามารถศึกษาหัวข้อเนื่อเยื่อพืชที่ตนเองสนใจได้ ทำให้นักเรียนได้เห็นเนื้อเยื่อของพืชหลากหลายชนิดจากนักเรียน คนอื่น ๆ จากการสังเกตและเชื่อมโยงภาพเหล่านั้นจะทำให้นักเรียนสามารถสร้างข้อสรุปและสร้างองค์ความรู้ได้ด้วยตนเอง (constructivisim) นอกจากนี้ยังเป็นเครื่องมือที่อำนวยความสะดวกให้ครูจัดการเรียนรู้ด้วยวิธีปฏิบัติจริง (active learning) อีกด้วย  Dataset สามารถหาได้จากการทำปฏิบัติการเนื้อเยื่อพืชของนักเรียนหรือสร้างขึ้นเอง\"\n",
      "---\n",
      "date: \"1-8-22\"\n",
      "title: \"American Sign Language\"\n",
      "builder: \"กรกมล แสงสว่าง (เบลล์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/52/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Berubell9/American-sign-language\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/434912155343896\"\n",
      "    blog: \"https://medium.com/@15192/american-sign-language-asl-b9f1c1a6dc01\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/52/01.jpg)\n",
      "\n",
      "- แรงบันดาลใจจากการดูวิดีโอที่มีชื่อว่า “ครู…โลกเงียบ” ของ 7Eleven ที่แสดงให้เห็นถึงครูที่เข้าใจหัวอกของเด็กสาวที่ชื่อว่า “บัว” ซึ่งเธอเป็นผู้พิการที่มีความบกพร่องทางการได้ยิน แต่กลับกันแม่ของเธอกลับไม่เข้าใจถึงโลกที่เธออยู่ และเพิกเฉยต่อสิ่งที่เธอเป็น ทำให้เด็กสาวมีความพยายามที่อยากจะพูดให้ได้ เพื่อที่จะให้แม่ของเธอเข้าใจในสิ่งที่เธอนั้นต้องการ (https://www.youtube.com/watch?v=8n6ocbjrZw8),\n",
      "- พบข้อจำกัดคือไม่มีชุดข้อมูลภาษามือไทยจึงเริ่มทำโครงงานด้วยชุดข้อมูลตัวอักษรภาษามืออเมริกัน American sign language (ASL) ได้แก่ A , B, C, D, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, Nothing, Space และ Del,\n",
      "- ชุดข้อมูลรวบรวมจาก open source บน Kaggle จำนวน 7 แหล่ง; ทำความสะอาดข้อมูลจาก 352,647 รูป คัดอย่างละเอียดเหลือ 14,498 รูป (หนึงประเภทตัวอักษรมีข้อมูลประมาณ 500 รูป),\n",
      "- ปรับจูนสถาปัตยกรรม ResNet50 จำนวน 30 epoch ได้ accuracy บน test set (แบ่ง 90/10) ที่ 71%,\n",
      "- พบตัวอักษรที่ใช้สัญลักษณ์มือคล้ายกันทำให้โมเดลอาจจะจำผิดพลาด เช่น A กับ E, S กับ T, G กับ Z เป็นต้น\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"จากประสบการณ์ที่หนูเคยได้เข้าร่วมกิจกรรม และเข้าร่วมการแข่งขันทางด้าน AI มา มันทำให้หนูค้นพบว่าตนเองสนใจอะไร ค้นพบเส้นทางที่อยากเดินต่อ แต่ตอนนี้ยังขาดความรู้ ยังอ่อนประสบการณ์ ถ้าทางโครงการอยากได้คนที่พร้อมที่จะรับความรู้ คนที่มีความมุ่งมั่นและความตั้งใจ หนูขอให้ทางโครงการลองเปิดโอกาสให้หนูได้แสดงให้เห็น หนูรับรองว่าจะไม่ทำให้ทางโครงการผิดหวังแน่นอนค่ะ  ตัวหนูมีความสนใจทางด้าน AI ค่ะ เลยอยากที่จะเข้าร่วมโครงการนี้ เนื่องจากหนูมีเป้าหมายที่อยากจะนำความรู้ที่ได้จากโครงการไปพัฒนาศักยภาพของตนเอง จนสามารถนำความรู้ที่ได้ไปเป็นส่วนหนึ่งในการสร้างสรรค์นวัตกรรมใหม่ๆ และพัฒนาเทคโนโลยีทางด้าน AI เพื่อเข้ามาช่วยเหลือสังคม และตอบสนองความต้องการของผู้คนทั่วโลกค่ะ  อยากทำแอปพลิเคชันสำหรับคนพิการทั้งที่เป็นใบ้ และหูหนวกค่ะ โดยโครงงานนี้จะเข้ามาช่วยแก้ปัญหาในเรื่องการสื่อสารระหว่างคนปกติและคนพิการ หลักการทำงานจะใช้กล้องถ่ายเก็บข้อมูลภาษามือ แล้วให้ AI ประมวลผล พร้อมแปลความหมายให้กับคนที่จะสื่อสารด้วย โดยหาชุดข้อมูลจากคนที่หูหนวกและเป็นใบ้ และบุคคลที่เชี่ยวชาญเรื่องการแปลภาษามือ\"\n",
      "---\n",
      "date: \"2-8-22\"\n",
      "title: \"A Lip Reader\"\n",
      "builder: \"พุทธคุณ บุญชัย (ข้าวตู)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/53/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Kaotu999/A_Lip_Reader\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/435685011933277\"\n",
      "    blog: \"https://medium.com/@boonchaiphutthakhun/a-lip-reader-c69be0d8363c\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/53/01.jpg)\n",
      "\n",
      "- โมเดลอ่านปากจากวิดีโอด้วย CNN-LSTM,\n",
      "- สร้างชุดข้อมูลขึ้นมาเองโดยใช้รูปหน้าคนที่กำลังพูด phoneme จากวิดีโอคนพูดบทหนัง Bee Movie เป็นเวลา 1 ชั่วโมงกว่า (https://www.youtube.com/watch?v=AJCfgXhA5fc),\n",
      "- จับคู่รูปหน้า(และปาก)กับ phoneme ได้ประมาณ 100,000 คู่; phoneme มี 40 ประเภท,\n",
      "- ทดลองสถาปัตยกรรม CNN ทายทีละรูปและ CNN-LSTM เพื่อทาย phoneme จาก sequence ของรูปก่อนหน้า; ได้ accuracy บน validation set ที่ 42.9% (CNN) และ 32% (CNN-LSTM),\n",
      "- เปลี่ยน phoneme เป็นคำด้วย The CMU Pronouncing Dictionary,\n",
      "- เหตุผลความผิดพลาดหลักๆเนื่องจาก phoneme มีประเภทเยอะ, บาง phoneme รูปปากใกล้เคียงกันมาก เช่น f และ v, และบาง phoneme มีจำนวนรูปที่ใช้เทรนน้อย (เสียงที่ไม่ค่อยมีคนใช้ เช่น zh)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เพราะผมรู้ตัวว่าผมชอบด้านนี้แน่ๆ ผมอยากเรียนรู้เพิ่มเติมในด้านการเขียนโปรแกรมภาษาไพทอน ถึงแม้โครงการนี้จะไม่รับผมเข้าผมก็ยังจะศึกษาคนคว้าแลอบด้านนี้ต่อไป และผมทุ่มเทเวลาและตั้งใจ ศึกษาหาคอร์สสอนพวกนี้อยู่ตลอด และถ้าเข้าโครงการนี้ได้ผมจะตั้งใจจริงๆ  ผมสนใจในการโค้ดภาษา python มากๆ หาเรียนฟรีใน YouTube มาตลอดและมีเรียนจากที่โรงเรียนเล็กน้อย ผมเห็นว่า python สามารถทำอะไรได้มากมายจึงอยากเรียนรู้เพิ่มเติมในด้านนี้ ผมไม่ค่อยมีความรู้ด้าน library numpy หรือ pandas (อาจจะทำผิดในข้อสอบข้อต่างๆที่ใช้ module พวกนี้ แต่เรียนคอร์สปรับพื้นฐานที่โครงการจัดให้แล้ว) แต่ผมพอมีพื้นฐาน python เคยทำเกมจาก pygame หรือ lib ต่างๆ ผมจึงอยากเข้าร่วมโครงการนี้เพื่อเรียนรู้การทำ AI ด้วย python และการใช้ library ต่างๆเช่น numpy หรือ pandas ผมเพิ่งมาเห็นโพสต์นี้เอาวันสุดท้ายก็อาจจะมีมีโค้ดผิดอยู่สองข้อ แต่ผมตั้งใจทำในระยะเวลาที่เหลืออยู่มากที่สุดแล้วครับ อยากเข้ามากๆครับ\"\n",
      "---\n",
      "date: \"3-8-22\"\n",
      "title: \"Obstacle Detection for Blind people ช่วยเหลือผู้พิการทางสายตาด้วย Deep Learning\"\n",
      "builder: \"เทพบดินทร์ ใจอินสม (ฟู่)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/54/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/thepbordin/Obstacle-Detection-for-Blind-people\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/436406668527778\"\n",
      "    blog: \"https://medium.com/@thepbordinjaiinsom/obstacle-detection-for-blind-people-d33e3c4e11dd\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/54/01.jpg)\n",
      "\n",
      "- โมเดลตรวจจับสิ่งกีดขวางเพื่อช่วยนำทางผู้พิการทางสายตาด้วย YOLO v5,\n",
      "- แรงบันดาลใจจากการเป็นจิตอาสาอ่านหนังสือให้ผู้พิการทางสายตาบน Read for The Blind สนใจการพัฒนา Accessibility ต่างๆให้กับผู้พิการ,\n",
      "- ไอเดียแรกเริ่มจากการทำโมเดลตรวจจับ ประตู vs ทางเดิน (object detection) ด้วยชุดข้อมูล Unimelb Corridor Synthetic Dataset และ MiguelARD/DoorDetect-Dataset ด้วยการปรับจูนสถาปัตยกรรม Detectron2 และ Faster R-CNN R50-FPN ได้ผลไม่เป็นที่น่าพอใจ สันนิษฐานว่าเป็นเพราะคำนิยาม \"ทางเดิน\" นั้นกว้างจนเกินไป,\n",
      "- ปรับไอเดียเป็น object detection สำหรับสิ่งกีดขวาง 10 ชนิด เช่น ประตู ประตูที่เปิด ประตูตู้เย็น โต๊ะ โซฟา ฯลฯ โดยใช้ชุดข้อมูล Indoor Training Set (ITS) [RESIDE-Standard] บน Kaggle และ annotate ข้อมูลเองด้วย openvinotoolkit/CVAT; แบ่งเป็น test set ประมาณ 100 รูป,\n",
      "- ทดลองเทรน Detectron2 และ Faster R-CNN R50-FPN หลายครั้ง พร้อมทำ error analysis ว่าสิ่งกีดขวางประเภทไหนโมเดลยังจับได้ไม่ดี ได้ทำการ annotate ข้อมูลเพิ่ม,\n",
      "- สุดท้ายเปลี่ยนมาใช้สถาปัตยกรรม YOLO v5 ที่ได้ผลดีที่สุดบน test set; ยังมีสิ่งกีดขวางบางประเภท เช่น เสา ที่มีข้อมูลน้อยจนโมเดลไม่สามารถเรียนรู้ได้ดีเท่าที่ควร,\n",
      "- เปิดชุดข้อมูลเป็นสาธารณะ เข้าไปใช้งานได้ที่ https://www.kaggle.com/datasets/thepbordin/indoor-object-detection,\n",
      "- เปิด template สำหรับการ deploy YOLO v5 บน streamlit เป็น open source; เข้าไปใช้ไดที่ https://github.com/thepbordin/YOLOv5-Streamlit-Deployment\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมมีความใฝ่รู้สิ่งใหม่ๆ มีไฟในการเรียนรู้ศึกษาสิ่งใหม่ๆอย่างมาก ผมพร้อมที่จะเรียนรู้สิ่งที่โครงการนี้พร้อมที่จะมอบให้และผมจะนำไปพัฒนาให้ดีมากยิ่งขึ้น ผมยังมีประสบการณ์เข้าร่วมโครงการ Young Computer Scientist Camp #2 มหาวิทยาลัยเชียงใหม่ที่เรียนรู้เกี่ยวกับการเขียน Bot Python เบื้องต้น และมีประสบการณ์การเขียนภาษา Python มีประสบการณ์เป็นเจ้าของและผู้พัฒนาเซิร์ฟเวอร์ Minecraft และมีความเข้าใจภาษาอังกฤษได้เป็นอย่างดี ผมมั่นใจว่าถ้าผมได้เข้าร่วมโครงการนี้จะสร้างผลงานดีๆและนำไปสานต่อในอนาคตให้เกิดประโยชน์ต่อส่วนรวม  ผมมีความสนใจด้าน AI และวิทยาศาสตร์ข้อมูล และกำลังเริ่มศึกษาหาความรู้ พี่ๆของผมจึงแนะนำค่ายนี้ หลังจากที่ผมเข้าไปศึกษาดูโครงการนี้แล้วเห็นว่า โอ้โห เด็กนักเรียนระดับมัธยมก็สามารถสร้าง AI ดีๆขึ้นมาได้ ผมจึงทำการศึกษาข้อมูลเพิ่มเติมและตั้งเป้าหมายให้ได้เข้าร่วมโครงการนี้ และในที่สุดผมจะนำความรู้ที่ได้จากโครงการไปพัฒนาปัญญาประดิษฐ์ที่ใช้งานได้จริง และมีประโยชน์ต่อผู้อื่น นั่นจะเป็นหนึ่งในความภาคภูมิใจของผม  ผมอยากทำโครงงานแก้ไขปัญหาให้กับผู้พิการทางสายตา ที่เดินทาง Indoor ได้ลำบาก โดยใช้ Image Processing ร่วมกับโมเดล Text to Speech ของผู้ศึกษาโครงการ AI Builders รุ่นแรกโดยภาพที่ได้จากกล้องที่ติดบนหมวกของผู้พิการทางสายตานำไปประมวลผลกับโมเดลที่เทรนโดย https://www.kaggle.com/datasets/hamzafar/look4me จะได้ทิศทางการเดินที่เป็นไปได้แล้วตอบกลับด้วยเสียง โดยใช้ Thai TTS Tacotron (สามารถเดินตรงไป เลี้ยวซ้ายและเลี้ยวขวาได้) หรืออาจจะรับข้อมูลจากไม้เท้าของผู้พิการทางสายตาว่าชี้ไปทิศทางไหน แล้วให้ตอบกลับว่าทิศทางนั้นเป็นไปได้หรือไม่ และในอนาคตอาจนำไปสานต่อกับการเดิน Outdoor ของผู้พิการทางสายตาบอกถึง ทางม้าลาย ทางเดินเท้าที่เป็นไปได้ หรือยานพาหนะต่างๆ ให้มีความปลอดภัยมากขึ้น\"\n",
      "---\n",
      "date: \"4-8-22\"\n",
      "title: \"Detect and collect COVID-19 data more faster by using ATK-OCR Classification (AOC) model\"\n",
      "builder: \"ธนอนันท์ เฉลิมพันธ์ (เอ็ม)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/55/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Tanaanan/AOC_ATK_OCR_Classification\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/437047961796982\"\n",
      "    blog: \"www.shorturl.at/apGX5\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/55/01.jpg)\n",
      "\n",
      "- Model คัดกรอง และ บันทึกผลตรวจเชื้อ COVID-19 ผ่านที่ตรวจ ATK (Antigen Test Kit) คู่กับ บัตรประชาชน (Identification Card; ตัวอย่างภาพบัตรประชาชน อ้างอิงมาจาก AIForThai) ด้วย Efficientdet_d2 (Object detection) ควบคู่กับ PyThaiNLP (Natural Language Processing),\n",
      "- Dataset ที่ตรวจ ATK ได้จากการทำ Image Scraping ผ่านทาง Web Stock image กับ DuckDuckgo แล้วทำการคัดแยกข้อมูลด้วยมืออีกรอบ (1,500 รูป) ; ส่วนของบัตรประชาชน ใช้ Rules-based programming. (Selection + Edit distance) คู่กับ OCR (Optical Character Recognition) ในการตรวจจับ ชื่อ-นามสกุล และ เลขบัตรประชาชน เนื่องจากไม่สามารถหา Dataset ได้ T T,\n",
      "- ข้อมูลแบ่งเป็น Train set : 1,000 รูป , Validation / Test set : อย่างละ 250 รูป,\n",
      "- เทรนโมเดล Efficientdet_d2 (Object detection) ด้วย Google Colab Pro,\n",
      "- ได้ accuracy และ F1Score ที่ประมาณ 99.51 % บนชุดข้อมูล Validation set และ 94.00 % บนชุดข้อมูล Test set,\n",
      "- ศึกษาคุณภาพโมเดลด้วยให้คนจำนวน 15 คน ทดลองบันทึกผลตรวจ ATK ควบคู่กับ ชื่อ-นามสกุล, เลขบัตรประชาชนด้วยตัวเอง และ ทดลองใช้บน Webapp พบว่ามีประสิทธิภาพที่มากกว่า และ ใช้ระยะเวลาที่น้อยกว่าในการบันทึก และ แยกแยะข้อมูลด้วยตัวเอง,\n",
      "- พบว่าโมเดลยังมีข้อบกพร่องในกรณีที่เป็นตัวอักษร “i” (อักษรไอตัวเล็ก) กับ “l” (อักษรแอลตัวเล็ก) ที่ชื่อ-นามสกุล ของบัตรประชาชน โมเดลยังมีโอกาสตรวจจับผิดพลาดได้อยู่ (เกิดขึ้นสามในสิบครั้งโดยเฉลี่ย) ; แก้ไขได้ด้วยการทำ prediction model อักษร (i, l) [พัฒนาต่อในอนาคต],\n",
      "- ในกรณีที่ที่ตรวจ ATK สีมีความจางมาก หรือ มีแสงรบกวนเข้ามาในรูปภาพ อาจทำให้โมเดลตรวจจับผิดพลาดได้ ; แก้ไขได้โดยการถ่ายภาพใหม่ หรือ เปลี่ยนที่ตรวจ ATK ใหม่ และ หา Dataset เพิ่ม [พัฒนาต่อในอนาคต],\n",
      "- โดยในอนาคตจะพัฒนาให้ใช้ได้ในระบบ Line หรือ Application เพื่อให้โมเดลสามารถใช้งานได้จริงในการคัดกรอง และ บันทึกผลตรวจเชื้อ COVID-19 ในสถานศึกษา หรือ ในหน่วยงานต่างๆในอนาคต, ** ตอนนี้เปิดให้ทดลองใช้บน Webapp [กรณีพบเจอปัญหา หรือ อยากให้คำแนะนำสามารถ report มาใน Webapp ได้เลยย…. O w O\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"แรงบันดาลใจมาจาก ตอนที่ผมได้เข้าร่วมกิจกรรมในงานของ Kidbright AI Bot ครับ ตอนนั้นเป็นครั้งแรกที่ผมได้รู้จักและเข้าใจภาพรวมในเรื่องของ AI และกระบวนการโดยรวมครับ จากพี่ๆที่โครงการมาอบรมให้ครับ ผมเลยได้ลองสร้าง, เทรน model และ เขียนโค้ดที่เป็น AI โดยใช้ Kidbright AI Platform ครั้งแรกโดยการสั่งการให้หุ่นยนต์เดินด้วยเสียงได้ครับ หลังจากนั้นผมจึงมีความคิดที่อยากทำโครงการที่ใช้ AI ในการประมวลผลขึ้นมาจริงๆครับ ผมเคยเข้าร่วมโครงการ Super AI Engineer เมื่อ 2 ปีที่แล้วครับแต่ตอนนั้นผมยังไม่มีพื้นฐานในเรื่องของ Coding กับ Math เลยไม่ผ่านรอบต่อไปที่ทำ AI ครับ หลังจากนั้นผมจึงกลับไปฝึกพื้นฐาน Coding ที่เป็น Python, Pandas, Numpy มาเลยพอมีพื้นฐานระดับนึงแล้วครับ แล้วก็คิดจะลองทำโปรเจคที่เป็น AI ดูแต่ผมก็ไม่ค่อยเข้าใจเลยไม่กล้าทำขึ้นมาทีครับ หลังจากที่ผมรู้ว่ามีโครงการ AI Builder ผมเลยสนใจที่อยากเข้าร่วมโครงการเพราะผมว่าตอนนี้ผมมีความพร้อมมากกว่ารอบที่แล้ว และ ผมมีความมั่นใจมากกว่าที่แล้ว และ ก็ผมคิดว่าถ้าผมได้เข้าทำโครงการนี้จริงๆแล้ว ผมจะได้มีเพื่อนๆ และ พี่ๆที่มีประสบการณ์ในการปรึกษา และ เรียนรู้ได้ครับ  เนื่องจากผมเคยทำ project ที่เขียน coding มาบ้างครับเลยได้รู้จักในเรื่องของ AI ครับแต่ยังไม่เคยทำแบบจริงๆจังๆด้วยตัวเองมาก่อนครับ เพราะ ไม่เข้าใจเรื่องหลักการแบบจริงๆจังๆรู้แต่คร่าวๆครับเคยแต่ใช้ในรูปของ platform ครับ เลยสนใจที่อยากจะเข้าโครงการนี้เพราะจากที่ผมศึกษามามีการสอนพื้นฐานต่างๆ ในการสร้าง AI มี Workshop ต่างๆ ได้ทำและพัฒนาผลงานจริงๆ ผมจึงอยากที่จะเข้าร่วมโครงการครับ  โครงงานที่ผมอยากทำเป็น การตรวจเอกสารยืนยันผลเชื้อของไวรัส Covid 19 ครับ โดยเป็นการ detection จากเอกสารว่า คนๆนี้ ชื่อ นามสกุล ผลตรวจติดเชื้อหรือไม่ ตรวจจากสถานที่ใด โดยสามารถทำได้ 2 แบบ 1. ส่งไฟล์ รูปภาพเข้ามาในระบบ กับ 2.ในสถานที่จริงให้เอาเอกสารยื่นเข้ากล้องให้ตรวจจับ หรือ เป็นตัวที่ตรวจสีขาวที่เป็นขีด โดยแนบคู่กับบัตรประชาชนครับ โดยจะแสดงผลว่าติดเชื้อหรือไม่ และก็จะเข้าระบบใน google sheet เป็น .csv เพื่อใช้ pandas ในการจัดการข้อมูลต่างๆได้ครับ เนื่องจากล่าสุดผมได้คุมสอบของนักศึกษาแพทย์ กสพท โดยที่คนที่จะเข้าสอบมีจำนวนเกือบถึง 5000 คนครับ โดยต้องตรวจสอบเอกสารการตรวจเชื้อของทุกๆคนด้วยตวเอง ทำให้เกิดโอกาสผิดพลาด และ คลาดเคลื่อนสูงครับ ถ้ามีระบบที่เป็น AI วิเคราะห์ได้ก็จะแก้ปัญหาในเรื่องของระยะเวลาในการตรวจเอกสาร, จำนวนของเจ้าหน้าที่คุมสอบ และ สถานการแออัดในสถานที่นั้นๆได้ครับ และ สามารถใช้ได้ทุกสถานที่ เช่น สนามสอบ, สถานศึกษาที่ต้องใช้ตรวจเอกสารผลเชื้อ covid 19 ครับ โดยชุดข้อมูลที่ใช้ในการเทรน หาได้จากใน internet (keyword == เอกสารตรวจโควิด, รูปแบบเอกสาร ผลการตรวจ covid) ส่วนถ้าเป็นเครื่องตรวจก็จะเทรนขีด (keyword == covid antigen test results, ) แสดงผลครับรูปแบบของเครื่องตรวจแบบต่างๆ โดยจะเอารูปแบบของเอกสาร และ เครื่องตรวจให้มีความหลากหลายเพื่อไม่ให้เกิดความผิดพลาดครับ\"\n",
      "---\n",
      "date: \"5-8-22\"\n",
      "title: \"โมเดล CNN สำหรับการจำแนกสัญญาณสมองในระบบ SSVEP-BCI สำหรับไมเกรน (A CNN for Classification Task in SSVEP-BCI for Migraine)\"\n",
      "builder: \"ฆนัท บุญจง (เค)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/56/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/KhanutBJ/Migraine_CNN\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/438384788329966\"\n",
      "    blog: \"https://medium.com/@vwgprvvtsf/showcase-120bc69fb720\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/56/01.jpg)\n",
      "\n",
      "- แรงบันดาลใจจากความสนใจในการทำวิจัยทางการแพทย์และชีววิทยา; ไมเกรนเป็นโรคที่ส่งผลกระทบต่อประชากรถึง 10% โดยไม่เลือกเพศและอายุ,\n",
      "- โมเดลจำแนกคลื่นสมอง EEG (electroencephalogram) ของผู้ป่วยไมเกรนที่เกิดจาก SSEVP (steady state visually evoked potentials) หรือการให้ผู้ป่วยดูภาพ/เสียงและบันทึกคลื่นสมองผ่าน BCI (brain-computer interface),\n",
      "- ใช้ชุดข้อมูลคนเป็มไมเกรน 17 คนและไม่เป็นไมเกรน 18 คนจากงานวิจัย Zar et al (2020; https://kilthub.cmu.edu/articles/dataset/Ultra_high-density_EEG_recording_of_interictal_migraine_and_controls_sensory_and_rest/12636731),\n",
      "- ใช้ 60 Hz notch filter เพื่อลด noise ในข้อมูลสัญญาณ; ใช้ sampling rate ที่ 512 Hz และทดลองแยกแยะสัญญาณด้วย window 30 และ 4 วินาที; แบ่ง train-valid-test ที่ 64:16:20,\n",
      "- ใช้สถาปัตยกรรม EEGNet ในการเทรน; โมเดลประกอบด้วย 2D convolution, depthwise 2D convolution และ separable 2D convolution layers; https://arxiv.org/abs/1611.08024,\n",
      "- สำหรับ window 30 วินาที ได้ accuracy ดีกว่า SVM (51.4%) และ XGBoost (54.8%) ที่ 74% และ 87.5% สำหรับ window 4 วินาที\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"\"เนื่องจากผมเป็นคนที่สนใจและถนัดในชีววิทยา ที่ผ่านมาจึงเข้าร่วมการแข่งขันทางวิชาการหลายๆอย่างทั้งโอลิมปิกวิชาการ ตอบปัญหาชีววิทยา/การแพทย์ และได้ทำโครงงานที่เกี่ยวกับการตรวจคัดกรองทางการแพทย์ จึงยังไม่ได้มีโอกาสทำโครงงาน ML หรือโคดดิ้ง แต่จากประสบการณ์ในการเรียนวิชานี้ ทำให้ผมมีความเข้าใจในระบบต่างๆทางชีววิทยา และพบว่ากลไก ปฏิกิริยาทางเคมีต่างๆ ล้วนสามารถศึกษาได้โดยใช้การวิเคราะห์ ข้อมูล เชิงชีววิทยา หรือที่เรียกว่า Bioinformatics เมื่อไม่นานมานี้ผมจึงได้เริ่มศึกษาการสร้างโมเดล QSAR เพื่อหาความสัมพันธ์ของโครงสร้างทางเคมีของโมเลกุลกับ bioactivity โดยใช้ ML เข้ามาทำนายข้อมูล ซึ่งถือว่าเป็นการที่ผมได้ self-study เกี่ยวกับ ML ด้วยตัวเองครั้งแรก ถึงแม้จะเป็นการหยิบยืมโค้ดเพื่อให้เข้าใจการใช้ ML ในเบื้องต้น แต่อย่างไรก็ตาม ผมคิดว่า ยังมีส่วน algorithm ของ model ที่ยังไม่เข้าใจมากนัก และไม่รู้จะนำไป apply ต่ออย่างไร .. ดังนั้นผมจึงต้องการที่จะหาโอกาสที่จะเรียนรู้ในเรื่องนี้อย่างลึกซึ้ง และมั่นใจว่าเราจะได้ประโยชน์จากจุดนี้ และสามารถทำให้เกิดประโยชน์ต่อไปได้ เช่น project ที่ช่วยพัฒนายา หรือ วิเคราะห์ข้อมูลทางชีวภาพต่างๆ\",  นอกจากนี้คือ ผมกำลังทำงานวิจัยเกี่ยวกับ Molecular Dynamics Simulation โดยมีอาจารย์จาก KMUTT เป็นที่ปรึกษา ซึ่งการทำงานนี้เป็นส่วนของ Computational Biophysics ที่ต้องอาศัยการเขียนโปรแกรมเข้ามาช่วยวิเคราะห์โครงสร้าง DNA ผมจึงจะได้มีโอกาสทำงานใช้ ภาษา python และคิดว่า ML อาจสามารถนำมาประยุกต์ใช้ในงานได้ไม่มากก็น้อย  สาเหตุที่ผมอยากเข้าโครงการ คือ การที่ AI และ Machine Learning จะเข้ามามีบทบาทความสำคัญในอนาคตเป็นอย่างมาก ไม่ว่าจะเป็นในเชิงการแพทย์ วิศวกรรม การทำธุรกิจ ฉะนั้น การเรียนรู้ทักษะการเขียนโปรแกรมเพื่อพัฒนา AI เบื้องต้นจึงจะเป็นทักษะที่จำเป็น ยิ่งไปกว่านั้นคือ การหาประสบการณ์ในการทำ AI เพื่อนำมาใช้แก้ปัญหาจริง จะช่วยให้เห็นแนวทางที่จะนำไปต่อยอดเพื่อให้เกิดประโยชน์ในอนาคตมากยิ่งขึ้นไป โดยผมเห็นว่าโครงการนี้สามารถตอบโจทย์ เพราะถ้าได้เข้าร่วมผมจะได้ผู้เชี่ยวชาญคอยชี้แนะและสอนการทำงานในสายนี้จริงๆ ซึ่งอาจทำให้เราได้เรียนรู้ในสิ่งที่ลึกกว่าการเรียนจากแหล่งข้อมูลทั่วไปในอินเตอร์เน็ต นอกจากนี้ ผมยังเห็นว่า การเข้าโครงการจะช่วยให้เรามี connection กับเพื่อนที่สนใจใน AI เหมือนกัน และรู้จักกับอาจารย์ต่างๆ ซึ่งจะเป็นประโยชน์มาก เพราะอาจช่วยให้ผมมีโอกาสได้ partner ทำงานวิจัย หรือทำธุรกิจเทคโนโลยีที่ได้สร้างจากประสบการณ์การเข้าร่วมโครงการและการศึกษาต่อเพิ่มเติม\"\n",
      "---\n",
      "date: \"6-8-22\"\n",
      "title: \"PsychNLP: A BERT-based NLP model as a screening tool to help classify the risks of depression and suicide\"\n",
      "builder: \"พลกฤต สาตสิน (เจ)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/57/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/urseamajoris/PsychNLP\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/441008288067616\"\n",
      "    blog: \"https://medium.com/@urseamlaccs/psychnlp-part-1-d8180740c0ec\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/57/01.jpg)\n",
      "\n",
      "- โมเดลแยกแยะข้อความ depression, suicidal และ neither จากข้อความในกระทู้ออนไลน์; อยู่ในขั้นตอนการศึกษา ไม่สามารถนำไปวินิฉัยโรคได้จริง โปรดใช้วิจารณญาณในการรับชม,\n",
      "- แรงบันดาลใจจากจับใจและสายใจ บอทคัดกรองภาวะซึมเศร้าของโรงพยาบาลศิริราช,\n",
      "- เก็บข้อมูลจากกระทู้ Reddit ที่มีข้อความยาวกว่า 32 ตัวอักษรต่อประโยคด้วย Python Reddit API Wrapper (PRAW) และ PushshiftAPI รวมประมาณ 400,000 ประโยค; ทำความสะอาดด้วยการลบ emoticon, ปรับเป็น lowercase, ลบสัญลักษณ์ต่างๆ ฯลฯ,\n",
      "- แยก label ตาม subreddit คือ depression จาก r/depression, suicidal จาก r/SuicideWatch และ neither จาก r/offmychest (คนมาโพสระบายเฉยๆไม่ได้ระบุว่าต้องมีอาการ); มีจำนวนแต่ละ label เท่าๆกัน,\n",
      "- ปรับจูนสถาปัตยกรรม all-distilroberta-v1 ที่เป็น sentence embeddings (768 dimensions) แล้วเพิ่ม classification head เพื่อจำแนกประเภทข้อความ,\n",
      "- ได้ผลใกล้เคียงกับ baseline ที่เป็น tf-idf + LinearSVC ที่ F1 0.548 (vs 0.584) และ accuracy 62.7% (vs 58.8%),\n",
      "- จากการวิเคราะห์พบว่าสาเหตุใหญ่มาจากข้อความใน r/depression และ r/SuicideWatch มีความคล้ายคลึงกันแม้ตัดสินด้วยมนุษย์,\n",
      "- สามารถปรับไปใช้กับ Discord Bot ได้ด้วย\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมสนใจแพทยศาสตร์เป็นหลัก และตอนนี้ AI ก็มีความน่าสนใจเท่ากัน ผมเคยศึกษางานวิจัยจากรามาธิบดีเวชสารมาพอสมควร และพบว่า ยังมีสิ่งที่ผมสามารถต่อยอดจากการเอาทั้ง 2 แขนงมารวมกันได้อีกมาก ผมได้กล่าวไปในจดหมายที่ส่งให้คณะแพทยศาสตร์โรงพยาบาลรามาธิบดี และผมจะกล่าวไว้ที่นี่เช่นกัน ว่าผมมีจุดมุ่งหมายจะนำทั้ง 2 แขนงนี้มาสร้างประโยชน์ให้สังคม นี่เป็นเหตุที่ผมตัดสินใจสมัคร AI Builders และเป็นเหุผลที่ท่านควรรับผมเข้าโครงการครับ  เมื่อช่วง lockdown ปี 2564 ผมมาเริ่มสนใจการเขียนโปรแกรม เริ่มเรียน python ด้วยตัวเองประมาณ 2 เดือน ต่อมาเห็นเพื่อนที่เรียนมาด้วยกันทำโครงงาน CNN พยากรณ์อาการลมชักจากสัญญาณ EEG ผมก็เลยเข้ามาสนใจในงาน AI มากขึ้น ใช้เวลาอีก 2 เดือนเรียน Tensorflow จนพอมีพื้นฐานบ้าง แต่ผมเรียนทุกอย่างด้วยตัวเอง ไม่เคยได้มีโอกาสที่ได้รับหลักสูตรในสายนี้จาก Lectures เลย ผมเห็นว่า AI Builders เป็นโอกาสให้ผมได้มีประสบการณ์ในด้าน AI อย่างเป็นทางการ ให้ผมได้เรียนรู้และพบปะคนอื่นที่มีความสนใจตรงกับผม และทำ projects เพื่อเพิ่มประสบการณ์ที่จะกลับมาพัฒนาในสิ่งที่เป็นประโยชน์สูงสุดครับ\"\n",
      "---\n",
      "date: \"7-8-22\"\n",
      "title: \"My Little HR: โมเดลประเมินเงินเดือนอาชีพสาย IT ในประเทศไทย\"\n",
      "builder: \"กันตพงศ์ วงศ์พานิชย์ (เติร์ด)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/58/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/JustAnotherTunaInTheSea/LittleHR-Thai-IT-Salary-Estimator\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/442411951260583\"\n",
      "    blog: \"https://medium.com/@kantapong.vong/%E0%B8%A1%E0%B8%AB%E0%B8%B2%E0%B8%81%E0%B8%B2%E0%B8%9E%E0%B8%A2%E0%B9%8C%E0%B9%82%E0%B8%A1%E0%B9%80%E0%B8%94%E0%B8%A5%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B9%80%E0%B8%A1%E0%B8%B4%E0%B8%99%E0%B9%80%E0%B8%87%E0%B8%B4%E0%B8%99%E0%B9%80%E0%B8%94%E0%B8%B7%E0%B8%AD%E0%B8%99%E0%B8%AD%E0%B8%B2%E0%B8%8A%E0%B8%B5%E0%B8%9E%E0%B8%AA%E0%B8%B2%E0%B8%A2-it-%E0%B9%83%E0%B8%99%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B9%80%E0%B8%97%E0%B8%A8%E0%B9%84%E0%B8%97%E0%B8%A2-c2743d96d164\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/58/01.jpg)\n",
      "\n",
      "- โมเดลประเมินเงินเดือนอาชีพสาย IT ในประเทศไทยจากข้อมูลคนทำงาน,\n",
      "- แรงบันดาลใจจากโปรแกรมเมอร์หรือคนทำงานสาย IT ที่จบใหม่แล้วถูกกดเงินเดือนค่อนข้างมาก หรือคนที่ทำงานไปแล้วตั้งคำถามกับตัวเองว่างานที่ทำอยู่ค่าตอบแทนเหมาะสมรึเปล่า ซึ่งเป็นคำถามทั่วไปที่ตอบได้ยาก เพราะเราไม่รู้ว่าเงินเดือนของคนอื่นๆที่มีทักษะ ประสบการณ์ หรือตำแหน่งงานแบบเดียวกับเรา ได้ค่าตอบแทนเท่าไรหรือควรจะได้เท่าไร ถ้าไม่มีแหล่งข้อมูลที่มากพอหรือเวลาที่ใช้ในการหาข้อมูลเหล่านั้น ก็ไม่สามารถตอบได้อย่างมั่นใจเท่าไร,\n",
      "- พบ Thailand IT Salary Rates ซึ่งเป็นการประเมินเงินเดือนจากคนทำงาน 1,704 คนด้วย linear regression 7 ตัวแปร จึงใช้เป็น baseline ในการต่อยอด,\n",
      "- สร้างชุดข้อมูลจากการตอบแบบสอบถามสมาชิกกลุ่มหลังบ้านายอาร์ม ได้ 368 คน แบ่งเป็น train-valid-test ที่ 64:16:20,\n",
      "- ทำความสะอาดข้อมูลด้วยการรวบประเภท เช่น จังหวัด->[กรุงเทพ, อื่นๆ], ระดับการศึกษา->[ต่ำกว่าป.ตรี, ป.ตรี และสูงกว่าป.ตรี], ลบ outlier ของเงินเดือนที่สูงเกินความเป็นจริง, ลบ feature ที่ส่งสัญญาณต่อเงินเดือนน้อย เช่น อายุ, ประเภทการจ้างงาน, ภาษาโปรแกรมมิ่งที่เคยใช้, และสร้าง feature ใหม่จากข้อความอธิบายอาชีพ,\n",
      "- โมเดลใช้ 51 features จาก 6 หัวข้อใหญ่ คือ วุฒิการศึกษาสุดท้าย, จังหวัดที่ทำงานอยู่, ประสบการณ์การทำงานในองค์กร, ประสบการณ์การเขียนโปรแกรม/ฝึกฝนทั้งหมด, ขนาดองค์กรนับตามจำนวนพนักงาน, รายละเอียดตำแหน่งงานที่ทำ,\n",
      "- ใช้ AutoGluon ซึ่งเป็น open source AutoML ในการหาโมเดลที่ดีที่สุดจาก CatBoost, LightGBMLarge, LightGBMXT และ NeuralNetFastAI และทำ weighted ensemble ด้วย ridge regression,\n",
      "- ได้ผลดีกว่าโมเดล baseline คือ MAE 17798.86 (-21.83%), MSE 52472.00 (-52.78%); ตีความได้คร่าวๆว่าโมเดลประเมินคลาดเคลื่อนโดยเฉลี่ย 17,798 บาทต่อเดือน (มากที่สุดคือ 63,478 บาท น้อยที่สุด 756 บาท)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมมีประสบการณ์ทำ Project ต่างๆ ไม่ว่าจะเป็น Web App,Desktop/Mobile App,IoT,Game Dev,Networking,Image/Signal Processing ผมจึงมีทักษะในการเขียนโปรแกรมด้วยหลายภาษารวมถึง Python ทำให้ผมสามารถเรียนรู้การสร้าง AI ได้เร็ว สามารถนำไปปรับใช้กับความรู้ที่มี และพัฒนาออกมาเป็น product ที่ใช้งานได้จริง  ในโลกของเทคโนโลยีจะมีการเปลี่ยนแปลงเกิดขึ้นตลอดเวลา ซึ่งตอนนี้ AI เป็นเทคโนโลยีใหม่ที่มีศัยภาพที่น่าสนใจเป็นอย่างมาก ผมที่ชื่นชอบการแข่งขันและทำงานวิจัยเพื่อพัฒนาศักยภาพของตนเอง อยากที่จะเข้าร่วมโครงการ AI Builder เพื่อที่จะศึกษาขอบเขตความสามารถ และการพัฒนา AI เพื่อใช้ในงานวิจัยของผมต่อไปในอนาคต  ผมชอบการเป็น Content Creator และ Game Dev แต่ดนตรีประกอบมีผลสำคัญอย่างมากกับสื่อทั้งสองประเภท และการแต่งเพลงขึ้นใหม่จะใช้เวลาและเงินทุนมาก ทำให้ผู้พัฒนาทุนน้อยไม่สามารถทำได้ ทำให้ผมอยากพัฒนา AI ที่สามารถ Generate ดนตรีประกอบคลิปวีดีโอหรือเกมออกมาได้ โดยใช้ Dataset เป็นจาก Github และ Kaggle\"\n",
      "---\n",
      "date: \"8-8-22\"\n",
      "title: \"GANime-FullBody วาดรูปตัวละครอนิเมะ(สาวๆ)แบบเต็มตัว ด้วย Deep Learning\"\n",
      "builder: \"หิรัญกุล พิมพ์ศิริ (ไกด์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/59/01.jpg\"\n",
      "links:\n",
      "    github: \"https://hrnph.github.io/GANime-FullBody/\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/445888770912901\"\n",
      "    blog: \"https://medium.com/@hrnph/%E0%B8%A7%E0%B8%B2%E0%B8%94%E0%B8%A3%E0%B8%B9%E0%B8%9B%E0%B8%95%E0%B8%B1%E0%B8%A7%E0%B8%A5%E0%B8%B0%E0%B8%84%E0%B8%A3%E0%B8%AD%E0%B8%99%E0%B8%B4%E0%B9%80%E0%B8%A1%E0%B8%B0%E0%B8%AA%E0%B8%B2%E0%B8%A7%E0%B9%86-%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B9%80%E0%B8%95%E0%B9%87%E0%B8%A1%E0%B8%95%E0%B8%B1%E0%B8%A7-%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2-deep-learning-ganime-fullbody-9b3822e58934\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/59/01.jpg)\n",
      "\n",
      "- โมเดล Generative Adversarial Network (GAN) สำหรับสร้างรูปวาดตัวละครสาวน้อยอนิเมะ; แรงบันดาลใจจากความชื่นชอบในอนิเมะและประสบการณ์ในการทำเกมที่จำเป็นต้องออกแบบตัวละครใหม่เรื่อยๆ จึงคิดว่าน่าจะสะดวกขึ้นหากมีโมเดลที่สร้างสาวน้อยอนิเมะออกมาให้เลือกปรับใช้กับทั้งเกม, ไลท์โนเวล, รูปประกอบ ฯลฯ,\n",
      "- เลือกใช้ GAN มากกว่า Variational Autoencoder (VAE) เนื่องจากได้ภาพที่คมชัดกว่า; ด้วยข้อจำกัดทางเวลาและทรัพยากร ตั้งเป้าสร้างรูปขนาด 32², 64² หรือ 128² pixels,\n",
      "- สร้างชุดข้อมูลขึ้นมาเองด้วยมาตรฐานว่ารูปต้อง 1) ไม่มีพื้นหลัง (ขาวล้วน) 2) ลายเส้นและลักษณะตรงความต้องการ (เต็มตัว, ลายเส้นญี่ปุ่น, ตัวละครหญิง) 3) ชุดข้อมูลที่มีขนาดใหญ่ เนื่องจาก GAN ต้องใช้ชุดข้อมูลจำนวนมาก (10k ++),\n",
      "- เปรียบเทียบแหล่งข้อมูลที่จะรวบรวมมาเพื่อสร้างชุดข้อมูลหลายแห่ง เช่น Getchu ที่ปริมาณและคุณภาพดีที่สุดแต่การเชื่อมต่อไม่เสถียรพอ, Gelbooru ที่ปริมาณและคุณภาพดีเช่นกันแต่เต็มไปด้วยรูป 18+ จึงลงท้ายที่ Safebooru ซึ่งเป็น Gelbooru เวอร์ชั่นที่คัดรูป 18+ ออกแล้วโดยใช้แท้ก full_body solo, standing, 1girl, white_background เพื่อให้ได้รูปสาวน้อยอนิเมะเต็มตัวพื้นหลังสีขาว,\n",
      "- ทำความสะอาดข้อมูลด้วยการคัดรูปต่อไปนี้ออก 1) ตัวละครจิบิ (หัวโตตัวเล็ก) 2) ภาพที่มีมากกว่า 1 ตัวละคร 3) พื้นหลังสีฉูดฉาด/ท่ายืนแปลกๆ; โดยตัวละครจิบิเป็นรูปประเภทที่ไม่ต้องการที่เยอะที่สุด,\n",
      "- ทำโมเดลคัดแยกรูปที่ไม่ต้องการด้วย ResNet34 2 โมเดลคือ Chibi(~1k datasets) และ More Than 1(~0.3k datasets) ได้ผลอย่างดีเยี่ยม F1 0.96-0.98; เหลือชุดข้อมูลหลังทำความสะอาดแล้ว 12k รูป,\n",
      "- ขั้นตอนการเทรนเริ่มจากใช้ DCGAN พบว่า generator (โมเดลสร้างภาพปลอม) แทบไม่ได้เรียนรู้เลยเพราะ discriminator (โมเดลจับว่าภาพจริงหรือปลอม) เรียนรู้เร็วจนเกินไป คาดว่าปัญหาเกิดจาก vanishing gradients ของ BCE Loss ที่ใช้กับ discriminator จึงเปลี่ยนมาใช้ Wasserstein Loss และเพิ่ม gradient penalty เพื่อไม่ให้ loss ลดลงใกล้ 0 เร็วจนเกินไป,\n",
      "- จากนั้นปรับปรุงสถาปัตยกรรมโดยเปลี่ยนจาก DCGAN มาใช้ Progressive GAN ที่จะค่อยๆจับ Feature ที่ความละเอียดต่ำๆก่อน ในภาพ 4² เมื่อคุ้นชินแล้วก็จะเริ่มปรัปความละเอียดในสูงขึ้น เป็น 8² แล้วค่อยๆเพิ่มไปเรื่อยๆ จนถึง Scaling เป้าหมาย ที่ 128²,\n",
      "- เพิ่มประสิทธิผลของ generator อีกขั้นโดยการปรับใช้เทคนิคจาก StyleGAN คือ 1) Mapping Network จัดเรียง Random Noise ให้มีรูปแบบ 2) Adaptive Instance Normalization (AdaIN) เพื่อทำ style transfer; StyleGAN ได้ผลดีพอๆกับ Progressive GAN โดยใช้เวลาที่สั้นกว่า; เทรนโมเดลด้วยสถาปัตยกรรมและชุดข้อมูลนี้ เรียกว่า Model A,\n",
      "- เมื่อสถาปัตยกรรมเป็นที่พอใจแล้วกลับไปทำความสะอาดข้อมูลอีกรอบ เนื่องจากพบว่ารูปที่มี effect หรือชุดอลังการงานสร้างเกินไปจะทำให้โมเดลเรียนรู้ได้ยาก; ใช้ ResNet50 ในการคัดแยกรูปที่ต้องการและไม่ต้องการ โดยเทรนจากข้อมูลกำกับเองด้วยมือ 500 รูป, ได้ผลไม่ดีนัก (precision 0.4) ทำให้ข้อมูลถูกทำความสะอาดไปเหลือเพียงประมาณ 5 พันรูป,\n",
      "- ลองเทรน Model B บนข้อมูล 5 พันรูปนั้นแล้วพบว่าความสวยงามเป็นที่น่าพึงพอใจแม้ปริมาณรูปจะลดลงเกินครึ่ง,\n",
      "- ใช้ Fréchet inception distance (FID; ยิ่งน้อยยิ่งดี) ในการวัดผลเทียบรูปที่สร้างจาก Model A กับ Model B อย่างละ 1 หมื่นรูปกับรูปจริง พบว่า Model B ทำได้ดีกว่าเกือบเท่าตัว (data-centric มั้ยละคุณ!),\n",
      "- แม้จะมีผลลัพท์ที่ออกมาน่ากลัวอยู่บ้าง แต่โดยรวมแล้วผลลัพท์ที่ออกมา ถือว่าน่าพึงพอใจ โมเดลสามารถจับดีเทลขาได้อย่างสวยงาม ชุดที่ถูกลักษณะ ร่างกายที่สมส่วน และยังพยายามเติมหน้าเข้าไปในทุกๆโมเดล; สิ่งที่จะพัฒนาต่อหลังจากนี้คือ 1) การทดลองปรัป Noise ของโมเดล และทดสอบ Latent W เพื่อหา Style แต่ละส่วน 2) การทำให้ภาพชัดขึ้นที่ 256² 3) การหา Datasets ที่ดีขึ้นเพื่อเพิ่มคุณภาพของโมเดล 4) การ Deploy ที่ผู้ใช้สามารถปรัป Style ของรูปได้,\n",
      "- เปิดชุดข้อมูลลิขสิทธิ์การรวบรวมเป็น open source ที่: https://www.kaggle.com/datasets/hirunkulphimsiri/fullbody-anime-girls-datasets,\n",
      "- เปิด Docker Image สำหรับ deploy API เป็น open source ที่: https://gallery.ecr.aws/z1f5v2y8/ganime-fullbody/model0\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมไม่ค่อยเข้าร่วมกิจกรรมมากนัก เพราะพวกกิจกรรมที่มีมาบ่อยๆ ไม่ค่อยน่าสนใจ เช่นพวก open house หรือ แคมป์เสียเงินต่างๆ ผมชอบนั่งเรียนไปเรื่อยๆมากกว่า ดู Tutorials นั่นนี่แล้วก็ลองทำอะไรไปเรื่อยๆ ถ้าเวลาว่างๆ ผมก็จะไปตอบคำถามให้คำปรึกษาที่กลุ่มเฟสบุ๊ค/ดิสคอร์ด programming ครับ ได้ทบทวนความรู้ด้วย ได้ช่วยคนอื่นด้วย ผมว่าแบบนี้มันดีกว่าเยอะ ไม่ว่าใครจะว่ายังไง อันนี้ถือเป็นกิจกรรมที่ผมดีใจที่ได้ทำครับ  เพราะผมสนุกครับ สนุกกับการเรียนอะไรใหม่ๆ เรียนเรื่องที่ยังไม่เข้าใจ ได้แบ่งปันงานของตัวเองให้คนอื่นเอาไปพัฒนาต่อ หลักๆคือ เพราะว่ามันน่าสนุกผมเลยสมัครเข้ามา พอได้รู้อะไรมากขึ้นก็สอนคนอื่นได้มากขึ้นด้วย อีกอย่างคือผมอยากออกจากโลกแคบๆ อยากไปเจอคนใหม่ๆ ผมกังวลนความสามารถตัวเองมาตลอด ผมเลยอยากสร้างอะไรเจ๋งๆ ผมอยากพิสูจน์ตัวเอง ให้ตัวเองเห็นครับ\"\n",
      "---\n",
      "date: \"9-8-22\"\n",
      "title: \"Find Water from Satellite Images Using U-Net Image Segmentation with Pytorch\"\n",
      "builder: \"วรกาญจน์ ลาสุดี (ปีใหม่)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/60/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/19xx47/Find-water-AI-builders-project\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/447914850710293\"\n",
      "    blog: \"https://medium.com/@worakan.lasudee/found-water-from-satellite-images-by-segmentation-using-u-net-with-pytorch-7b3b0a8abf1d\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/60/01.jpg)\n",
      "\n",
      "- โมเดล semantic segmentation สำหรับหาแหล่งน้ำจากรูปถ่ายดาวเทียมโดยใช้ U-Net,\n",
      "- เทรนบนชุดข้อมูล Satellite Images of Water Bodies จาก Kaggle ซึ่งประกอบด้วยสองประเภทคือ Images และ Mask ซึ่งมีจำนวนข้อมูลทั้งหมด 2841 รูป,\n",
      "- สถาปัตยกรรม U-net เป็น CNN (convolutional neural networks) ที่แบ่งออกเป็นสองประเภทคือ Encoder และ Decoder ในส่วนของ Encoder เป็นการแปลงขนาดของ Input ให้มีขนาดเล็กลงแต่มี Channel ที่มากขึ้น นั่นคือเครือข่ายสามารถเรียนรู้ ความสัมพันธ์ที่ซับซ้อนได้มากขึ้นในภาพ Decoder มีโครงสร้างสถาปัตยกรรมเหมือนกับ Enconder ซึ่งทำหน้าที่แปลงขนาดภาพให้เป็นขนาดเดิม ใช้ Loss เป็น BCE-Dice Loss,\n",
      "- เลือกทำ U-net ด้วย Pytorch เพื่อนำมาเปรียบเทียบ U-net ด้วย Tensorflow เพื่อหา Model ที่มีประสิทธิภาพมากที่สุด เนื่องจากทั้งสองตัวต่างก็เป็น deep learning framework ที่เป็นที่นิยมเหมือนกัน แต่ Pytorch นั้นเรียนรู้ได้ง่ายเพราะมี document ที่อ่านได้เข้าใจง่าย มีชุมชนที่ใช้ในงานวิจัยเยอะและมีเครื่องมือ debugging มากมาย ส่วน Tensorflow นั้นแม้จะไม่มี debugging ที่ดีและชุมชนกระตือรือล้นเหมือน Pytorch แต่ Tensorflow เหมาะสำหรับการพัฒนาใน production environment และยังสามารถทำ data visualization ได้ง่ายกว่า Pytorch มาก,\n",
      "- ทดลอง Optimizer เป็น RMSProp, Adam และ NAdam ด้วย pretrained U-Net จาก Pytorch และ Tensorflow พบว่า Pytorch U-Net และ Adam ทำความแม่นยำระดับ pixel ได้ดีที่สุดที่ 80.7% บน test set\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผลงานเกี๋ยวกับ AI 1. Model ทำนายการเสื่อมสภาพของดินเป็นผลให้ได้เป็นตัวแทนเข้าร่วมนำเสนอผลงานที่จัดโดยประเทศเกาหลี 2. Machine Learning ตรวจจับรูปร่างวัตถุโดยใช้กล้องตรวจจับในการแข่งขันหุ่นยนต์ ได้รับรางวัล Control Award และ Winner Award แรงบันดาลใจคือโครงงานที่อยากทำค่ะเป็นผลให้เข้าร่วมกิจกรรมอบรม AI ของ Microsoft และ AWS  ชื่นชอบและสนใจปัยญษประดิษฐ์มากยิ่งเหตุมีข่าวเกี่ยวกับค่าย AI ตั้งแต่ต้นปีก็ตั้งหน้าตั้งตารอวันที่ค่ายเปิดรับสมัครเลยค่ะ หนูเคยเข้าร่วมค่ายวิทยาศาตร์และมีโอกาสได้ทำงานเกี่ยวกับการทำนายของ Model แต่หนูไม่ได้เข้าใจมันทั้งหมดตอนนั้นที่ทำได้เพราะนำโค้ดที่มีอยู่แล้วมาเปลี่ยน dataset แล้วก็แก้นิดหน่อย สิ่งที่หนูจะบอกก็คือหนูอยากเข้าใจกระบวนการ algorithm ของ AI จริงๆค่ะ ถ้าหนูได้เข้าใจ algorithmของAI จริงๆแล้วหนูจะสามารถต่อยอดโครงงานให้เป็นจริงได้ค่ะ  การสร้าง Model วิเคราะห์และบอกประเภทของโรคหัวใจจากเสียงของจังหวะการเต้นและกราฟคลื่นไฟฟ้าของหัวใจโดยใช้การวิเคราะห์เชิงลึก (Big data) ประยุกต์ร่วมกับปัญญาประดิษฐ์ (AI)\"\n",
      "---\n",
      "date: \"10-8-22\"\n",
      "title: \"Emotion Detection from Facial Micro-experessions\"\n",
      "builder: \"ครองภพ มั่นคง (ไบรท์)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/61/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/Doraminn/Micro-expression/\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/449331850568593\"\n",
      "    blog: \"https://medium.com/@brightkorn132/%E0%B9%80%E0%B8%88%E0%B9%87%E0%B8%9A%E0%B9%81%E0%B8%84%E0%B9%88%E0%B9%84%E0%B8%AB%E0%B8%99%E0%B8%81%E0%B9%87%E0%B8%95%E0%B9%89%E0%B8%AD%E0%B8%87%E0%B8%9D%E0%B8%B7%E0%B8%99%E0%B8%A2%E0%B8%B4%E0%B9%89%E0%B8%A1%E0%B8%A7%E0%B9%88%E0%B8%B2%E0%B9%84%E0%B8%A1%E0%B9%88%E0%B9%80%E0%B8%9B%E0%B9%87%E0%B8%99%E0%B9%84%E0%B8%A3-42c31e7cfdc1\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/61/01.jpg)\n",
      "\n",
      "- โมเดลตรวจจับอารมณ์เสี้ยววิหรือ Micro-expressions (Anger, Contempt, Happniess, Others, Surprise) จากรูปหน้า,\n",
      "- Micro-expression เป็นการแสดงอารมณ์ที่รู้สึกจริง ๆ แต่ต้องโกหกเอาไว้ และเกิดขึ้นเร็วมากจนมนุษย์ทั่วไปไม่สามารถรับรู้ได้เลย ถ้าสมมติมีโมเดลที่สามารถตรวจและระบุอารมณ์นี้ได้อย่างแม่นยำ ก็จะสามารถจับอารมณ์ที่โกหกอยู่ได้และมีประโยชน์เป็นอย่างมากเช่นการจับโกหกในการนำไปเป็นพยานหลักฐานของสืบสวนคดีต่าง ๆ,\n",
      "- ใช้ชุดข้อมูล SAMM dataset ประกอบไปด้วยรูปภาพที่แคปมาจากวิดีโอที่ถ่ายด้วยกล้องความเร็ว 200 fps มีทั้งหมด 29 subjects 159 samples แต่ละ sample มีรูปประมาณ 30-100 รูป,\n",
      "- ดูตัวอย่าง micro expression ได้ที่ https://www.facebook.com/aibuildersx/videos/1455685481578809,\n",
      "- ชุดข้อมูลมี 7 อารมณ์ ได้แก่ Happiness, Sadness, Anger, Disgust, Contempt, Fear และ Other แต่ Sadness, Fear และ Disgust มีจำนวนรูปน้อยเกินไปจึงตัดออกเพื่อป้องกัน label imbalance,\n",
      "- แต่ละเฟรมของชุดข้อมูลถูกจดไว้ว่าเป็น Onset frame (หมายเลขเฟรมที่เริ่มอัดคลิป), Apex frame (หมายเลขเฟรมที่เป็นจุดพีคของการเกิด micro-expression), Offset frame (หมายเลขเฟรมที่จบการอัดคลิป) และ Duration (จำนวนเฟรมที่จับได้ ซึ่งสอดคล้องกับจำนวนรูปในไฟล์),\n",
      "- จัดการแปลงรูปเพื่อเข้าสู่โมเดล 4 รูปแบบคือ 1) Original Apex frame — ใช้เฟรม ณ จุด Apex มาเป็น input 2) Difference of Apex frame and Onset frame — เนื่องด้วยเราได้แปลงข้อมูลภาพของเราเป็นตัวเลขเมื่อนำเข้าโมเดล จึงลองเอาผลต่างของ Apex กับ Onset มาเป็น input เพื่อแสดงว่าภาพตอนพีคกับตอนเริ่มต่างกันยังไง 3) Optical flow of Apex frame and Onset frame — เปลี่ยนจากผลต่างตัวเลขของ 2 เฟรมมาเป็น Optical flow ซึ่งก็คือแพทเทิร์นการขยับของภาพ โดยจะแสดงเป็นกลุ่มการไหลของแสง 4) Optical flow of Apex frame and Onset frame + Original Apex frame — คือการนำทั้ง Optical flow เมื่อกี้และภาพของ input แบบที่ 1 มารวมกันและนำไปเป็น input,\n",
      "- เลือกใช้ ResNet-18 ที่ pretrained มาจาก EfficientFace ซึ่งเทรนมาจาก MS-Celeb-1M และมีจำนวน class มากถึง 12,666 คน,\n",
      "- สร้างแบบทดสอบ 10 หน้าจากรูปที่ไม่ได้ใช้เทรนโมเดล โมเดลตอบถูก 6 จาก 10 ข้อเทียบกับมนุษย์ 29 คนที่ตอบถูก 2.759 ข้อโดยเฉลี่ย,\n",
      "- ปัญหาที่พบและน่าทำการแก้ไขในอนาคต 1) จำนวนข้อมูลที่มีน้อย 2) ความ Imbalance ของข้อมูลในแต่ละ class 3) sample บางคลิป แทบไม่ขยับหรือขยับน้อยมาก 4) sample บางคลิป มีตำแหน่งหน้า ที่ไม่ตรงกันใน Apex frame กับ Onset frame ทำให้ optical flow ฟุ้งกระจาย\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"ผมเคยมีประสบการณ์ในด้านนี้ตอนแข่ง TMLCC ครับ แต่ว่าก็ยังเป็นแค่สร้างโมเดลเพื่อใช้ในการแข่ง ซึ่งตอนนั้นผมรู้สึกว่ามันเพลินมากตอนสร้างโมเดล อาจจะมีเหนื่อยบ้างนิดหน่อยตอนที่ต้องอ่าน papers ยาว ๆ หลายสิบหน้าที่เกี่ยวกับเคมี แต่เราก็ต้องสู้ครับ! ฮ่าๆ แม้ว่าตอนแก้และรันแต่ละครั้ง accuracy จะขึ้นหรือลง แต่ผมก็รู้สึกสนุกและลุ้นไปกับมันทุกครั้งเลยครับ ถ้าจะให้บอกว่าแรงบันดาลใจในเรื่อง AI ของผมมาจากไหน ก็คงต้องบอกว่ามาจากตัวเองที่มึความสุขกับมันนี่แหละครับ  ตั้งแต่ประถม ผมเริ่มรู้สึกกับตัวเองว่าเรามีความสุขเวลาที่เราสามารถแก้ปัญหาต่าง ๆ ได้ (แน่นอนว่าใครก็ต้องมีความสุขแหละครับที่คิดหาทางแก้ปัญหาออกได้) นั่นจึงทำให้วิชาที่โดดเด่นในเรื่องของการแก้ปัญหาอย่างคณิตศาสตร์เป็นวิชาที่ผมชอบได้อย่างไม่ยากเลยครับ ผมรู้สึกมีความสุขและสนุกที่หาวิธีคิดออกโดยเฉพาะวิธีแปลก ๆ ที่คนอื่นเขาไม่คิดกัน จนม.ต้น ผมได้รู้จักกับการ coding ตั้งแต่ครั้งแรกที่ผมเริ่มโค้ดก็รู้เลยครับว่านี่แหละสิ่งที่เหมาะกับเรา จนมาตอนม.ปลาย ผมก็เริ่มมองตัวเองในอนาคตว่าเราจะทำอะไร ก็หาข้อมูลกับลองเขียนนู่นนี่นั่นเล่นๆ จนผมได้มาเจอกับ AI ความรู้สึกตอนเจอคือแบบเดียวกับตอนม.ต้นเลยครับ ก็รู้เลยว่านี่คือสิ่งที่เรากำลังตามหาอยู่ แต่ตั้งแต่ตอนนั้นผมก็ยังไม่ได้สัมผัสเลยว่า โปรเจค AI จริง ๆ เป็นแบบไหน กระบวนการในการทำโปรเจคที่แท้จริงเป็นอย่างไร จึงอยากเข้าร่วมโครงการนี้เพื่อที่จะได้รับประสบการณ์ในการทำโปรเจคที่เป็นชิ้นเป็นอันและได้รับความรู้ในด้านที่เกี่ยวข้องเพื่อที่จะไปเรียนรู้ต่อและนำมาพัฒนาตนเองขึ้นไปอีกครับ และผมยังอยากหาเพื่อนหรือกลุ่มคนที่สนใจในด้านเดียวกัน จะได้มีคนที่คุยเรื่องพวกนี้ด้วยได้ครับ\"\n",
      "---\n",
      "date: \"11-8-22\"\n",
      "title: \"Automatic E2E Thai Question Generation with MT5\"\n",
      "builder: \"ปรินทพัฒน์ เพ็งพันธุ์ (ปริน)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/62/01.jpg\"\n",
      "links:\n",
      "    github: \"https://parinzee.github.io/ThaiQuestionGenerationMT5/\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/450060740495704\"\n",
      "    blog: \"https://medium.com/@parinzee/studying-let-an-ai-generate-q-as-to-quiz-you-9ef27b1554d\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/62/01.jpg)\n",
      "\n",
      "- โมเดลสร้างคำถาม factoid จากบทความ; แรงบันดาลใจจาการเทคนิคการทบทวนบทเรียนส่วนตัวที่จะเน้นอ่านไวๆแล้วตอบคำถามท้ายบท ปัญหาคือบางคาบเรียน เช่น วิชาประวัติศาสตร์ ไม่มีคำถามท้ายบทให้ จึงทำโมเดลเพื่อสร้างคำถามขึ้นมาเองจากเนื้อหา,\n",
      "- สร้างโมเดล seq2seq ที่ทำงานประมาณนี้:, Input text: สร้าง 2 คำถาม: เฟซบุ๊ก (อังกฤษ: Facebook) เป็นบริการเครือข่ายสังคมสัญชาติอเมริกัน สำนักงานใหญ่อยู่ที่ เมนโลพาร์ก รัฐแคลิฟอร์เนีย เฟซบุ๊กก่อตั้งเมื่อวันพุธที่ 4 กุมภาพันธ์ ค.ศ. 2004, Output text: 1. เฟซบุ๊กคืออะไร A: บริการเครือข่ายสังคมสัญชาติอเมริกัน 2. เฟซบุ๊กก่อตั้งเมื่อไร A: วันที่ 4 กุมภาพันธ์ ค.ศ. 2004,\n",
      "- ใช้ชุดข้อมูล question answering (เอามากลับหัวกลับหางเป็น question generation) ได้แก่ XQuAD, Thai QA (SQuAD version), iapp-wiki-qa-dataset,\n",
      "- ทำความสะอาดข้อมูล เช่น HTML markup, ช่องว่างเกิน 1 ช่อง, วงเล็บที่ว่างเปล่า (ส่วนใหญ่เกิดกับบทความ Wikipedia); พบว่าหนึ่งบทความ (context) จะมีคำถามโดยทั่วไป 1-5 คำถาม,\n",
      "- เลือกใช้ mT5 ผ่าน Shivanandroy/simpleT5 เพื่อปรับจูนกับชุดข้อมูลที่มี; ใส่ seperator tokens (<SEP> และ <ตัวเลข>) ระหว่างคำถามเพื่อไม่ให้โมเดลงงกับการสร้างคำถามหลายข้อ โดยเฉพาะการที่โมเดลสับสนเลขบอกข้อคำถาม (1. xxx 2. xxx) กับเลขทศนิยม (1.2 ล้านคน),\n",
      "- ทำ data augmentation โดยการแตกคำถามสำหรับบทความเดียวกันเป็นหลายตัวอย่าง เช่น บทความที่มี 10 คำถาม แทนที่จะเป็นหนึ่งตัวอย่าง แตกให้เป็น 2 ตัวอย่าง ตัวอย่างละ 5 คำถาม เป็นต้น; ทำให้ได้จำนวนคำถามเพิ่มจาก 4,500 ข้อเป็น 14,000 ข้อ,\n",
      "- วัดผลด้วยเกณฑ์อ้างอิงจากโครงงานคล้ายกัน patil-suraj/question_generation คือ METEOR, GLEU, BLEU-4, Chr-F, และ ROUGE-L; พบว่าโมเดลที่ใช้ data augmentation ทำคะแนนได้ดีที่สุด แต่มีปัญหาว่าไม่สามารถสร้างคำถามได้ตามจำนวนที่ต้องการนัก,\n",
      "- ตรวจว่าคำถาม-ตอบ 449 คู่ที่ถูกสร้างขึ้นมาสำหรับ validation set นั้นถูกต้องแค่นั้น **ด้วยมือ** พบว่าถูกประมาณ 70%; คู่คำถาม-ตอบที่ผิดแบ่งได้เป็น อ่านไม่รู้เรื่อง (37.7%), ไม่มีคำตอบ (15.2%), จำนวนคำถามไม่ตรงตามที่ต้องการ (8.7%), คำตอบผิด (13.8%), สร้างคำถามซ้ำ ( 24.6%)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"I firmly stand by the fact that I have a passion for always seeking to learn and research new things and technologies to improve myself and the world around me.  \"One example of this was when I took the Harvard University CS50x course last year in grade 8. This programming course was extremely challenging. But with my passion and determination, I pressed on, excelled, and earned my certificate shown in the attached portfolio. Furthermore, I went on to completely self-study the AP Computer Science Principles course and was the only person who ever scored a perfect 5 out of 5 for my school. Currently, Im studying another Harvard course that focuses on artificial intelligence: CS50AI.\",  Another achievement was the application that I wrote for my school, which is being used by over 200 people. For context, I am the youngest Student Council member in the history of my school, and I wanted to help the community by combining all the news into one place. Please see the portfolio for links to the app. During this time, I also joined the AWS Builders program to learn about the platform and all the marvelous tools that it offers.  Additionally, I am also very familiar with Linux. Throughout the last 3 to 4 years, I have researched on my own about it and have learned enough about it to post an install guide on Youtube and help countless people. To make the installation straightforward, I created various packages to add support for the Microsoft Surface devices (https://github.com/parinzee/linux-surface-overlay).  Finally, I believe that I am a compelling candidate because of my experience, ability to self-study, and extreme perseverance. These are qualities that innovators and leaders need to have. Accepting me into this program would allow me to help Thailand effectively in the future.\"\n",
      "---\n",
      "date: \"12-8-22\"\n",
      "title: \"Using Machine Learning to create Auto Pitch Writer for UTAU\"\n",
      "builder: \"จิรา กุลจิราพงษ์ (จิรา)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/63/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/CCSleep/utau-pitch-ml/\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/450681343766977\"\n",
      "    blog: \"https://medium.com/@CCSleep/using-machine-learning-to-create-auto-pitch-writer-for-utau-eec2d104236a\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/63/01.jpg)\n",
      "\n",
      "- โมเดลปรับแต่งพิช (Auto Pitch Writer) สำหรับโปรแกรมสร้างเพลง UTAU (คล้าย Vocaloid),\n",
      "- [สำคัญมาก] ก่อนอื่นทำความเข้าใจ Tuning ใน UTAU ด้วยวิดีโอ https://youtu.be/ciJlUPlS7dU, , ตัวอย่างเพลงที่ไม่ได้ tune: https://youtu.be/ciJlUPlS7dU?t=59, ตัวอย่างเพลงที่ tune แล้ว: https://youtu.be/ciJlUPlS7dU?t=723, ,\n",
      "- ปัญหาที่ต้องกาจะแก้คือการทำให้เพลงที่สร้างด้วยโปรแกรม \"ฟังเป็นธรรมชาติขึ้น\" เนื่องจากหากเราแค่ใส่พิชของแต่ละตัวโน้ตต่อกันไปเรื่อยๆจะทำให้ได้เพลงที่เหมือนหุ่นยนต์ร้อง จึงต้องมีการปรับพิชระหว่างตัวโน้ต (pitchbends) ซึ่งปกติทำด้วยมือคนแต่ง,\n",
      "- เก็บข้อมูลจากลิสต์ไฟล์ UST (UTAU sequence text) ที่ถูกรวบรวมไว้ที่ https://docs.google.com/document/d/1yKn3jN3rLoVFSXcPUET_iYsmbUi-nThRktgIAyXc230/edit และใช้ไฟล์ที่ถูกเก็บด้วย Mediafire ทั้งหมด,\n",
      "- UTAU แสดง pitchbends ด้วยตัวแปร 3 ตัวในรูปแบบ, , PBS=-66;-50 (เวลาเริ่ม;พิชเริ่ม), PBW=38,71,-3,141,50 (ค่าบนแกน Y นั่นคือแกนพิช สำหรับจุดถัดไป ในที่นี้คือ 4 จุด), PBY=-17.9,-18.6,-0.7,0,0 (ค่าความห่างจากจุดที่แล้วตามแกน X นั่นคือแกนเวลา), ,\n",
      "- ก่อนอื่นปรับ PBS ด้วยกฎโดยให้เวลาเริ่มคือเริ่มจาก 20% สุดท้ายของความยาวโน้ตตัวที่แล้ว และเริ่มจากพิชของโน้ตตัวที่แล้ว,\n",
      "- สำหรับ PBW และ PBY นั้น ใช้วิธีการสร้างโมเดล machine learning เพื่อทำนาย \"เทรนด์การขึ้นลง\" ของ PBY (ขึ้นเป็น 1 ลงเป็น 0; ตัวเลข 4 ตัว รวม 63 คลาส) เช่น [0,1,0,0], [0,1,1,1], ...,\n",
      "- จากนั้นใช้ประสบการณ์การแต่งเพลง สร้างกฎเปลี่ยนคำทำนายกลับเป็น PBW และ PBY,\n",
      "- สำหรับ feature ในการทำนาย ใช้ความยาวและพิชจากโน้ตทั้งสองตัวสร้างขึ้นด้วย pyUTAU,\n",
      "- ใช้ baseline เป็นการสร้าง pitchbends ด้วย Portamento ใน UTAU คือแค่ลากเส้นขึ้น-ลงแบบเป็นเส้นตรง แน่นอนว่าจะได้เสียงที่ไม่เป็นธรรมชาตินัก,\n",
      "- ใช้ random forest ได้ accuracy 61% บน test set เทียบกับ 27% ของ Portamento baseline จาก 63 classes,\n",
      "- สังเกตว่าโมเดลทาย class 0 (ไม่มีพิช) และ 1 (พิชลง) มากกว่าปกติมาก (ทั้งสองคลาสเป็น 2/3 ของตัวอย่างทั้งหมด) จึงลองสร้างโมเดล logistic regression เพื่อดูว่าโมเดลคิดอย่างไร; พบว่าสำหรับ 0 โมเดลมองว่าถ้าโน้ตตัวหน้าเป็น rest แทบจะแน่นอนว่าต้องทายว่าไม่มีพิช สำหรับ 1 โมเดลมองว่าถ้าโน้ตตัวหน้าสั้นกว่าส่วนใหญ่จะเป็นพิชลง ซึ่งตรงกับสัญชาติญาณของนักแต่งเพลงที่เป็นมนุษย์\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"What inspires me to create AI is how I discovered NLP by accident while I was looking to create spoonerism for Thai words. Back then I really wonder how a library like PyThaiNLP can split syllables nearly perfectly without me having to tell the users to split on my own, and that really get me obsessed.\"\n",
      "---\n",
      "date: \"13-8-22\"\n",
      "title: \"Object Detection in White Blood Cells for Leukemia\"\n",
      "builder: \"แพรวา ชูบ้านนา (แพรว)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/64/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/praewery/objectdetction-White_blood_cell\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/451374247031020\"\n",
      "    blog: \"https://medium.com/@cytokinin8/object-detection-in-white-blood-cell-60273002fdb3\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/64/01.jpg)\n",
      "\n",
      "- โมเดลจับและแยกแยะภาพเซลล์มะเร็งเม็ดเลือดขาวด้วย Faster CNN, YOLO v5 และ Swin Transformer,\n",
      "- มะเร็งเม็ดเลือดขาวชนิดเฉียบพลันจัดเป็นโรคมะเร็งที่มีความรุนแรงสูง พบได้ทุกเพศทุกวัย พบมากขึ้นในผู้สูงอายุ และเป็น 1 ใน 10 โรคมะเร็งที่พบบ่อยในประเทศไทย; เซลล์มะเร็งเม็ดเลือดขาวมีหลากหลายชนิด การแบ่งชนิดของมะเร็งเม็ดเลือดขาวจะมีผลต่อการเลือกวิธีการรักษา เนื่องจากมะเร็งเม็ดเลือดขาวแต่ละชนิดมีการดำเนินโรคและการพยากรณ์โรคที่แตกต่างกัน,\n",
      "- ในปัจจุบันการวินิจฉัยมะเร็งเม็ดเลือดขาว จะทำการตรวจไขกระดูก (bone marrow smear or biopsy) หรือการดูจากเลือดที่เจาะจากหลอดเลือดดำ (vein)เช่น ที่แขน โดยทั้งสองวิธีนั้นจะนำเลือดมาไถดูบนสไลด์ เพื่อดูผ่านกล้องจุลทรรศน์ เรียกว่า (peripheral blood smear) เพื่อนับจำนวนเซลล์ตัวอ่อน และแยกชนิดของเซลล์ เพื่อพยากรณ์โรค ทั้งนี้ การแบ่งชนิดของมะเร็งเม็ดเลือดขาวจะมีผลต่อการเลือกวิธีการรักษาทำให้สำคัญมากๆ จำเป็นต้องอาศัยบุคลากรทางการแพทย์และผู้เชี่ยวชาญในการจำแนก จึงเป็นเหตุผลที่ดีถ้าเราจะนำ AI เข้าไป screening tools ช่วยบุคลากรทางการแพทย์ เพื่อเพิ่มประสิทธิภาพทางการรักษาได้มากยิ่งขึ้น,\n",
      "- ใช้ชุดข้อมูล microscopic image of white blood cells จาก โรงพยาบาลศิริราช โดยภายใน Dataset ประกอบด้วยรูปภาพ ตัวอ่อนของเม็ดเลือดขาวของกลุ่มคนประเภทหนึ่ง ซึ่งสามารถแบ่งเป็น 12 ชนิดด้วยกันได้แก่ Atypical lymphocyte, Band Neutrophil, Basophil, Blast, Eosinophil, Lymphocyte, Metamyelocyte, Monocyte, Myelocyte, NRC, Promyelocyte, Segmented neutrophil; ทั้งหมดจำนวน 3,376 ภาพ เป็น train set จำนวน 2700 ภาพ, validation set จำนวน 338 ภาพและ test set จำนวน 338 ภาพ,\n",
      "- ทำ data augmentation หรือ การเพิ่มจำนวน dataset เพื่อให้โมเดลได้ train ข้อมูลที่เยอะมากขึ้น จากการ rotation, cropping, horizintal flips ภาพใน dataset และ ปรับขนาดรูปภาพของเรา,\n",
      "- ทดลองใช้สถาปัตยกรรม Faster CNN (accuracy 33.53%), YOLO v5 (accuracy 51.63%) และ Swin Transformer (accuracy 56.37%),\n",
      "- จาก test set ทั้งหมด 337 ภาพสามารถทายถูก 190 ภาพและ ทายผิด 71 ภาพ และมีอีก 76 ภาพที่โมเดลของเราไม่ detect ซึ่งพอไปตรวจสอบรูปภาพเหล่านั้นพบว่าส่วนมากจะเป็นรูป ที่มีปริมาณเม็ดเลือดเกาะตัวเป็นกลุ่มทำให้ โมเดลเกิดการสับสน และจับภาพ ออกมาได้ไม่ครบถ้วนและเมื่อลองดูจากจำนวน dataset แล้วจะเห็นได้ว่า จำนวนตัวอย่างของ Promyelocyte มีจำนวนน้อยมากๆทำให้โมเดลสามารถเรียนรู้ได้น้อยและทายผิดอยู่บ้าง\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"หนูมีความแน่วแน่และสนใจด้านนี้จริงๆ หลังจากที่ได้รู้ว่า AI builders ได้เปิดรับสมัครอีกครั้ง ก็ได้ติดตามข่าวสาร และ ศึกษาจากไลฟ์สดที่พี่ๆได้สอนในวันที่ 21 และ 28 มีนาคมที่ผ่านมา เพื่อใช้ในการทำแบบทดสอบของทางโครงการ ยอมรับค่ะว่าตอนทำข้อสอบช่วงแรกๆอาจจะมีนบ้างรันได้ error บ้างแต่หลังจากที่ได้ดูไลฟ์ของทางเพจ AI builders ทำให้หนูสามารถทำข้อสอบได้หมดทุกข้อเลยค่ะถึงแม้อาจจะใช้เวลาเยอะกว่าคนอื่นไปบ้าง หนูอาจจะไม่ใช่คนที่เก่งที่สุด อาจจะไม่ใช่อัจฉริยะที่เรียนรู้ได้รวดเร็ว แต่หนูเชื่อมั่นค่ะว่าหนูมีความสามารถไม่ต่างจากคนอื่น และสามารถประสบความสำเร็จได้เหมือนกันกับ เพื่อนๆAI builders ปีที่ผ่านมา หนูมีประสบการณ์ด้าน AI และ coding จากเวที Space Fight , YSLC ,The 2nd Kibo- RPC จากปีที่ผ่านมาค่ะ และหนูอยากจะให้ โครงการ AI builders เป็นหนึ่งในประสบการณ์ด้าน AI ของหนูต่อไปในอนาคตค่ะ  ส่วนตัวหนูเป็นคนชอบเขียนโปรแกรมมิ่งมากๆค่ะ หลังจากที่ได้รู้ในสิ่งที่ตัวเองชอบได้ไม่นาน หนูก็ได้พยายามฝึกฝนและขวนขวายเกี่ยวกับภาษาpythonมากยิ่งขึ้น ในช่วงที่ผ่านมาหนูได้มีโอกาสเข้าร่วมเวทีSPACE FIGHT ,The 2nd Kibo- RPC ยิ่งทำให้หนูสนใจด้าน AI มากยิ่งขึ้นและได้นำความรู้จากค่ายต่างๆมาประยุกต์ใช้ในโปรเจกต์ที่โรงเรียนและอื่นๆ เมื่อไม่นานมานี้ หนูพึ่งได้เรียนรู้เกี่ยวกับ Machine Learning ไม่ว่าจะเป็น การจัดการข้อมูล โดยใช้ Numpy , pandas และอยากจะนำความรู้เหล่านี้มาลองทำเป็นโปรเจกต์ของตัวเองดูบ้าง  จนมาเจอ AI Builder จากผลงานของเพื่อนๆในปีที่ผ่านมา ทุกคนสุดยอดมากๆเลยค่ะ น่าประทับใจมาก มีตั้งแต่รุ่นน้องๆ ไปจนถึงเพื่อนๆพี่ๆ ทำให้เห็นได้เลยค่ะว่าถ้าจบจากโครงการ AI builders ไปจะต้องได้คุณภาพทางด้าน Data Science และ AI แน่ๆ และ หนูอยากจะมีโอกาสเหมือนเพื่อนๆเหล่านั้น จนกระทั่งได้รับข่าวสารไม่นานมานี้ว่าโครงการนี้เปิดรับสมัครอีกครั้ง หนูเลยอยากลองทำโปรเจกต์ Machine learning ดูบ้าง หนูได้ตั้งเป้าหมายแน่วแน่เลยค่ะ ว่าต้องสมัครโครงการนี้และเป็นส่วนหนึ่งของโครงการนี้ให้ได้ ถ้าหนูได้รับโอกาสนี้หนูจะตั้งใจและหมั่นศึกษาหาความรู้จากโครงการนี้ ให้เกิดประโยชน์ต่อหนูเองในอนาคตและช่วยพัฒนาสังคมประเทศของเราให้ดียิ่งขึ้นค่ะ\"\n",
      "---\n",
      "date: \"14-8-22\"\n",
      "title: \"Single Note Music Classification\"\n",
      "builder: \"ณภัทร เสรีรักษ์ (นีร)\"\n",
      "builder_info: \"\"\n",
      "thumbnail: \"/images/2022/65/01.jpg\"\n",
      "links:\n",
      "    github: \"https://github.com/neennera/AI_single-music-note-classification\"\n",
      "    facebook: \"https://facebook.com/aibuildersx/posts/452054363629675\"\n",
      "    blog: \"https://neennera.medium.com/single-note-music-classification-by-convolutional-neural-networks-5f72434d139a\"\n",
      "---\n",
      "\n",
      "![image](/images/2022/65/01.jpg)\n",
      "\n",
      "- โมเดลแยกแยะโน้ตเพลงรายตัวจากไฟล์ MIDI ด้วย Convolutional Neural Networks (CNN),\n",
      "- แรงบันดาลใจจากความคิดง่ายๆอย่าง “ถ้ามี AI ที่พอฟังเราฮัมเพลงแล้วทายโน๊ตถูกเลยคงดีนะ” ในช่วงนั้นเราได้รู้จักคำว่า “Perfect Pitch” ซึ่งเป็นคำเรียกกลุ่มคนที่ฟังเพลงแล้วรู้โน๊ตในทันที สามารถแยกแยะเสียงโน๊ตได้ตั้งแต่เกิดหรือฝึกเอา จาก ear training บ่อยๆ ประจวบกับโครงการ AI Builders ประกาศพอดี เลยถือโอกาสมาลองฝึก “Perfect Pitch” กับ Model ดู,\n",
      "- ชุดข้อมูลจากไฟล์เสียง MIDI ที่สร้างขึ้น ประกอบไปด้วยเสียงโน๊ตตั้งแต่ C0-B9 ที่เล่นโดยเครื่องดนตรีต่างชนิดกัน มีไฟล์เสียงทั้งสิ้น 26,643 ไฟล์,\n",
      "- จัดการข้อมูลโดย 1) resample เสียงให้มีความละเอียดที่ 16000 Hz 2) mix down ในกรณีที่ไฟล์บางไฟล์มีการแยก channel ซ้าย/ขวา เราจะรวมเสียงให้มาอยู่ใน mono channel 3) เปลี่ยนเป็น mel spectrogram ซึ่งเป็น short-time fourier transform ที่เน้นแค่คลื่นเสียงต่ำอันเสียงออกมาเป็นค่าที่ใกล้เคียงกับค่าที่มนุษย์ได้ยิน; ที่จริงเรายังสามารถ take log ลงไปเพื่อให้ range ของข้อมูลไม่กว้างและกระโดดมาถึง 20,000 แต่เนื่องจากการ predict note เราดูแค่ frequency เสียงที่โดดขึ้นมา จึงไม่ได้มีผลต่อการทำนายมากนัก กลับกัน หากเป็น speech ก็จะทำให้เกิดปัญหาตามมาได้,\n",
      "- โมเดลรับข้อมูล tensor ของ data ที่มี size เป็น (128,50) แล้วส่งเข้าโมเดลก่อนจะ predict ค่ามาเป็น index ของ classmap ตั้งแต่ 0–12 (classmap=[“C”,”C#”,”D”,”D#”,”E”,”F”,”F#”,”G”,”G#”,”A”,”A#”,”B”]),\n",
      "- เทรน 1D CNN 3 layers (ขนาด channel 128 -> 256 -> 512) ด้วย cross-entropy loss; ใช้ BatchNorm1D มา normalization ข้อมูลก่อนออกจาก layer ก่อนจะใช้ Activation ReLU เพื่อจะกำจัดค่าที่น้อยกว่า 0 ออกเป็นตอนสุดท้ายเพราะความถี่เสียงมีค่าติดลบไม่ได้,\n",
      "- ได้ accuracy 96.48% หลังเทรนไป 20 epochs,\n",
      "- นอกจากนี้ยังได้ทำอีกโครงการสำหรับแยกแยะโน้ตที่เรียงกัน 1,500 time steps จากชุดข้อมูล MusicNet (https://zenodo.org/record/5120004#.YrHWQLlBxQI) อีกด้วย; ทดลองสถาปัตยกรรมากมายได้แก่ Conv1d -> Conv1d -> Linear, Conv1d -> RELU -> Linear(บนแกน time) -> LSTM(บนแกน feature), Convo1d -> LSTM(time) -> Linear(time) -> LSTM(feature), Conv1d(kernel = 6) -> ReLU -> Conv1d(kernel = 8) -> LSTM แต่ปัญหาการทายโน้ตหลายตัวพร้อมกันยังยากกว่าทายตัวเดียวมาก (อ่านต่อได้ที่ https://neennera.medium.com/%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%9E%E0%B8%B1%E0%B8%92%E0%B8%99%E0%B8%B2-model-%E0%B9%81%E0%B8%A2%E0%B8%81%E0%B9%82%E0%B8%99%E0%B9%8A%E0%B8%95%E0%B8%94%E0%B8%99%E0%B8%95%E0%B8%A3%E0%B8%B5%E0%B9%83%E0%B8%99%E0%B9%80%E0%B8%9E%E0%B8%A5%E0%B8%87-%E0%B9%82%E0%B8%94%E0%B8%A2-pytorch-b239dc0e956c)\n",
      "\n",
      "### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n",
      "\n",
      "> \"เราให้นิยามตัวเองว่าเป็นคนที่มีความพยายามต่องานที่ทำอยู่เสมอ จึงมั่นใจได้ว่าเราจะทำโปรเจคนี้อย่างเต็มความสามารถ เรามีความรู้ในการเขียนโปรแกรมภาษา python มาจากการศึกษาด้วยตนเองเพื่อทำ project ในโรงเรียนและมีความกระตือรือร้นที่จะเรียนรู้อีก เรายังได้ทำการศึกษาการเขียนโปรแกรมมาหลากหลายผ่านการเข้าค่ายโอลิมปิกวิชาการคอมพิวเตอร์ค่าย 2 ที่ทำให้เราได้เข้าใจ algorithm ที่หลากหลาย เราได้ร่วมพัฒนาโครงการเครื่องให้อาหารแมวที่ควบคุมบน Web Application และทำงานร่วมกับระบบ IoT โดยตลอดเวลาที่ทำงานเหล่านั้นเราศึกษาบนเว็บต่างประเทศจึงสามารถอ่าน, แปล, และทำความเข้าใจบทความหรือ paper ภาษาอังกฤษได้ดีมาก เรามีแรงบันดาลใจในการสร้าง AI แก้ปัญหาในชีวิตประจำวัน แม้จะเป็นปัญหาเฉพาะกลุ่มแต่ก็สามารถสร้างความแปลกใหม่ได้ เราคาดหวังอย่างยิ่งว่าจะได้รับโอกาสในการทำความฝันนั้นให้เป็นจริง  ปฏิเสธไม่ได้ว่า Artificial Intelligence ได้เข้ามาบทบาทอย่างมากในปัจจุบัน ทั้งช่วยย่นการทำงานของมนุษย์ ช่วยจำแนกหรือวิเคราะห์ข้อมูลที่ซับซ้อน แนะนำ content ที่เกี่ยวข้อง หรือแม้แต่ช่วยตัดสินใจ แต่ก็ใช่ว่า AI จะสามารถทำได้ทุกอย่างหรือแม้แต่การทำงานออกมาได้ perfect 100% ก็เป็นไปได้ยากหากขาด dataset , การจัดการข้อมูลที่ดี หรือ วิธีการ train model ที่เหมาะสม ซึ่งสิ่งนี้จำเป็นต้องศึกษาเพิ่มเติมกว่าความรู้ในม.ปลายไปมาก และจำเป็นต้องพึ่งพาผู้ที่มีประสบการณ์มากกว่า  เราสนใจโครงการ AI Builder ตั้งแต่ปีที่แล้ว แม้จะไม่ผ่านรอบคัดเลือกตัวจริงแต่ก็ได้ศึกษาเนื้อหาไปบ้างในแบบของนักเรียน sit-in หลังจากเห็นโครงงานของเพื่อนหลายคนก็ทำให้เรามีไฟที่อยากจะมาลองสมัครรอบของปีนี้อีก! AI Builder มีเนื้อหาที่เข้มข้นและสิ่งที่สำคัญคือการมี mentor ที่เชี่ยวชาญ และกลุ่มเพื่อนเข้ามาช่วยให้คำปรึกษา เราจึงคิดว่าหากได้เข้าร่วมโครงการนี้แล้ว คงจะได้พัฒนาฝีมือตัวเองให้ดีขึ้นและเข้าใจถึงการพัฒนาโปรเจค AI อย่างเต็มรูปแบบจนอาจสามารถตกตะกอนความรู้และถ่ายทอดให้ผู้อื่นได้ในภายหลัง\"\n"
     ]
    }
   ],
   "source": [
    "for x in posts:\n",
    "    print(make_md(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./posts/2022/BACK-(Blind-All-Can-Know)---Action-Captioning-for-Blinds.md\n",
      "./posts/2022/Violence-Detection.md\n",
      "./posts/2022/Fake-Product-Detection-on-Online-Retail.md\n",
      "./posts/2022/Cactus-Classification-with-Fastai.md\n",
      "./posts/2022/Food-Ingredients-Label-Reader-for-Food-Allergy.md\n",
      "./posts/2022/Edge-to-Face-Drawing-Realistic-Faces-from-Canny-Edges.md\n",
      "./posts/2022/TextDoe-โมเดลจำแนกแวดวงบทความสิ่งพิมพ์.md\n",
      "./posts/2022/Auto-Lyric-Recognizer.md\n",
      "./posts/2022/Image-Transfer-Day-to-Night-and-Night-to-Day.md\n",
      "./posts/2022/Music-Recognition.md\n",
      "./posts/2022/vTranslator-Transcribe-and-Translate-VTuber-using-Wav2Vec2.md\n",
      "./posts/2022/Text-to-image-synthesis-with-VQGAN-ThCLIP.md\n",
      "./posts/2022/Game-Recommendation-by-using-Neural-Network-Embeddings.md\n",
      "./posts/2022/Chaos-EDM-Generating-EDM-Song-with-VAE-(Variational-Autoencoder)-Spectrogram.md\n",
      "./posts/2022/WanchanBERTa-Thai-Grammarly.md\n",
      "./posts/2022/Garbage-Detection-with-Tensorflow-Lite.md\n",
      "./posts/2022/Sick-Pig-Classifier.md\n",
      "./posts/2022/NLP-for-genre-predictions-on-FFnet-an-antithesis-to-utilitarianism.md\n",
      "./posts/2022/AI-แยกแยะแมงดาจาน-กับ-แมงดาถ้วย.md\n",
      "./posts/2022/Is-that-a-Supra.md\n",
      "./posts/2022/Microplastic-detection-and-collect-statistical-tebular-data..md\n",
      "./posts/2022/Debunker-ML-ตรวจจับข่าวลวง.md\n",
      "./posts/2022/Brain-Tumor-Segmentation-using-SegResNet.md\n",
      "./posts/2022/Classical-Music-Generator.md\n",
      "./posts/2022/Lamiaceae-Classification-แยกพืชวงศ์กะเพรา-3-ชนิด.md\n",
      "./posts/2022/สร้างสรรบทเพลง-Undertale-ผ่าน-LSTM-และ-Teacher-Forcing-RNN.md\n",
      "./posts/2022/Plant-Disease-Classification.md\n",
      "./posts/2022/TLDR;-Terms-and-Conditions-Summarizer.md\n",
      "./posts/2022/RL-in-Traffic-Management.md\n",
      "./posts/2022/Learn-Chinese-Faster-by-Using-Handwritten-Chinese-Character-Recognition-(HCCR).md\n",
      "./posts/2022/Crossec--ระบบส่งเสริมการทำปฏิบัติการเนื้อเยื่อพืชด้วยปัญญาประดิษฐ์.md\n",
      "./posts/2022/American-Sign-Language.md\n",
      "./posts/2022/A-Lip-Reader.md\n",
      "./posts/2022/Obstacle-Detection-for-Blind-people-ช่วยเหลือผู้พิการทางสายตาด้วย-Deep-Learning.md\n",
      "./posts/2022/Detect-and-collect-COVID-19-data-more-faster-by-using-ATK-OCR-Classification-(AOC)-model.md\n",
      "./posts/2022/โมเดล-CNN-สำหรับการจำแนกสัญญาณสมองในระบบ-SSVEP-BCI-สำหรับไมเกรน-(A-CNN-for-Classification-Task-in-SSVEP-BCI-for-Migraine).md\n",
      "./posts/2022/PsychNLP-A-BERT-based-NLP-model-as-a-screening-tool-to-help-classify-the-risks-of-depression-and-suicide.md\n",
      "./posts/2022/My-Little-HR-โมเดลประเมินเงินเดือนอาชีพสาย-IT-ในประเทศไทย.md\n",
      "./posts/2022/GANime-FullBody-วาดรูปตัวละครอนิเมะ(สาวๆ)แบบเต็มตัว-ด้วย-Deep-Learning.md\n",
      "./posts/2022/Find-Water-from-Satellite-Images-Using-U-Net-Image-Segmentation-with-Pytorch.md\n",
      "./posts/2022/Emotion-Detection-from-Facial-Micro-experessions.md\n",
      "./posts/2022/Automatic-E2E-Thai-Question-Generation-with-MT5.md\n",
      "./posts/2022/Using-Machine-Learning-to-create-Auto-Pitch-Writer-for-UTAU.md\n",
      "./posts/2022/Object-Detection-in-White-Blood-Cells-for-Leukemia.md\n",
      "./posts/2022/Single-Note-Music-Classification.md\n"
     ]
    }
   ],
   "source": [
    "def naming_sense(text, root='./posts/2022/'):\n",
    "    # tokenize\n",
    "    # tokens = pythai.word_tokenize(text)\n",
    "    # x = '-'.join(tokens)\n",
    "    # if len(x) < 20:\n",
    "    #     x = text\n",
    "    # elif len(x) > 20:\n",
    "    #     x = x = ''.join(tokens[:3])\n",
    "    x = text\n",
    "        \n",
    "    naming = x.replace(' ', '-').replace('!', '').replace('?', '').replace(':','')\n",
    "    path = f\"{root}{naming}.md\"\n",
    "    return path\n",
    "\n",
    "for post in posts:\n",
    "    data = make_md(post)\n",
    "    if naming_sense(post['title']) in ['ChaosEDM', 'Crossec', 'Debunker', 'Edge-to-Face', 'MyLittleHR', 'NLPforgenrepredictionsonFFnet', 'PsychNLP', 'TextDoe', 'vTranslator']:\n",
    "        print(post['title'])\n",
    "\n",
    "    # test naming\n",
    "    print(naming_sense(post['title']))\n",
    "    with open(naming_sense(post['title'], \"./posts/2022/\"), 'w', encoding='utf8') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "# check if the post was generated correctly\n",
    "print(len(os.listdir('./posts/2022/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e73a464379447ddfc8ee4935215540133560b3ea78e2ab4739eadfcb8582468"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
